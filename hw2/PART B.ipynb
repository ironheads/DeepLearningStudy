{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 2 Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the torch cuda is ok\n",
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "## Note that: here we provide a basic solution for loading data and transforming data.\n",
    "## You can directly change it if you find something wrong or not good enough.\n",
    "\n",
    "## the mean and standard variance of imagenet dataset\n",
    "## mean_vals = [0.485, 0.456, 0.406]\n",
    "## std_vals = [0.229, 0.224, 0.225]\n",
    "\n",
    "def load_data(data_dir = \"dataset/\",input_size = 224,batch_size = 36):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    ## The default dir is for the first task of large-scale deep learning\n",
    "    ## For other tasks, you may need to modify the data dir or even rewrite some part of 'data.py'\n",
    "    image_dataset_train = datasets.ImageFolder(os.path.join(data_dir, '2-Medium-Scale', 'train'), data_transforms['train'])\n",
    "    image_dataset_valid = datasets.ImageFolder(os.path.join(data_dir,'test'), data_transforms['test'])\n",
    "\n",
    "    train_loader = DataLoader(image_dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    valid_loader = DataLoader(image_dataset_valid, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "# load the trained model\n",
    "def load_model(device,model_name,optimizer_name):\n",
    "    return torch.load(model_name+\" with \"+optimizer_name+ \" best_model.pt\",device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "def baselineModel(num_classes):\n",
    "    model_resnet = models.resnet18(pretrained=False)\n",
    "    num_features = model_resnet.fc.in_features\n",
    "    model_resnet.fc = nn.Linear(num_features, num_classes)\n",
    "    model_resnet.name = \"Medium-Scale Baseline Learning\"\n",
    "    return model_resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "## Note that: here we provide a basic solution for training and validation.\n",
    "## You can directly change it if you find something wrong or not good enough.\n",
    "\n",
    "def train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=20, logdir = 'logs_part_b'):\n",
    "    def train(model, train_loader,optimizer,criterion):\n",
    "        model.train(True)\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct += torch.sum(predictions == labels.data)\n",
    "\n",
    "        epoch_loss = total_loss / len(train_loader.dataset)\n",
    "        epoch_acc = total_correct.double() / len(train_loader.dataset)\n",
    "        return epoch_loss, epoch_acc.item()\n",
    "\n",
    "    def valid(model, valid_loader,criterion):\n",
    "        model.train(False)\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct += torch.sum(predictions == labels.data)\n",
    "        epoch_loss = total_loss / len(valid_loader.dataset)\n",
    "        epoch_acc = total_correct.double() / len(valid_loader.dataset)\n",
    "        return epoch_loss, epoch_acc.item()\n",
    "\n",
    "    best_acc = 0.0\n",
    "    train_loss_curves = []\n",
    "    train_acc_curves = []\n",
    "    valid_loss_curves = []\n",
    "    valid_acc_curves = []\n",
    "    writer = SummaryWriter(os.path.join(logdir,model.name + ' with ' + optimizer.name))\n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch:{:d}/{:d}'.format(epoch, num_epochs))\n",
    "        print('*' * 100)\n",
    "        train_loss, train_acc = train(model, train_loader,optimizer,criterion)\n",
    "        print(\"training: {:.4f}, {:.4f}\".format(train_loss, train_acc))\n",
    "        valid_loss, valid_acc = valid(model, valid_loader,criterion)\n",
    "        print(\"validation: {:.4f}, {:.4f}\".format(valid_loss, valid_acc))\n",
    "        train_acc_curves.append(train_acc)\n",
    "        train_loss_curves.append(train_loss)\n",
    "        valid_acc_curves.append(valid_acc)\n",
    "        valid_loss_curves.append(valid_loss)\n",
    "        writer.add_scalars(os.path.join(model.name+\" with \"+optimizer.name,'loss curves'),{'train':train_loss,'valid':valid_loss},epoch)\n",
    "        writer.add_scalars(os.path.join(model.name+\" with \"+optimizer.name,'acc curves'),{'train':train_acc,'valid':valid_acc},epoch)\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_model = model\n",
    "            torch.save(best_model, model.name+' with '+optimizer.name +' best_model.pt')\n",
    "    writer.close()\n",
    "    return train_loss_curves,train_acc_curves,valid_loss_curves,valid_acc_curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "class LKA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim:int\n",
    "        ) -> None :\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(dim, dim, 5, padding=2, groups=dim)\n",
    "        self.conv_spatial = nn.Conv2d(dim,dim,7,stride=1,padding=9,groups = dim ,dilation=3)\n",
    "        self.conv2 = nn.Conv2d(dim,dim,1)\n",
    "\n",
    "    def forward(self,x:Tensor) -> Tensor:\n",
    "        u=x.clone()\n",
    "        attn = self.conv1(x)\n",
    "        attn = self.conv_spatial(attn)\n",
    "        attn = self.conv2(attn)\n",
    "        return u*attn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        bottleneck_dim: int,\n",
    "        out_dim: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.proj_1 = nn.Conv2d(in_dim, bottleneck_dim, 1)\n",
    "        self.norm_layer_1 = nn.BatchNorm2d(bottleneck_dim)\n",
    "        self.activation = nn.GELU()\n",
    "        self.spatial_gating_unit = LKA(bottleneck_dim)\n",
    "        self.proj_2 = nn.Conv2d(bottleneck_dim, out_dim, 1)\n",
    "        self.norm_layer_2 = nn.BatchNorm2d(out_dim)\n",
    "        self.downsample = None if in_dim==out_dim else nn.Sequential(\n",
    "            nn.Conv2d(in_dim,out_dim,1),\n",
    "            nn.BatchNorm2d(out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x:Tensor)->Tensor:\n",
    "        out = self.proj_1(x)\n",
    "        out = self.norm_layer_1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.spatial_gating_unit(out)\n",
    "        out = self.norm_layer_2(out)\n",
    "        out = self.proj_2(out)\n",
    "        if (self.downsample is not None):\n",
    "            x=self.downsample(x)\n",
    "        out = out + x\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "# class Block(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         input_dim: int,\n",
    "        \n",
    "#         drop_path: float,\n",
    "#         act_layer: Optional[Callable[...,nn.Module]]=nn.GELU\n",
    "#     ) -> None:\n",
    "#         super().__init__()\n",
    "#         self.norm1=Bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testBaselineModel():\n",
    "    ## about model\n",
    "    num_classes = 10\n",
    "\n",
    "    ## about data\n",
    "    data_dir = \"dataset/\" ## You need to specify the data_dir first\n",
    "    input_size = 224\n",
    "    batch_size = 32\n",
    "\n",
    "    ## about training\n",
    "    num_epochs = 100\n",
    "    lr = 0.001\n",
    "\n",
    "    ## model initialization\n",
    "    model = baselineModel(num_classes=num_classes)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    ## data preparation\n",
    "    train_loader, valid_loader = load_data(data_dir=data_dir,input_size=input_size, batch_size=batch_size)\n",
    "\n",
    "    ## optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9,0.999))\n",
    "    optimizer.name = 'Adam'\n",
    "    ## loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loss_curves,train_acc_curves,valid_loss_curves,valid_acc_curves = train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_model(model):\n",
    "    ## about data\n",
    "    data_dir = \"dataset/\" ## You need to specify the data_dir first\n",
    "    input_size = 224\n",
    "    batch_size = 32\n",
    "\n",
    "    ## about training\n",
    "    num_epochs = 100\n",
    "    lr = 0.001\n",
    "\n",
    "    ## model initialization\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    ## data preparation\n",
    "    train_loader, valid_loader = load_data(data_dir=data_dir,input_size=input_size, batch_size=batch_size)\n",
    "\n",
    "    ## optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9,0.999))\n",
    "    optimizer.name = 'Adam'\n",
    "    ## loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loss_curves,train_acc_curves,valid_loss_curves,valid_acc_curves = train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100\n",
      "****************************************************************************************************\n",
      "training: 1.6966, 0.4300\n",
      "validation: 1.5781, 0.4244\n",
      "epoch:1/100\n",
      "****************************************************************************************************\n",
      "training: 1.4342, 0.4870\n",
      "validation: 1.4513, 0.4702\n",
      "epoch:2/100\n",
      "****************************************************************************************************\n",
      "training: 1.2367, 0.5610\n",
      "validation: 1.7276, 0.4565\n",
      "epoch:3/100\n",
      "****************************************************************************************************\n",
      "training: 1.1770, 0.6000\n",
      "validation: 1.3630, 0.5620\n",
      "epoch:4/100\n",
      "****************************************************************************************************\n",
      "training: 1.1751, 0.5640\n",
      "validation: 1.4516, 0.5228\n",
      "epoch:5/100\n",
      "****************************************************************************************************\n",
      "training: 1.1352, 0.6050\n",
      "validation: 1.2363, 0.5565\n",
      "epoch:6/100\n",
      "****************************************************************************************************\n",
      "training: 1.0404, 0.6270\n",
      "validation: 1.2958, 0.5739\n",
      "epoch:7/100\n",
      "****************************************************************************************************\n",
      "training: 0.9513, 0.6520\n",
      "validation: 0.8694, 0.7143\n",
      "epoch:8/100\n",
      "****************************************************************************************************\n",
      "training: 0.9674, 0.6620\n",
      "validation: 1.0351, 0.6733\n",
      "epoch:9/100\n",
      "****************************************************************************************************\n",
      "training: 0.8618, 0.6990\n",
      "validation: 0.8251, 0.7063\n",
      "epoch:10/100\n",
      "****************************************************************************************************\n",
      "training: 0.8045, 0.7160\n",
      "validation: 0.8533, 0.7085\n",
      "epoch:11/100\n",
      "****************************************************************************************************\n",
      "training: 0.8539, 0.7050\n",
      "validation: 0.9529, 0.6724\n",
      "epoch:12/100\n",
      "****************************************************************************************************\n",
      "training: 0.7838, 0.7240\n",
      "validation: 0.6978, 0.7531\n",
      "epoch:13/100\n",
      "****************************************************************************************************\n",
      "training: 0.7537, 0.7320\n",
      "validation: 0.6739, 0.7752\n",
      "epoch:14/100\n",
      "****************************************************************************************************\n",
      "training: 0.7503, 0.7420\n",
      "validation: 0.8569, 0.7152\n",
      "epoch:15/100\n",
      "****************************************************************************************************\n",
      "training: 0.7412, 0.7460\n",
      "validation: 0.9812, 0.6596\n",
      "epoch:16/100\n",
      "****************************************************************************************************\n",
      "training: 0.6764, 0.7680\n",
      "validation: 0.7042, 0.7578\n",
      "epoch:17/100\n",
      "****************************************************************************************************\n",
      "training: 0.6382, 0.7890\n",
      "validation: 0.6705, 0.7865\n",
      "epoch:18/100\n",
      "****************************************************************************************************\n",
      "training: 0.6294, 0.7840\n",
      "validation: 0.5879, 0.8157\n",
      "epoch:19/100\n",
      "****************************************************************************************************\n",
      "training: 0.6380, 0.7690\n",
      "validation: 1.0203, 0.7081\n",
      "epoch:20/100\n",
      "****************************************************************************************************\n",
      "training: 0.6676, 0.7800\n",
      "validation: 0.7270, 0.7715\n",
      "epoch:21/100\n",
      "****************************************************************************************************\n",
      "training: 0.5813, 0.8120\n",
      "validation: 0.9103, 0.7294\n",
      "epoch:22/100\n",
      "****************************************************************************************************\n",
      "training: 0.6922, 0.7680\n",
      "validation: 0.6773, 0.7804\n",
      "epoch:23/100\n",
      "****************************************************************************************************\n",
      "training: 0.6567, 0.7770\n",
      "validation: 0.6855, 0.7789\n",
      "epoch:24/100\n",
      "****************************************************************************************************\n",
      "training: 0.6084, 0.7870\n",
      "validation: 0.6176, 0.8057\n",
      "epoch:25/100\n",
      "****************************************************************************************************\n",
      "training: 0.5229, 0.8220\n",
      "validation: 0.5606, 0.8091\n",
      "epoch:26/100\n",
      "****************************************************************************************************\n",
      "training: 0.4973, 0.8310\n",
      "validation: 0.5548, 0.8267\n",
      "epoch:27/100\n",
      "****************************************************************************************************\n",
      "training: 0.5250, 0.8190\n",
      "validation: 0.6201, 0.7930\n",
      "epoch:28/100\n",
      "****************************************************************************************************\n",
      "training: 0.5217, 0.8120\n",
      "validation: 0.5595, 0.8154\n",
      "epoch:29/100\n",
      "****************************************************************************************************\n",
      "training: 0.4883, 0.8270\n",
      "validation: 0.6292, 0.7961\n",
      "epoch:30/100\n",
      "****************************************************************************************************\n",
      "training: 0.5038, 0.8310\n",
      "validation: 0.5630, 0.8213\n",
      "epoch:31/100\n",
      "****************************************************************************************************\n",
      "training: 0.5620, 0.8050\n",
      "validation: 0.5790, 0.8096\n",
      "epoch:32/100\n",
      "****************************************************************************************************\n",
      "training: 0.4460, 0.8510\n",
      "validation: 0.5461, 0.8246\n",
      "epoch:33/100\n",
      "****************************************************************************************************\n",
      "training: 0.4635, 0.8410\n",
      "validation: 0.6562, 0.8070\n",
      "epoch:34/100\n",
      "****************************************************************************************************\n",
      "training: 0.4941, 0.8180\n",
      "validation: 0.5667, 0.8219\n",
      "epoch:35/100\n",
      "****************************************************************************************************\n",
      "training: 0.4954, 0.8290\n",
      "validation: 0.9495, 0.7265\n",
      "epoch:36/100\n",
      "****************************************************************************************************\n",
      "training: 0.4382, 0.8480\n",
      "validation: 0.5556, 0.8241\n",
      "epoch:37/100\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "## about model\n",
    "num_classes = 10\n",
    "model = baselineModel(num_classes)\n",
    "model.name = 'Resnet with 4 LKA layer'\n",
    "model.layer1 = Attention(64,64,64)\n",
    "model.layer2 = Attention(64,128,128)\n",
    "model.layer3 = Attention(128,256,256)\n",
    "model.layer4 = Attention(256,512,512)\n",
    "test_new_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100\n",
      "****************************************************************************************************\n",
      "training: 1.9901, 0.3490\n",
      "validation: 26.5236, 0.1098\n",
      "epoch:1/100\n",
      "****************************************************************************************************\n",
      "training: 1.4453, 0.4950\n",
      "validation: 37.9088, 0.1328\n",
      "epoch:2/100\n",
      "****************************************************************************************************\n",
      "training: 1.2622, 0.5540\n",
      "validation: 3.2240, 0.3854\n",
      "epoch:3/100\n",
      "****************************************************************************************************\n",
      "training: 1.2458, 0.5520\n",
      "validation: 2.1845, 0.4202\n",
      "epoch:4/100\n",
      "****************************************************************************************************\n",
      "training: 1.1488, 0.5830\n",
      "validation: 1.5308, 0.5469\n",
      "epoch:5/100\n",
      "****************************************************************************************************\n",
      "training: 1.1067, 0.6160\n",
      "validation: 1.7032, 0.4663\n",
      "epoch:6/100\n",
      "****************************************************************************************************\n",
      "training: 1.1140, 0.6080\n",
      "validation: 1.9303, 0.5350\n",
      "epoch:7/100\n",
      "****************************************************************************************************\n",
      "training: 1.1183, 0.6290\n",
      "validation: 2.8388, 0.3991\n",
      "epoch:8/100\n",
      "****************************************************************************************************\n",
      "training: 1.0079, 0.6530\n",
      "validation: 2.3303, 0.3922\n",
      "epoch:9/100\n",
      "****************************************************************************************************\n",
      "training: 1.0074, 0.6390\n",
      "validation: 3.2723, 0.3893\n",
      "epoch:10/100\n",
      "****************************************************************************************************\n",
      "training: 0.9666, 0.6830\n",
      "validation: 1.3629, 0.5974\n",
      "epoch:11/100\n",
      "****************************************************************************************************\n",
      "training: 0.9746, 0.6670\n",
      "validation: 1.1358, 0.6135\n",
      "epoch:12/100\n",
      "****************************************************************************************************\n",
      "training: 0.9914, 0.6540\n",
      "validation: 1.5337, 0.5319\n",
      "epoch:13/100\n",
      "****************************************************************************************************\n",
      "training: 0.9077, 0.6830\n",
      "validation: 1.0433, 0.6696\n",
      "epoch:14/100\n",
      "****************************************************************************************************\n",
      "training: 0.8861, 0.6860\n",
      "validation: 1.1846, 0.6124\n",
      "epoch:15/100\n",
      "****************************************************************************************************\n",
      "training: 0.9226, 0.6760\n",
      "validation: 1.5398, 0.5461\n",
      "epoch:16/100\n",
      "****************************************************************************************************\n",
      "training: 0.8556, 0.7070\n",
      "validation: 1.4723, 0.5815\n",
      "epoch:17/100\n",
      "****************************************************************************************************\n",
      "training: 0.8332, 0.7090\n",
      "validation: 1.3304, 0.5585\n",
      "epoch:18/100\n",
      "****************************************************************************************************\n",
      "training: 0.9152, 0.6950\n",
      "validation: 2.3542, 0.4428\n",
      "epoch:19/100\n",
      "****************************************************************************************************\n",
      "training: 0.8683, 0.6910\n",
      "validation: 0.9635, 0.6669\n",
      "epoch:20/100\n",
      "****************************************************************************************************\n",
      "training: 0.8358, 0.6920\n",
      "validation: 1.3268, 0.5835\n",
      "epoch:21/100\n",
      "****************************************************************************************************\n",
      "training: 0.8739, 0.6990\n",
      "validation: 1.2276, 0.6111\n",
      "epoch:22/100\n",
      "****************************************************************************************************\n",
      "training: 0.7989, 0.7240\n",
      "validation: 2.5500, 0.4428\n",
      "epoch:23/100\n",
      "****************************************************************************************************\n",
      "training: 0.8201, 0.7210\n",
      "validation: 0.9338, 0.6572\n",
      "epoch:24/100\n",
      "****************************************************************************************************\n",
      "training: 0.7948, 0.7290\n",
      "validation: 0.8586, 0.7161\n",
      "epoch:25/100\n",
      "****************************************************************************************************\n",
      "training: 0.7088, 0.7480\n",
      "validation: 0.9676, 0.6974\n",
      "epoch:26/100\n",
      "****************************************************************************************************\n",
      "training: 0.7525, 0.7370\n",
      "validation: 1.0070, 0.6783\n",
      "epoch:27/100\n",
      "****************************************************************************************************\n",
      "training: 0.7208, 0.7480\n",
      "validation: 1.0071, 0.6596\n",
      "epoch:28/100\n",
      "****************************************************************************************************\n",
      "training: 0.7551, 0.7210\n",
      "validation: 1.1587, 0.6611\n",
      "epoch:29/100\n",
      "****************************************************************************************************\n",
      "training: 0.7072, 0.7330\n",
      "validation: 1.4916, 0.6041\n",
      "epoch:30/100\n",
      "****************************************************************************************************\n",
      "training: 0.7314, 0.7400\n",
      "validation: 1.2983, 0.6244\n",
      "epoch:31/100\n",
      "****************************************************************************************************\n",
      "training: 0.7585, 0.7360\n",
      "validation: 1.8907, 0.5315\n",
      "epoch:32/100\n",
      "****************************************************************************************************\n",
      "training: 0.7254, 0.7440\n",
      "validation: 0.8428, 0.7361\n",
      "epoch:33/100\n",
      "****************************************************************************************************\n",
      "training: 0.7239, 0.7460\n",
      "validation: 1.1560, 0.6311\n",
      "epoch:34/100\n",
      "****************************************************************************************************\n",
      "training: 0.7273, 0.7400\n",
      "validation: 0.9287, 0.7106\n",
      "epoch:35/100\n",
      "****************************************************************************************************\n",
      "training: 0.6778, 0.7530\n",
      "validation: 0.8984, 0.7046\n",
      "epoch:36/100\n",
      "****************************************************************************************************\n",
      "training: 0.6203, 0.7880\n",
      "validation: 0.8330, 0.7365\n",
      "epoch:37/100\n",
      "****************************************************************************************************\n",
      "training: 0.6213, 0.7890\n",
      "validation: 0.9562, 0.7302\n",
      "epoch:38/100\n",
      "****************************************************************************************************\n",
      "training: 0.6334, 0.7790\n",
      "validation: 0.7633, 0.7496\n",
      "epoch:39/100\n",
      "****************************************************************************************************\n",
      "training: 0.6292, 0.7890\n",
      "validation: 0.9592, 0.7026\n",
      "epoch:40/100\n",
      "****************************************************************************************************\n",
      "training: 0.6364, 0.7850\n",
      "validation: 1.3175, 0.6169\n",
      "epoch:41/100\n",
      "****************************************************************************************************\n",
      "training: 0.6472, 0.7790\n",
      "validation: 0.8411, 0.7159\n",
      "epoch:42/100\n",
      "****************************************************************************************************\n",
      "training: 0.6264, 0.7830\n",
      "validation: 1.1130, 0.6485\n",
      "epoch:43/100\n",
      "****************************************************************************************************\n",
      "training: 0.6399, 0.7630\n",
      "validation: 0.8692, 0.7341\n",
      "epoch:44/100\n",
      "****************************************************************************************************\n",
      "training: 0.6189, 0.7760\n",
      "validation: 0.6873, 0.7817\n",
      "epoch:45/100\n",
      "****************************************************************************************************\n",
      "training: 0.5855, 0.8000\n",
      "validation: 0.8437, 0.7363\n",
      "epoch:46/100\n",
      "****************************************************************************************************\n",
      "training: 0.5465, 0.8030\n",
      "validation: 1.5598, 0.5444\n",
      "epoch:47/100\n",
      "****************************************************************************************************\n",
      "training: 0.5786, 0.8020\n",
      "validation: 0.7467, 0.7598\n",
      "epoch:48/100\n",
      "****************************************************************************************************\n",
      "training: 0.5460, 0.7990\n",
      "validation: 0.8367, 0.7381\n",
      "epoch:49/100\n",
      "****************************************************************************************************\n",
      "training: 0.5726, 0.7860\n",
      "validation: 1.0033, 0.7143\n",
      "epoch:50/100\n",
      "****************************************************************************************************\n",
      "training: 0.5260, 0.8170\n",
      "validation: 1.3129, 0.6530\n",
      "epoch:51/100\n",
      "****************************************************************************************************\n",
      "training: 0.5953, 0.7990\n",
      "validation: 0.7960, 0.7646\n",
      "epoch:52/100\n",
      "****************************************************************************************************\n",
      "training: 0.5469, 0.8120\n",
      "validation: 1.1530, 0.6674\n",
      "epoch:53/100\n",
      "****************************************************************************************************\n",
      "training: 0.5424, 0.8020\n",
      "validation: 0.7390, 0.7839\n",
      "epoch:54/100\n",
      "****************************************************************************************************\n",
      "training: 0.5024, 0.8210\n",
      "validation: 0.9894, 0.7065\n",
      "epoch:55/100\n",
      "****************************************************************************************************\n",
      "training: 0.5655, 0.7910\n",
      "validation: 0.9575, 0.7098\n",
      "epoch:56/100\n",
      "****************************************************************************************************\n",
      "training: 0.5667, 0.7970\n",
      "validation: 0.9077, 0.7081\n",
      "epoch:57/100\n",
      "****************************************************************************************************\n",
      "training: 0.4597, 0.8340\n",
      "validation: 1.1270, 0.6985\n",
      "epoch:58/100\n",
      "****************************************************************************************************\n",
      "training: 0.4823, 0.8310\n",
      "validation: 0.7321, 0.7657\n",
      "epoch:59/100\n",
      "****************************************************************************************************\n",
      "training: 0.5353, 0.7990\n",
      "validation: 0.8091, 0.7596\n",
      "epoch:60/100\n",
      "****************************************************************************************************\n",
      "training: 0.4930, 0.8320\n",
      "validation: 0.7289, 0.7700\n",
      "epoch:61/100\n",
      "****************************************************************************************************\n",
      "training: 0.5648, 0.8180\n",
      "validation: 0.6593, 0.7950\n",
      "epoch:62/100\n",
      "****************************************************************************************************\n",
      "training: 0.4931, 0.8150\n",
      "validation: 1.2346, 0.6800\n",
      "epoch:63/100\n",
      "****************************************************************************************************\n",
      "training: 0.4979, 0.8360\n",
      "validation: 0.7527, 0.7824\n",
      "epoch:64/100\n",
      "****************************************************************************************************\n",
      "training: 0.5264, 0.8050\n",
      "validation: 1.0689, 0.7037\n",
      "epoch:65/100\n",
      "****************************************************************************************************\n",
      "training: 0.4687, 0.8270\n",
      "validation: 0.7530, 0.7767\n",
      "epoch:66/100\n",
      "****************************************************************************************************\n",
      "training: 0.4385, 0.8520\n",
      "validation: 1.0729, 0.6970\n",
      "epoch:67/100\n",
      "****************************************************************************************************\n",
      "training: 0.3707, 0.8730\n",
      "validation: 0.8304, 0.7606\n",
      "epoch:68/100\n",
      "****************************************************************************************************\n",
      "training: 0.4460, 0.8390\n",
      "validation: 0.8133, 0.7663\n",
      "epoch:69/100\n",
      "****************************************************************************************************\n",
      "training: 0.4393, 0.8530\n",
      "validation: 0.8496, 0.7550\n",
      "epoch:70/100\n",
      "****************************************************************************************************\n",
      "training: 0.4923, 0.8300\n",
      "validation: 0.6913, 0.7994\n",
      "epoch:71/100\n",
      "****************************************************************************************************\n",
      "training: 0.3856, 0.8670\n",
      "validation: 1.2524, 0.6743\n",
      "epoch:72/100\n",
      "****************************************************************************************************\n",
      "training: 0.4136, 0.8640\n",
      "validation: 1.8030, 0.5817\n",
      "epoch:73/100\n",
      "****************************************************************************************************\n",
      "training: 0.5002, 0.8260\n",
      "validation: 0.7726, 0.7724\n",
      "epoch:74/100\n",
      "****************************************************************************************************\n",
      "training: 0.4590, 0.8470\n",
      "validation: 0.7509, 0.7878\n",
      "epoch:75/100\n",
      "****************************************************************************************************\n",
      "training: 0.4102, 0.8480\n",
      "validation: 0.8152, 0.7648\n",
      "epoch:76/100\n",
      "****************************************************************************************************\n",
      "training: 0.4571, 0.8480\n",
      "validation: 0.7396, 0.7637\n",
      "epoch:77/100\n",
      "****************************************************************************************************\n",
      "training: 0.4480, 0.8380\n",
      "validation: 1.5734, 0.6483\n",
      "epoch:78/100\n",
      "****************************************************************************************************\n",
      "training: 0.4663, 0.8360\n",
      "validation: 1.1145, 0.6924\n",
      "epoch:79/100\n",
      "****************************************************************************************************\n",
      "training: 0.4537, 0.8450\n",
      "validation: 0.8355, 0.7348\n",
      "epoch:80/100\n",
      "****************************************************************************************************\n",
      "training: 0.4171, 0.8450\n",
      "validation: 0.9200, 0.7420\n",
      "epoch:81/100\n",
      "****************************************************************************************************\n",
      "training: 0.4205, 0.8450\n",
      "validation: 0.7234, 0.7976\n",
      "epoch:82/100\n",
      "****************************************************************************************************\n",
      "training: 0.4511, 0.8420\n",
      "validation: 0.8824, 0.7441\n",
      "epoch:83/100\n",
      "****************************************************************************************************\n",
      "training: 0.3879, 0.8620\n",
      "validation: 0.7161, 0.7891\n",
      "epoch:84/100\n",
      "****************************************************************************************************\n",
      "training: 0.4117, 0.8600\n",
      "validation: 1.0232, 0.7246\n",
      "epoch:85/100\n",
      "****************************************************************************************************\n",
      "training: 0.3887, 0.8560\n",
      "validation: 0.6751, 0.8019\n",
      "epoch:86/100\n",
      "****************************************************************************************************\n",
      "training: 0.4057, 0.8580\n",
      "validation: 0.8000, 0.7656\n",
      "epoch:87/100\n",
      "****************************************************************************************************\n",
      "training: 0.3449, 0.8870\n",
      "validation: 0.6391, 0.8063\n",
      "epoch:88/100\n",
      "****************************************************************************************************\n",
      "training: 0.3280, 0.8720\n",
      "validation: 1.1380, 0.7165\n",
      "epoch:89/100\n",
      "****************************************************************************************************\n",
      "training: 0.4245, 0.8550\n",
      "validation: 1.0562, 0.6911\n",
      "epoch:90/100\n",
      "****************************************************************************************************\n",
      "training: 0.4790, 0.8250\n",
      "validation: 0.7999, 0.7707\n",
      "epoch:91/100\n",
      "****************************************************************************************************\n",
      "training: 0.4527, 0.8400\n",
      "validation: 0.8496, 0.7844\n",
      "epoch:92/100\n",
      "****************************************************************************************************\n",
      "training: 0.3920, 0.8580\n",
      "validation: 0.7283, 0.7854\n",
      "epoch:93/100\n",
      "****************************************************************************************************\n",
      "training: 0.3623, 0.8680\n",
      "validation: 0.6392, 0.8120\n",
      "epoch:94/100\n",
      "****************************************************************************************************\n",
      "training: 0.3614, 0.8770\n",
      "validation: 0.7921, 0.7667\n",
      "epoch:95/100\n",
      "****************************************************************************************************\n",
      "training: 0.3784, 0.8690\n",
      "validation: 0.6809, 0.7893\n",
      "epoch:96/100\n",
      "****************************************************************************************************\n",
      "training: 0.3786, 0.8650\n",
      "validation: 0.8856, 0.7326\n",
      "epoch:97/100\n",
      "****************************************************************************************************\n",
      "training: 0.4256, 0.8530\n",
      "validation: 0.5936, 0.8200\n",
      "epoch:98/100\n",
      "****************************************************************************************************\n",
      "training: 0.3675, 0.8740\n",
      "validation: 0.8711, 0.7370\n",
      "epoch:99/100\n",
      "****************************************************************************************************\n",
      "training: 0.3557, 0.8730\n",
      "validation: 0.6309, 0.8198\n"
     ]
    }
   ],
   "source": [
    "testBaselineModel()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6b347f591e985303f98a5578330a51eea0838d27215b123c4c1d58108c23409"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

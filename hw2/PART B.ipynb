{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 2 Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the torch cuda is ok\n",
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "## Note that: here we provide a basic solution for loading data and transforming data.\n",
    "## You can directly change it if you find something wrong or not good enough.\n",
    "\n",
    "## the mean and standard variance of imagenet dataset\n",
    "## mean_vals = [0.485, 0.456, 0.406]\n",
    "## std_vals = [0.229, 0.224, 0.225]\n",
    "\n",
    "def load_data(data_dir = \"dataset/\",input_size = 224,batch_size = 36):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    ## The default dir is for the first task of large-scale deep learning\n",
    "    ## For other tasks, you may need to modify the data dir or even rewrite some part of 'data.py'\n",
    "    image_dataset_train = datasets.ImageFolder(os.path.join(data_dir, '2-Medium-Scale', 'train'), data_transforms['train'])\n",
    "    image_dataset_valid = datasets.ImageFolder(os.path.join(data_dir,'test'), data_transforms['test'])\n",
    "\n",
    "    train_loader = DataLoader(image_dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    valid_loader = DataLoader(image_dataset_valid, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "# load the trained model\n",
    "def load_model(device,model_name,optimizer_name):\n",
    "    return torch.load(model_name+\" with \"+optimizer_name+ \" best_model.pt\",device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "def baselineModel(num_classes):\n",
    "    model_resnet = models.resnet18(pretrained=False)\n",
    "    num_features = model_resnet.fc.in_features\n",
    "    model_resnet.fc = nn.Linear(num_features, num_classes)\n",
    "    model_resnet.name = \"Medium-Scale Baseline Learning\"\n",
    "    return model_resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "## Note that: here we provide a basic solution for training and validation.\n",
    "## You can directly change it if you find something wrong or not good enough.\n",
    "\n",
    "def train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=20, logdir = 'logs_part_b'):\n",
    "    def train(model, train_loader,optimizer,criterion):\n",
    "        model.train(True)\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct += torch.sum(predictions == labels.data)\n",
    "\n",
    "        epoch_loss = total_loss / len(train_loader.dataset)\n",
    "        epoch_acc = total_correct.double() / len(train_loader.dataset)\n",
    "        return epoch_loss, epoch_acc.item()\n",
    "\n",
    "    def valid(model, valid_loader,criterion):\n",
    "        model.train(False)\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct += torch.sum(predictions == labels.data)\n",
    "        epoch_loss = total_loss / len(valid_loader.dataset)\n",
    "        epoch_acc = total_correct.double() / len(valid_loader.dataset)\n",
    "        return epoch_loss, epoch_acc.item()\n",
    "\n",
    "    best_acc = 0.0\n",
    "    train_loss_curves = []\n",
    "    train_acc_curves = []\n",
    "    valid_loss_curves = []\n",
    "    valid_acc_curves = []\n",
    "    writer = SummaryWriter(os.path.join(logdir,model.name + ' with ' + optimizer.name))\n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch:{:d}/{:d}'.format(epoch, num_epochs))\n",
    "        print('*' * 100)\n",
    "        train_loss, train_acc = train(model, train_loader,optimizer,criterion)\n",
    "        print(\"training: {:.4f}, {:.4f}\".format(train_loss, train_acc))\n",
    "        valid_loss, valid_acc = valid(model, valid_loader,criterion)\n",
    "        print(\"validation: {:.4f}, {:.4f}\".format(valid_loss, valid_acc))\n",
    "        train_acc_curves.append(train_acc)\n",
    "        train_loss_curves.append(train_loss)\n",
    "        valid_acc_curves.append(valid_acc)\n",
    "        valid_loss_curves.append(valid_loss)\n",
    "        writer.add_scalars(os.path.join(model.name+\" with \"+optimizer.name,'loss curves'),{'train':train_loss,'valid':valid_loss},epoch)\n",
    "        writer.add_scalars(os.path.join(model.name+\" with \"+optimizer.name,'acc curves'),{'train':train_acc,'valid':valid_acc},epoch)\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_model = model\n",
    "            torch.save(best_model, model.name+' with '+optimizer.name +' best_model.pt')\n",
    "    writer.close()\n",
    "    return train_loss_curves,train_acc_curves,valid_loss_curves,valid_acc_curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "class LKA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim:int\n",
    "        ) -> None :\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(dim, dim, 5, padding=2, groups=dim)\n",
    "        self.conv_spatial = nn.Conv2d(dim,dim,7,stride=1,padding=9,groups = dim ,dilation=3)\n",
    "        self.conv2 = nn.Conv2d(dim,dim,1)\n",
    "\n",
    "    def forward(self,x:Tensor) -> Tensor:\n",
    "        u=x.clone()\n",
    "        attn = self.conv1(x)\n",
    "        attn = self.conv_spatial(attn)\n",
    "        attn = self.conv2(attn)\n",
    "        return u*attn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        bottleneck_dim: int,\n",
    "        out_dim: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.proj_1 = nn.Conv2d(in_dim, bottleneck_dim, 1)\n",
    "        self.norm_layer_1 = nn.BatchNorm2d(bottleneck_dim)\n",
    "        self.activation = nn.GELU()\n",
    "        self.spatial_gating_unit = LKA(bottleneck_dim)\n",
    "        self.proj_2 = nn.Conv2d(bottleneck_dim, out_dim, 1)\n",
    "        self.norm_layer_2 = nn.BatchNorm2d(out_dim)\n",
    "        self.downsample = None if in_dim==out_dim else nn.Sequential(\n",
    "            nn.Conv2d(in_dim,out_dim,1),\n",
    "            nn.BatchNorm2d(out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x:Tensor)->Tensor:\n",
    "        out = self.proj_1(x)\n",
    "        out = self.norm_layer_1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.spatial_gating_unit(out)\n",
    "        out = self.norm_layer_2(out)\n",
    "        out = self.proj_2(out)\n",
    "        if (self.downsample is not None):\n",
    "            x=self.downsample(x)\n",
    "        out = out + x\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "# class Block(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         input_dim: int,\n",
    "        \n",
    "#         drop_path: float,\n",
    "#         act_layer: Optional[Callable[...,nn.Module]]=nn.GELU\n",
    "#     ) -> None:\n",
    "#         super().__init__()\n",
    "#         self.norm1=Bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testBaselineModel():\n",
    "    ## about model\n",
    "    num_classes = 10\n",
    "\n",
    "    ## about data\n",
    "    data_dir = \"dataset/\" ## You need to specify the data_dir first\n",
    "    input_size = 224\n",
    "    batch_size = 16\n",
    "\n",
    "    ## about training\n",
    "    num_epochs = 100\n",
    "    lr = 0.001\n",
    "\n",
    "    ## model initialization\n",
    "    model = baselineModel(num_classes=num_classes)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    ## data preparation\n",
    "    train_loader, valid_loader = load_data(data_dir=data_dir,input_size=input_size, batch_size=batch_size)\n",
    "\n",
    "    ## optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9,0.999))\n",
    "    optimizer.name = 'Adam'\n",
    "    ## loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loss_curves,train_acc_curves,valid_loss_curves,valid_acc_curves = train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_model(model):\n",
    "    ## about data\n",
    "    data_dir = \"dataset/\" ## You need to specify the data_dir first\n",
    "    input_size = 224\n",
    "    batch_size = 16\n",
    "\n",
    "    ## about training\n",
    "    num_epochs = 100\n",
    "    lr = 0.001\n",
    "\n",
    "    ## model initialization\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    ## data preparation\n",
    "    train_loader, valid_loader = load_data(data_dir=data_dir,input_size=input_size, batch_size=batch_size)\n",
    "\n",
    "    ## optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9,0.999))\n",
    "    optimizer.name = 'Adam'\n",
    "    ## loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loss_curves,train_acc_curves,valid_loss_curves,valid_acc_curves = train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.76 GiB total capacity; 9.46 GiB already allocated; 22.56 MiB free; 9.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sunzhangliang/DeepLearningStudy/hw2/PART B.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000008vscode-remote?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mlayer3 \u001b[39m=\u001b[39m Attention(\u001b[39m128\u001b[39m,\u001b[39m256\u001b[39m,\u001b[39m256\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000008vscode-remote?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mlayer4 \u001b[39m=\u001b[39m Attention(\u001b[39m256\u001b[39m,\u001b[39m512\u001b[39m,\u001b[39m512\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000008vscode-remote?line=8'>9</a>\u001b[0m test_new_model(model)\n",
      "\u001b[1;32m/home/sunzhangliang/DeepLearningStudy/hw2/PART B.ipynb Cell 8'\u001b[0m in \u001b[0;36mtest_new_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000007vscode-remote?line=19'>20</a>\u001b[0m \u001b[39m## loss function\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000007vscode-remote?line=20'>21</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000007vscode-remote?line=21'>22</a>\u001b[0m train_loss_curves,train_acc_curves,valid_loss_curves,valid_acc_curves \u001b[39m=\u001b[39m train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs\u001b[39m=\u001b[39;49mnum_epochs)\n",
      "\u001b[1;32m/home/sunzhangliang/DeepLearningStudy/hw2/PART B.ipynb Cell 5'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, valid_loader, criterion, optimizer, num_epochs, logdir)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mepoch:\u001b[39m\u001b[39m{:d}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{:d}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch, num_epochs))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=55'>56</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=56'>57</a>\u001b[0m train_loss, train_acc \u001b[39m=\u001b[39m train(model, train_loader,optimizer,criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtraining: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(train_loss, train_acc))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=58'>59</a>\u001b[0m valid_loss, valid_acc \u001b[39m=\u001b[39m valid(model, valid_loader,criterion)\n",
      "\u001b[1;32m/home/sunzhangliang/DeepLearningStudy/hw2/PART B.ipynb Cell 5'\u001b[0m in \u001b[0;36mtrain_model.<locals>.train\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=16'>17</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=18'>19</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000004vscode-remote?line=20'>21</a>\u001b[0m _, predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/torchvision/models/resnet.py:283\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torchvision/models/resnet.py?line=281'>282</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torchvision/models/resnet.py?line=282'>283</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/torchvision/models/resnet.py:272\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torchvision/models/resnet.py?line=268'>269</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torchvision/models/resnet.py?line=270'>271</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x)\n\u001b[0;32m--> <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torchvision/models/resnet.py?line=271'>272</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer2(x)\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torchvision/models/resnet.py?line=272'>273</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torchvision/models/resnet.py?line=273'>274</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer4(x)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/sunzhangliang/DeepLearningStudy/hw2/PART B.ipynb Cell 6'\u001b[0m in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000005vscode-remote?line=42'>43</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x:Tensor)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39mTensor:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000005vscode-remote?line=43'>44</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_1(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000005vscode-remote?line=44'>45</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_layer_1(out)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000005vscode-remote?line=45'>46</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(out)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewserver/home/sunzhangliang/DeepLearningStudy/hw2/PART%20B.ipynb#ch0000005vscode-remote?line=46'>47</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspatial_gating_unit(out)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=160'>161</a>\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=162'>163</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=163'>164</a>\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=164'>165</a>\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=165'>166</a>\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=166'>167</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=167'>168</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=168'>169</a>\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=169'>170</a>\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=170'>171</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=171'>172</a>\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=172'>173</a>\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=173'>174</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=174'>175</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=175'>176</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=176'>177</a>\u001b[0m     bn_training,\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=177'>178</a>\u001b[0m     exponential_average_factor,\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=178'>179</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=179'>180</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/functional.py:2421\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/functional.py?line=2417'>2418</a>\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/functional.py?line=2418'>2419</a>\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/functional.py?line=2420'>2421</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/functional.py?line=2421'>2422</a>\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   <a href='file:///home/sunzhangliang/.conda/envs/deeplearning/lib/python3.8/site-packages/torch/nn/functional.py?line=2422'>2423</a>\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.76 GiB total capacity; 9.46 GiB already allocated; 22.56 MiB free; 9.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "## about model\n",
    "num_classes = 10\n",
    "model = baselineModel(num_classes)\n",
    "model.name = 'Resnet with 4 LKA layer'\n",
    "model.layer1 = Attention(64,64,64)\n",
    "model.layer2 = Attention(64,128,128)\n",
    "model.layer3 = Attention(128,256,256)\n",
    "model.layer4 = Attention(256,512,512)\n",
    "test_new_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100\n",
      "****************************************************************************************************\n",
      "training: 1.9901, 0.3490\n",
      "validation: 26.5236, 0.1098\n",
      "epoch:1/100\n",
      "****************************************************************************************************\n",
      "training: 1.4453, 0.4950\n",
      "validation: 37.9088, 0.1328\n",
      "epoch:2/100\n",
      "****************************************************************************************************\n",
      "training: 1.2622, 0.5540\n",
      "validation: 3.2240, 0.3854\n",
      "epoch:3/100\n",
      "****************************************************************************************************\n",
      "training: 1.2458, 0.5520\n",
      "validation: 2.1845, 0.4202\n",
      "epoch:4/100\n",
      "****************************************************************************************************\n",
      "training: 1.1488, 0.5830\n",
      "validation: 1.5308, 0.5469\n",
      "epoch:5/100\n",
      "****************************************************************************************************\n",
      "training: 1.1067, 0.6160\n",
      "validation: 1.7032, 0.4663\n",
      "epoch:6/100\n",
      "****************************************************************************************************\n",
      "training: 1.1140, 0.6080\n",
      "validation: 1.9303, 0.5350\n",
      "epoch:7/100\n",
      "****************************************************************************************************\n",
      "training: 1.1183, 0.6290\n",
      "validation: 2.8388, 0.3991\n",
      "epoch:8/100\n",
      "****************************************************************************************************\n",
      "training: 1.0079, 0.6530\n",
      "validation: 2.3303, 0.3922\n",
      "epoch:9/100\n",
      "****************************************************************************************************\n",
      "training: 1.0074, 0.6390\n",
      "validation: 3.2723, 0.3893\n",
      "epoch:10/100\n",
      "****************************************************************************************************\n",
      "training: 0.9666, 0.6830\n",
      "validation: 1.3629, 0.5974\n",
      "epoch:11/100\n",
      "****************************************************************************************************\n",
      "training: 0.9746, 0.6670\n",
      "validation: 1.1358, 0.6135\n",
      "epoch:12/100\n",
      "****************************************************************************************************\n",
      "training: 0.9914, 0.6540\n",
      "validation: 1.5337, 0.5319\n",
      "epoch:13/100\n",
      "****************************************************************************************************\n",
      "training: 0.9077, 0.6830\n",
      "validation: 1.0433, 0.6696\n",
      "epoch:14/100\n",
      "****************************************************************************************************\n",
      "training: 0.8861, 0.6860\n",
      "validation: 1.1846, 0.6124\n",
      "epoch:15/100\n",
      "****************************************************************************************************\n",
      "training: 0.9226, 0.6760\n",
      "validation: 1.5398, 0.5461\n",
      "epoch:16/100\n",
      "****************************************************************************************************\n",
      "training: 0.8556, 0.7070\n",
      "validation: 1.4723, 0.5815\n",
      "epoch:17/100\n",
      "****************************************************************************************************\n",
      "training: 0.8332, 0.7090\n",
      "validation: 1.3304, 0.5585\n",
      "epoch:18/100\n",
      "****************************************************************************************************\n",
      "training: 0.9152, 0.6950\n",
      "validation: 2.3542, 0.4428\n",
      "epoch:19/100\n",
      "****************************************************************************************************\n",
      "training: 0.8683, 0.6910\n",
      "validation: 0.9635, 0.6669\n",
      "epoch:20/100\n",
      "****************************************************************************************************\n",
      "training: 0.8358, 0.6920\n",
      "validation: 1.3268, 0.5835\n",
      "epoch:21/100\n",
      "****************************************************************************************************\n",
      "training: 0.8739, 0.6990\n",
      "validation: 1.2276, 0.6111\n",
      "epoch:22/100\n",
      "****************************************************************************************************\n",
      "training: 0.7989, 0.7240\n",
      "validation: 2.5500, 0.4428\n",
      "epoch:23/100\n",
      "****************************************************************************************************\n",
      "training: 0.8201, 0.7210\n",
      "validation: 0.9338, 0.6572\n",
      "epoch:24/100\n",
      "****************************************************************************************************\n",
      "training: 0.7948, 0.7290\n",
      "validation: 0.8586, 0.7161\n",
      "epoch:25/100\n",
      "****************************************************************************************************\n",
      "training: 0.7088, 0.7480\n",
      "validation: 0.9676, 0.6974\n",
      "epoch:26/100\n",
      "****************************************************************************************************\n",
      "training: 0.7525, 0.7370\n",
      "validation: 1.0070, 0.6783\n",
      "epoch:27/100\n",
      "****************************************************************************************************\n",
      "training: 0.7208, 0.7480\n",
      "validation: 1.0071, 0.6596\n",
      "epoch:28/100\n",
      "****************************************************************************************************\n",
      "training: 0.7551, 0.7210\n",
      "validation: 1.1587, 0.6611\n",
      "epoch:29/100\n",
      "****************************************************************************************************\n",
      "training: 0.7072, 0.7330\n",
      "validation: 1.4916, 0.6041\n",
      "epoch:30/100\n",
      "****************************************************************************************************\n",
      "training: 0.7314, 0.7400\n",
      "validation: 1.2983, 0.6244\n",
      "epoch:31/100\n",
      "****************************************************************************************************\n",
      "training: 0.7585, 0.7360\n",
      "validation: 1.8907, 0.5315\n",
      "epoch:32/100\n",
      "****************************************************************************************************\n",
      "training: 0.7254, 0.7440\n",
      "validation: 0.8428, 0.7361\n",
      "epoch:33/100\n",
      "****************************************************************************************************\n",
      "training: 0.7239, 0.7460\n",
      "validation: 1.1560, 0.6311\n",
      "epoch:34/100\n",
      "****************************************************************************************************\n",
      "training: 0.7273, 0.7400\n",
      "validation: 0.9287, 0.7106\n",
      "epoch:35/100\n",
      "****************************************************************************************************\n",
      "training: 0.6778, 0.7530\n",
      "validation: 0.8984, 0.7046\n",
      "epoch:36/100\n",
      "****************************************************************************************************\n",
      "training: 0.6203, 0.7880\n",
      "validation: 0.8330, 0.7365\n",
      "epoch:37/100\n",
      "****************************************************************************************************\n",
      "training: 0.6213, 0.7890\n",
      "validation: 0.9562, 0.7302\n",
      "epoch:38/100\n",
      "****************************************************************************************************\n",
      "training: 0.6334, 0.7790\n",
      "validation: 0.7633, 0.7496\n",
      "epoch:39/100\n",
      "****************************************************************************************************\n",
      "training: 0.6292, 0.7890\n",
      "validation: 0.9592, 0.7026\n",
      "epoch:40/100\n",
      "****************************************************************************************************\n",
      "training: 0.6364, 0.7850\n",
      "validation: 1.3175, 0.6169\n",
      "epoch:41/100\n",
      "****************************************************************************************************\n",
      "training: 0.6472, 0.7790\n",
      "validation: 0.8411, 0.7159\n",
      "epoch:42/100\n",
      "****************************************************************************************************\n",
      "training: 0.6264, 0.7830\n",
      "validation: 1.1130, 0.6485\n",
      "epoch:43/100\n",
      "****************************************************************************************************\n",
      "training: 0.6399, 0.7630\n",
      "validation: 0.8692, 0.7341\n",
      "epoch:44/100\n",
      "****************************************************************************************************\n",
      "training: 0.6189, 0.7760\n",
      "validation: 0.6873, 0.7817\n",
      "epoch:45/100\n",
      "****************************************************************************************************\n",
      "training: 0.5855, 0.8000\n",
      "validation: 0.8437, 0.7363\n",
      "epoch:46/100\n",
      "****************************************************************************************************\n",
      "training: 0.5465, 0.8030\n",
      "validation: 1.5598, 0.5444\n",
      "epoch:47/100\n",
      "****************************************************************************************************\n",
      "training: 0.5786, 0.8020\n",
      "validation: 0.7467, 0.7598\n",
      "epoch:48/100\n",
      "****************************************************************************************************\n",
      "training: 0.5460, 0.7990\n",
      "validation: 0.8367, 0.7381\n",
      "epoch:49/100\n",
      "****************************************************************************************************\n",
      "training: 0.5726, 0.7860\n",
      "validation: 1.0033, 0.7143\n",
      "epoch:50/100\n",
      "****************************************************************************************************\n",
      "training: 0.5260, 0.8170\n",
      "validation: 1.3129, 0.6530\n",
      "epoch:51/100\n",
      "****************************************************************************************************\n",
      "training: 0.5953, 0.7990\n",
      "validation: 0.7960, 0.7646\n",
      "epoch:52/100\n",
      "****************************************************************************************************\n",
      "training: 0.5469, 0.8120\n",
      "validation: 1.1530, 0.6674\n",
      "epoch:53/100\n",
      "****************************************************************************************************\n",
      "training: 0.5424, 0.8020\n",
      "validation: 0.7390, 0.7839\n",
      "epoch:54/100\n",
      "****************************************************************************************************\n",
      "training: 0.5024, 0.8210\n",
      "validation: 0.9894, 0.7065\n",
      "epoch:55/100\n",
      "****************************************************************************************************\n",
      "training: 0.5655, 0.7910\n",
      "validation: 0.9575, 0.7098\n",
      "epoch:56/100\n",
      "****************************************************************************************************\n",
      "training: 0.5667, 0.7970\n",
      "validation: 0.9077, 0.7081\n",
      "epoch:57/100\n",
      "****************************************************************************************************\n",
      "training: 0.4597, 0.8340\n",
      "validation: 1.1270, 0.6985\n",
      "epoch:58/100\n",
      "****************************************************************************************************\n",
      "training: 0.4823, 0.8310\n",
      "validation: 0.7321, 0.7657\n",
      "epoch:59/100\n",
      "****************************************************************************************************\n",
      "training: 0.5353, 0.7990\n",
      "validation: 0.8091, 0.7596\n",
      "epoch:60/100\n",
      "****************************************************************************************************\n",
      "training: 0.4930, 0.8320\n",
      "validation: 0.7289, 0.7700\n",
      "epoch:61/100\n",
      "****************************************************************************************************\n",
      "training: 0.5648, 0.8180\n",
      "validation: 0.6593, 0.7950\n",
      "epoch:62/100\n",
      "****************************************************************************************************\n",
      "training: 0.4931, 0.8150\n",
      "validation: 1.2346, 0.6800\n",
      "epoch:63/100\n",
      "****************************************************************************************************\n",
      "training: 0.4979, 0.8360\n",
      "validation: 0.7527, 0.7824\n",
      "epoch:64/100\n",
      "****************************************************************************************************\n",
      "training: 0.5264, 0.8050\n",
      "validation: 1.0689, 0.7037\n",
      "epoch:65/100\n",
      "****************************************************************************************************\n",
      "training: 0.4687, 0.8270\n",
      "validation: 0.7530, 0.7767\n",
      "epoch:66/100\n",
      "****************************************************************************************************\n",
      "training: 0.4385, 0.8520\n",
      "validation: 1.0729, 0.6970\n",
      "epoch:67/100\n",
      "****************************************************************************************************\n",
      "training: 0.3707, 0.8730\n",
      "validation: 0.8304, 0.7606\n",
      "epoch:68/100\n",
      "****************************************************************************************************\n",
      "training: 0.4460, 0.8390\n",
      "validation: 0.8133, 0.7663\n",
      "epoch:69/100\n",
      "****************************************************************************************************\n",
      "training: 0.4393, 0.8530\n",
      "validation: 0.8496, 0.7550\n",
      "epoch:70/100\n",
      "****************************************************************************************************\n",
      "training: 0.4923, 0.8300\n",
      "validation: 0.6913, 0.7994\n",
      "epoch:71/100\n",
      "****************************************************************************************************\n",
      "training: 0.3856, 0.8670\n",
      "validation: 1.2524, 0.6743\n",
      "epoch:72/100\n",
      "****************************************************************************************************\n",
      "training: 0.4136, 0.8640\n",
      "validation: 1.8030, 0.5817\n",
      "epoch:73/100\n",
      "****************************************************************************************************\n",
      "training: 0.5002, 0.8260\n",
      "validation: 0.7726, 0.7724\n",
      "epoch:74/100\n",
      "****************************************************************************************************\n",
      "training: 0.4590, 0.8470\n",
      "validation: 0.7509, 0.7878\n",
      "epoch:75/100\n",
      "****************************************************************************************************\n",
      "training: 0.4102, 0.8480\n",
      "validation: 0.8152, 0.7648\n",
      "epoch:76/100\n",
      "****************************************************************************************************\n",
      "training: 0.4571, 0.8480\n",
      "validation: 0.7396, 0.7637\n",
      "epoch:77/100\n",
      "****************************************************************************************************\n",
      "training: 0.4480, 0.8380\n",
      "validation: 1.5734, 0.6483\n",
      "epoch:78/100\n",
      "****************************************************************************************************\n",
      "training: 0.4663, 0.8360\n",
      "validation: 1.1145, 0.6924\n",
      "epoch:79/100\n",
      "****************************************************************************************************\n",
      "training: 0.4537, 0.8450\n",
      "validation: 0.8355, 0.7348\n",
      "epoch:80/100\n",
      "****************************************************************************************************\n",
      "training: 0.4171, 0.8450\n",
      "validation: 0.9200, 0.7420\n",
      "epoch:81/100\n",
      "****************************************************************************************************\n",
      "training: 0.4205, 0.8450\n",
      "validation: 0.7234, 0.7976\n",
      "epoch:82/100\n",
      "****************************************************************************************************\n",
      "training: 0.4511, 0.8420\n",
      "validation: 0.8824, 0.7441\n",
      "epoch:83/100\n",
      "****************************************************************************************************\n",
      "training: 0.3879, 0.8620\n",
      "validation: 0.7161, 0.7891\n",
      "epoch:84/100\n",
      "****************************************************************************************************\n",
      "training: 0.4117, 0.8600\n",
      "validation: 1.0232, 0.7246\n",
      "epoch:85/100\n",
      "****************************************************************************************************\n",
      "training: 0.3887, 0.8560\n",
      "validation: 0.6751, 0.8019\n",
      "epoch:86/100\n",
      "****************************************************************************************************\n",
      "training: 0.4057, 0.8580\n",
      "validation: 0.8000, 0.7656\n",
      "epoch:87/100\n",
      "****************************************************************************************************\n",
      "training: 0.3449, 0.8870\n",
      "validation: 0.6391, 0.8063\n",
      "epoch:88/100\n",
      "****************************************************************************************************\n",
      "training: 0.3280, 0.8720\n",
      "validation: 1.1380, 0.7165\n",
      "epoch:89/100\n",
      "****************************************************************************************************\n",
      "training: 0.4245, 0.8550\n",
      "validation: 1.0562, 0.6911\n",
      "epoch:90/100\n",
      "****************************************************************************************************\n",
      "training: 0.4790, 0.8250\n",
      "validation: 0.7999, 0.7707\n",
      "epoch:91/100\n",
      "****************************************************************************************************\n",
      "training: 0.4527, 0.8400\n",
      "validation: 0.8496, 0.7844\n",
      "epoch:92/100\n",
      "****************************************************************************************************\n",
      "training: 0.3920, 0.8580\n",
      "validation: 0.7283, 0.7854\n",
      "epoch:93/100\n",
      "****************************************************************************************************\n",
      "training: 0.3623, 0.8680\n",
      "validation: 0.6392, 0.8120\n",
      "epoch:94/100\n",
      "****************************************************************************************************\n",
      "training: 0.3614, 0.8770\n",
      "validation: 0.7921, 0.7667\n",
      "epoch:95/100\n",
      "****************************************************************************************************\n",
      "training: 0.3784, 0.8690\n",
      "validation: 0.6809, 0.7893\n",
      "epoch:96/100\n",
      "****************************************************************************************************\n",
      "training: 0.3786, 0.8650\n",
      "validation: 0.8856, 0.7326\n",
      "epoch:97/100\n",
      "****************************************************************************************************\n",
      "training: 0.4256, 0.8530\n",
      "validation: 0.5936, 0.8200\n",
      "epoch:98/100\n",
      "****************************************************************************************************\n",
      "training: 0.3675, 0.8740\n",
      "validation: 0.8711, 0.7370\n",
      "epoch:99/100\n",
      "****************************************************************************************************\n",
      "training: 0.3557, 0.8730\n",
      "validation: 0.6309, 0.8198\n"
     ]
    }
   ],
   "source": [
    "testBaselineModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "model = models.resnet18()\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6b347f591e985303f98a5578330a51eea0838d27215b123c4c1d58108c23409"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

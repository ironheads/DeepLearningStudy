{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 2 Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the torch cuda is ok\n",
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "## Note that: here we provide a basic solution for loading data and transforming data.\n",
    "## You can directly change it if you find something wrong or not good enough.\n",
    "\n",
    "## the mean and standard variance of imagenet dataset\n",
    "## mean_vals = [0.485, 0.456, 0.406]\n",
    "## std_vals = [0.229, 0.224, 0.225]\n",
    "\n",
    "def load_data(data_dir = \"dataset/\",input_size = 224,batch_size = 36):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    ## The default dir is for the first task of large-scale deep learning\n",
    "    ## For other tasks, you may need to modify the data dir or even rewrite some part of 'data.py'\n",
    "    image_dataset_train = datasets.ImageFolder(os.path.join(data_dir, '2-Medium-Scale', 'train'), data_transforms['train'])\n",
    "    image_dataset_valid = datasets.ImageFolder(os.path.join(data_dir,'test'), data_transforms['test'])\n",
    "\n",
    "    train_loader = DataLoader(image_dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    valid_loader = DataLoader(image_dataset_valid, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "# load the trained model\n",
    "def load_model(device,model_name,optimizer_name):\n",
    "    return torch.load(model_name+\" with \"+optimizer_name+ \" best_model.pt\",device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "def baselineModel(num_classes):\n",
    "    model_resnet = models.resnet18(pretrained=False)\n",
    "    num_features = model_resnet.fc.in_features\n",
    "    model_resnet.fc = nn.Linear(num_features, num_classes)\n",
    "    model_resnet.name = \"Medium-Scale Baseline Learning\"\n",
    "    return model_resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "## Note that: here we provide a basic solution for training and validation.\n",
    "## You can directly change it if you find something wrong or not good enough.\n",
    "\n",
    "def train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=20, logdir = 'logs_part_b'):\n",
    "    def train(model, train_loader,optimizer,criterion):\n",
    "        model.train(True)\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct += torch.sum(predictions == labels.data)\n",
    "\n",
    "        epoch_loss = total_loss / len(train_loader.dataset)\n",
    "        epoch_acc = total_correct.double() / len(train_loader.dataset)\n",
    "        return epoch_loss, epoch_acc.item()\n",
    "\n",
    "    def valid(model, valid_loader,criterion):\n",
    "        model.train(False)\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct += torch.sum(predictions == labels.data)\n",
    "        epoch_loss = total_loss / len(valid_loader.dataset)\n",
    "        epoch_acc = total_correct.double() / len(valid_loader.dataset)\n",
    "        return epoch_loss, epoch_acc.item()\n",
    "\n",
    "    best_acc = 0.0\n",
    "    train_loss_curves = []\n",
    "    train_acc_curves = []\n",
    "    valid_loss_curves = []\n",
    "    valid_acc_curves = []\n",
    "    writer = SummaryWriter(os.path.join(logdir,model.name + ' with ' + optimizer.name))\n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch:{:d}/{:d}'.format(epoch, num_epochs))\n",
    "        print('*' * 100)\n",
    "        train_loss, train_acc = train(model, train_loader,optimizer,criterion)\n",
    "        print(\"training: {:.4f}, {:.4f}\".format(train_loss, train_acc))\n",
    "        valid_loss, valid_acc = valid(model, valid_loader,criterion)\n",
    "        print(\"validation: {:.4f}, {:.4f}\".format(valid_loss, valid_acc))\n",
    "        train_acc_curves.append(train_acc)\n",
    "        train_loss_curves.append(train_loss)\n",
    "        valid_acc_curves.append(valid_acc)\n",
    "        valid_loss_curves.append(valid_loss)\n",
    "        writer.add_scalars(os.path.join(model.name+\" with \"+optimizer.name,'loss curves'),{'train':train_loss,'valid':valid_loss},epoch)\n",
    "        writer.add_scalars(os.path.join(model.name+\" with \"+optimizer.name,'acc curves'),{'train':train_acc,'valid':valid_acc},epoch)\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_model = model\n",
    "            torch.save(best_model, model.name+' with '+optimizer.name +' best_model.pt')\n",
    "    writer.close()\n",
    "    return train_loss_curves,train_acc_curves,valid_loss_curves,valid_acc_curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "model = models.resnet18()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "class LKA(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim:int\n",
    "        ) -> None :\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(dim, dim, 5, padding=2, groups=dim)\n",
    "        self.conv_spatial = nn.Conv2d(dim,dim,7,stride=1,padding=9,groups = dim ,dilation=3)\n",
    "        self.conv2 = nn.Conv2d(dim,dim,1)\n",
    "\n",
    "    def forward(self,x:Tensor) -> Tensor:\n",
    "        u=x.clone()\n",
    "        attn = self.conv1(x)\n",
    "        attn = self.conv_spatial(attn)\n",
    "        attn = self.conv2(attn)\n",
    "        return u*attn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BasicLKALayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim\n",
    "    ) -> None:\n",
    "        super().__init__();\n",
    "        if norm_layer is None:\n",
    "            norm_layer=nn.BatchNorm2d\n",
    "        self.proj_1 = nn.Conv2d(dim, dim, 1)\n",
    "        self.activation = nn.GELU()\n",
    "        self.spatial_gating_unit = LKA(dim)\n",
    "        self.proj_2 = nn.Conv2d(dim, dim, 1)\n",
    "    \n",
    "    def forward(self,x:Tensor)->Tensor:\n",
    "        shorcut = x.clone()\n",
    "        x = self.proj_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.spatial_gating_unit(x)\n",
    "        x = self.proj_2(x)\n",
    "        x = x + shorcut\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testBaselineModel():\n",
    "    ## about model\n",
    "    num_classes = 10\n",
    "\n",
    "    ## about data\n",
    "    data_dir = \"dataset/\" ## You need to specify the data_dir first\n",
    "    input_size = 224\n",
    "    batch_size = 128\n",
    "\n",
    "    ## about training\n",
    "    num_epochs = 100\n",
    "    lr = 0.001\n",
    "\n",
    "    ## model initialization\n",
    "    model = baselineModel(num_classes=num_classes)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    ## data preparation\n",
    "    train_loader, valid_loader = load_data(data_dir=data_dir,input_size=input_size, batch_size=batch_size)\n",
    "\n",
    "    ## optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    optimizer.name = 'SGD'\n",
    "    ## loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loss_curves,train_acc_curves,valid_loss_curves,valid_acc_curves = train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0/100\n",
      "****************************************************************************************************\n",
      "training: 2.2195, 0.1560\n",
      "validation: 2.2609, 0.2020\n",
      "epoch:1/100\n",
      "****************************************************************************************************\n",
      "training: 2.0212, 0.3270\n",
      "validation: 2.2131, 0.1659\n",
      "epoch:2/100\n",
      "****************************************************************************************************\n",
      "training: 1.8308, 0.4240\n",
      "validation: 2.0539, 0.3011\n",
      "epoch:3/100\n",
      "****************************************************************************************************\n",
      "training: 1.6913, 0.4530\n",
      "validation: 1.8140, 0.4059\n",
      "epoch:4/100\n",
      "****************************************************************************************************\n",
      "training: 1.5788, 0.4840\n",
      "validation: 1.6117, 0.4915\n",
      "epoch:5/100\n",
      "****************************************************************************************************\n",
      "training: 1.4756, 0.5250\n",
      "validation: 1.5147, 0.5291\n",
      "epoch:6/100\n",
      "****************************************************************************************************\n",
      "training: 1.3807, 0.5690\n",
      "validation: 1.3966, 0.5531\n",
      "epoch:7/100\n",
      "****************************************************************************************************\n",
      "training: 1.3007, 0.5810\n",
      "validation: 1.3634, 0.5607\n",
      "epoch:8/100\n",
      "****************************************************************************************************\n",
      "training: 1.2746, 0.5860\n",
      "validation: 1.4483, 0.5159\n",
      "epoch:9/100\n",
      "****************************************************************************************************\n",
      "training: 1.1924, 0.6130\n",
      "validation: 1.3451, 0.5452\n",
      "epoch:10/100\n",
      "****************************************************************************************************\n",
      "training: 1.1531, 0.6180\n",
      "validation: 1.2257, 0.6048\n",
      "epoch:11/100\n",
      "****************************************************************************************************\n",
      "training: 1.1085, 0.6340\n",
      "validation: 1.4411, 0.5091\n",
      "epoch:12/100\n",
      "****************************************************************************************************\n",
      "training: 1.1147, 0.6280\n",
      "validation: 1.2953, 0.5628\n",
      "epoch:13/100\n",
      "****************************************************************************************************\n",
      "training: 1.0708, 0.6320\n",
      "validation: 1.1282, 0.6024\n",
      "epoch:14/100\n",
      "****************************************************************************************************\n",
      "training: 1.0494, 0.6450\n",
      "validation: 1.3045, 0.5557\n",
      "epoch:15/100\n",
      "****************************************************************************************************\n",
      "training: 1.0337, 0.6760\n",
      "validation: 1.2078, 0.5776\n",
      "epoch:16/100\n",
      "****************************************************************************************************\n",
      "training: 0.9895, 0.6720\n",
      "validation: 1.5321, 0.4344\n",
      "epoch:17/100\n",
      "****************************************************************************************************\n",
      "training: 0.9761, 0.6590\n",
      "validation: 1.2002, 0.5967\n",
      "epoch:18/100\n",
      "****************************************************************************************************\n",
      "training: 0.9393, 0.6690\n",
      "validation: 1.2770, 0.5570\n",
      "epoch:19/100\n",
      "****************************************************************************************************\n",
      "training: 0.9579, 0.6650\n",
      "validation: 1.0743, 0.6237\n",
      "epoch:20/100\n",
      "****************************************************************************************************\n",
      "training: 0.9651, 0.6570\n",
      "validation: 1.0823, 0.6391\n",
      "epoch:21/100\n",
      "****************************************************************************************************\n",
      "training: 0.8985, 0.6850\n",
      "validation: 0.9812, 0.6672\n",
      "epoch:22/100\n",
      "****************************************************************************************************\n",
      "training: 0.8705, 0.7150\n",
      "validation: 0.9989, 0.6676\n",
      "epoch:23/100\n",
      "****************************************************************************************************\n",
      "training: 0.8781, 0.7100\n",
      "validation: 1.0260, 0.6609\n",
      "epoch:24/100\n",
      "****************************************************************************************************\n",
      "training: 0.8679, 0.6900\n",
      "validation: 1.1509, 0.5887\n",
      "epoch:25/100\n",
      "****************************************************************************************************\n",
      "training: 0.8851, 0.7130\n",
      "validation: 1.1971, 0.6230\n",
      "epoch:26/100\n",
      "****************************************************************************************************\n",
      "training: 0.8358, 0.7120\n",
      "validation: 1.1363, 0.6109\n",
      "epoch:27/100\n",
      "****************************************************************************************************\n",
      "training: 0.8413, 0.7020\n",
      "validation: 1.1241, 0.6343\n",
      "epoch:28/100\n",
      "****************************************************************************************************\n",
      "training: 0.8261, 0.7070\n",
      "validation: 0.9663, 0.6761\n",
      "epoch:29/100\n",
      "****************************************************************************************************\n",
      "training: 0.8195, 0.7110\n",
      "validation: 0.9791, 0.6857\n",
      "epoch:30/100\n",
      "****************************************************************************************************\n",
      "training: 0.8198, 0.7180\n",
      "validation: 0.9765, 0.6724\n",
      "epoch:31/100\n",
      "****************************************************************************************************\n",
      "training: 0.7835, 0.7390\n",
      "validation: 1.1347, 0.6044\n",
      "epoch:32/100\n",
      "****************************************************************************************************\n",
      "training: 0.7989, 0.7270\n",
      "validation: 1.0796, 0.6706\n",
      "epoch:33/100\n",
      "****************************************************************************************************\n",
      "training: 0.7829, 0.7360\n",
      "validation: 0.8919, 0.6920\n",
      "epoch:34/100\n",
      "****************************************************************************************************\n",
      "training: 0.7526, 0.7560\n",
      "validation: 1.0258, 0.6685\n",
      "epoch:35/100\n",
      "****************************************************************************************************\n",
      "training: 0.7576, 0.7500\n",
      "validation: 1.0688, 0.6324\n",
      "epoch:36/100\n",
      "****************************************************************************************************\n",
      "training: 0.7322, 0.7540\n",
      "validation: 0.9626, 0.6731\n",
      "epoch:37/100\n",
      "****************************************************************************************************\n",
      "training: 0.7582, 0.7460\n",
      "validation: 0.9617, 0.6783\n",
      "epoch:38/100\n",
      "****************************************************************************************************\n",
      "training: 0.7496, 0.7530\n",
      "validation: 1.0222, 0.6519\n",
      "epoch:39/100\n",
      "****************************************************************************************************\n",
      "training: 0.7115, 0.7600\n",
      "validation: 1.0339, 0.6548\n",
      "epoch:40/100\n",
      "****************************************************************************************************\n",
      "training: 0.7654, 0.7450\n",
      "validation: 0.8968, 0.7046\n",
      "epoch:41/100\n",
      "****************************************************************************************************\n",
      "training: 0.7287, 0.7450\n",
      "validation: 0.8906, 0.6956\n",
      "epoch:42/100\n",
      "****************************************************************************************************\n",
      "training: 0.7252, 0.7440\n",
      "validation: 1.0772, 0.6413\n",
      "epoch:43/100\n",
      "****************************************************************************************************\n",
      "training: 0.7348, 0.7380\n",
      "validation: 0.8936, 0.6765\n",
      "epoch:44/100\n",
      "****************************************************************************************************\n",
      "training: 0.6765, 0.7580\n",
      "validation: 1.0071, 0.6576\n",
      "epoch:45/100\n",
      "****************************************************************************************************\n",
      "training: 0.6997, 0.7610\n",
      "validation: 0.9558, 0.6883\n",
      "epoch:46/100\n",
      "****************************************************************************************************\n",
      "training: 0.6147, 0.8000\n",
      "validation: 0.9345, 0.6881\n",
      "epoch:47/100\n",
      "****************************************************************************************************\n",
      "training: 0.6378, 0.7830\n",
      "validation: 0.8682, 0.7169\n",
      "epoch:48/100\n",
      "****************************************************************************************************\n",
      "training: 0.6050, 0.8130\n",
      "validation: 0.9222, 0.6900\n",
      "epoch:49/100\n",
      "****************************************************************************************************\n",
      "training: 0.6209, 0.7920\n",
      "validation: 0.7917, 0.7407\n",
      "epoch:50/100\n",
      "****************************************************************************************************\n",
      "training: 0.6113, 0.7970\n",
      "validation: 0.8340, 0.7167\n",
      "epoch:51/100\n",
      "****************************************************************************************************\n",
      "training: 0.6413, 0.7790\n",
      "validation: 0.8049, 0.7393\n",
      "epoch:52/100\n",
      "****************************************************************************************************\n",
      "training: 0.5904, 0.7950\n",
      "validation: 0.8270, 0.7291\n",
      "epoch:53/100\n",
      "****************************************************************************************************\n",
      "training: 0.6024, 0.7790\n",
      "validation: 0.8854, 0.7165\n",
      "epoch:54/100\n",
      "****************************************************************************************************\n",
      "training: 0.6139, 0.7890\n",
      "validation: 0.8392, 0.7302\n",
      "epoch:55/100\n",
      "****************************************************************************************************\n",
      "training: 0.6042, 0.8020\n",
      "validation: 0.7879, 0.7328\n",
      "epoch:56/100\n",
      "****************************************************************************************************\n",
      "training: 0.6111, 0.7780\n",
      "validation: 1.2134, 0.6072\n",
      "epoch:57/100\n",
      "****************************************************************************************************\n",
      "training: 0.5878, 0.8000\n",
      "validation: 0.8113, 0.7369\n",
      "epoch:58/100\n",
      "****************************************************************************************************\n",
      "training: 0.5711, 0.8010\n",
      "validation: 0.7623, 0.7443\n",
      "epoch:59/100\n",
      "****************************************************************************************************\n",
      "training: 0.5788, 0.8090\n",
      "validation: 0.9514, 0.7043\n",
      "epoch:60/100\n",
      "****************************************************************************************************\n",
      "training: 0.6509, 0.7750\n",
      "validation: 0.9481, 0.6919\n",
      "epoch:61/100\n",
      "****************************************************************************************************\n",
      "training: 0.6208, 0.7900\n",
      "validation: 0.8323, 0.7302\n",
      "epoch:62/100\n",
      "****************************************************************************************************\n",
      "training: 0.5393, 0.8090\n",
      "validation: 0.9376, 0.6980\n",
      "epoch:63/100\n",
      "****************************************************************************************************\n",
      "training: 0.6061, 0.7970\n",
      "validation: 1.0845, 0.6441\n",
      "epoch:64/100\n",
      "****************************************************************************************************\n",
      "training: 0.5707, 0.8010\n",
      "validation: 0.8374, 0.7215\n",
      "epoch:65/100\n",
      "****************************************************************************************************\n",
      "training: 0.5950, 0.7940\n",
      "validation: 0.8353, 0.7230\n",
      "epoch:66/100\n",
      "****************************************************************************************************\n",
      "training: 0.5387, 0.8090\n",
      "validation: 0.8104, 0.7413\n",
      "epoch:67/100\n",
      "****************************************************************************************************\n",
      "training: 0.5785, 0.8050\n",
      "validation: 0.8759, 0.7172\n",
      "epoch:68/100\n",
      "****************************************************************************************************\n",
      "training: 0.6184, 0.7860\n",
      "validation: 0.7828, 0.7448\n",
      "epoch:69/100\n",
      "****************************************************************************************************\n",
      "training: 0.5404, 0.8100\n",
      "validation: 0.8749, 0.7328\n",
      "epoch:70/100\n",
      "****************************************************************************************************\n",
      "training: 0.5423, 0.8130\n",
      "validation: 0.7605, 0.7511\n",
      "epoch:71/100\n",
      "****************************************************************************************************\n",
      "training: 0.5531, 0.8110\n",
      "validation: 1.4053, 0.5720\n",
      "epoch:72/100\n",
      "****************************************************************************************************\n",
      "training: 0.5534, 0.8210\n",
      "validation: 0.6934, 0.7807\n",
      "epoch:73/100\n",
      "****************************************************************************************************\n",
      "training: 0.5756, 0.8020\n",
      "validation: 0.8099, 0.7394\n",
      "epoch:74/100\n",
      "****************************************************************************************************\n",
      "training: 0.5238, 0.8290\n",
      "validation: 0.7310, 0.7624\n",
      "epoch:75/100\n",
      "****************************************************************************************************\n",
      "training: 0.4993, 0.8200\n",
      "validation: 0.7927, 0.7576\n",
      "epoch:76/100\n",
      "****************************************************************************************************\n",
      "training: 0.4981, 0.8280\n",
      "validation: 0.8185, 0.7324\n",
      "epoch:77/100\n",
      "****************************************************************************************************\n",
      "training: 0.4999, 0.8230\n",
      "validation: 0.8593, 0.7354\n",
      "epoch:78/100\n",
      "****************************************************************************************************\n",
      "training: 0.5057, 0.8280\n",
      "validation: 0.8166, 0.7459\n",
      "epoch:79/100\n",
      "****************************************************************************************************\n",
      "training: 0.5246, 0.8160\n",
      "validation: 0.8001, 0.7443\n",
      "epoch:80/100\n",
      "****************************************************************************************************\n",
      "training: 0.4604, 0.8480\n",
      "validation: 0.9806, 0.6817\n",
      "epoch:81/100\n",
      "****************************************************************************************************\n",
      "training: 0.4844, 0.8390\n",
      "validation: 0.8280, 0.7389\n",
      "epoch:82/100\n",
      "****************************************************************************************************\n",
      "training: 0.5122, 0.8150\n",
      "validation: 1.2492, 0.6102\n",
      "epoch:83/100\n",
      "****************************************************************************************************\n",
      "training: 0.5151, 0.8270\n",
      "validation: 0.7281, 0.7752\n",
      "epoch:84/100\n",
      "****************************************************************************************************\n",
      "training: 0.4754, 0.8380\n",
      "validation: 0.8232, 0.7304\n",
      "epoch:85/100\n",
      "****************************************************************************************************\n",
      "training: 0.5026, 0.8300\n",
      "validation: 0.9094, 0.7396\n",
      "epoch:86/100\n",
      "****************************************************************************************************\n",
      "training: 0.4693, 0.8400\n",
      "validation: 0.8832, 0.7131\n",
      "epoch:87/100\n",
      "****************************************************************************************************\n",
      "training: 0.4499, 0.8560\n",
      "validation: 0.8576, 0.7233\n",
      "epoch:88/100\n",
      "****************************************************************************************************\n",
      "training: 0.4831, 0.8310\n",
      "validation: 0.7265, 0.7665\n",
      "epoch:89/100\n",
      "****************************************************************************************************\n",
      "training: 0.4386, 0.8580\n",
      "validation: 0.7390, 0.7726\n",
      "epoch:90/100\n",
      "****************************************************************************************************\n",
      "training: 0.4625, 0.8440\n",
      "validation: 0.8688, 0.7431\n",
      "epoch:91/100\n",
      "****************************************************************************************************\n",
      "training: 0.4818, 0.8320\n",
      "validation: 0.7896, 0.7541\n",
      "epoch:92/100\n",
      "****************************************************************************************************\n",
      "training: 0.4389, 0.8500\n",
      "validation: 0.7513, 0.7615\n",
      "epoch:93/100\n",
      "****************************************************************************************************\n",
      "training: 0.4247, 0.8530\n",
      "validation: 0.8349, 0.7402\n",
      "epoch:94/100\n",
      "****************************************************************************************************\n",
      "training: 0.4363, 0.8500\n",
      "validation: 0.8718, 0.7300\n",
      "epoch:95/100\n",
      "****************************************************************************************************\n",
      "training: 0.4443, 0.8500\n",
      "validation: 0.7900, 0.7631\n",
      "epoch:96/100\n",
      "****************************************************************************************************\n",
      "training: 0.4578, 0.8450\n",
      "validation: 0.7543, 0.7702\n",
      "epoch:97/100\n",
      "****************************************************************************************************\n",
      "training: 0.4421, 0.8480\n",
      "validation: 0.7612, 0.7644\n",
      "epoch:98/100\n",
      "****************************************************************************************************\n",
      "training: 0.4701, 0.8350\n",
      "validation: 1.0239, 0.6733\n",
      "epoch:99/100\n",
      "****************************************************************************************************\n",
      "training: 0.4650, 0.8480\n",
      "validation: 0.7100, 0.7826\n"
     ]
    }
   ],
   "source": [
    "testBaselineModel()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6b347f591e985303f98a5578330a51eea0838d27215b123c4c1d58108c23409"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

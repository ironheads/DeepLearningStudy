{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 2 Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the torch cuda is ok\n",
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "def create_model(args):\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc=nn.Linear(in_features,args.num_classes)\n",
    "    model.name = \"resnet18\"\n",
    "    # print(args.device)\n",
    "    model.to(args.device)\n",
    "    criteria_x = nn.CrossEntropyLoss().to(args.device)\n",
    "    criteria_u = nn.CrossEntropyLoss(reduction='none').to(args.device)\n",
    "    return model,criteria_x,criteria_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(gpu_id=0,\n",
       "          num_workers=4,\n",
       "          dataset='dataset',\n",
       "          num_labeled=250,\n",
       "          expand_labels=True,\n",
       "          arch='resnet',\n",
       "          total_steps=1048576,\n",
       "          eval_steps=1024,\n",
       "          start_epoch=0,\n",
       "          batch_size=64,\n",
       "          lr=0.03,\n",
       "          warmu=0,\n",
       "          wdecay=0.0005,\n",
       "          momentum=0.9,\n",
       "          nesterov=True,\n",
       "          use_ema=True,\n",
       "          ema_decay=0.999,\n",
       "          mu=7,\n",
       "          lambda_u=1,\n",
       "          T=1,\n",
       "          threshold=0.95,\n",
       "          out='result',\n",
       "          resume='resume',\n",
       "          seed=None,\n",
       "          local_rank=-1,\n",
       "          no_progress=False,\n",
       "          input_size=224,\n",
       "          num_classes=10,\n",
       "          num_images_per_epoch=16384,\n",
       "          num_epoches=128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import types \n",
    "args=types.SimpleNamespace()\n",
    "\n",
    "args.gpu_id = 0\n",
    "args.num_workers = 4\n",
    "args.dataset = 'dataset'\n",
    "args.num_labeled = 250\n",
    "args.expand_labels = True\n",
    "args.arch = 'resnet'\n",
    "args.total_steps = 2**20\n",
    "args.eval_steps = 1024\n",
    "args.start_epoch = 0\n",
    "args.batch_size = 64\n",
    "args.lr = 0.03\n",
    "args.warmu = 0\n",
    "args.wdecay = 5e-4\n",
    "args.momentum = 0.9\n",
    "args.nesterov = True\n",
    "args.use_ema = True\n",
    "args.ema_decay = 0.999\n",
    "args.mu = 7\n",
    "args.lambda_u = 1\n",
    "args.T = 1\n",
    "args.threshold = 0.95 \n",
    "args.out = 'result'\n",
    "args.resume = 'resume'\n",
    "args.seed = None\n",
    "# args.amp = True\n",
    "# args.opt_level = '01'\n",
    "args.local_rank = -1\n",
    "args.no_progress = False\n",
    "args.input_size = 224\n",
    "args.num_classes = 10\n",
    "args.num_images_per_epoch = 2**14\n",
    "args.num_epoches = 128\n",
    "\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.local_rank == -1:\n",
    "    device = torch.device('cuda', args.gpu_id)\n",
    "    args.world_size = 1\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device('cuda', args.local_rank)\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "    args.world_size = torch.distributed.get_world_size()\n",
    "    args.n_gpu = 1\n",
    "\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## aug functions\n",
    "def identity_func(img):\n",
    "    return img\n",
    "\n",
    "\n",
    "def autocontrast_func(img, cutoff=0):\n",
    "    '''\n",
    "        same output as PIL.ImageOps.autocontrast\n",
    "    '''\n",
    "    n_bins = 256\n",
    "\n",
    "    def tune_channel(ch):\n",
    "        n = ch.size\n",
    "        cut = cutoff * n // 100\n",
    "        if cut == 0:\n",
    "            high, low = ch.max(), ch.min()\n",
    "        else:\n",
    "            hist = cv2.calcHist([ch], [0], None, [n_bins], [0, n_bins])\n",
    "            low = np.argwhere(np.cumsum(hist) > cut)\n",
    "            low = 0 if low.shape[0] == 0 else low[0]\n",
    "            high = np.argwhere(np.cumsum(hist[::-1]) > cut)\n",
    "            high = n_bins - 1 if high.shape[0] == 0 else n_bins - 1 - high[0]\n",
    "        if high <= low:\n",
    "            table = np.arange(n_bins)\n",
    "        else:\n",
    "            scale = (n_bins - 1) / (high - low)\n",
    "            offset = -low * scale\n",
    "            table = np.arange(n_bins) * scale + offset\n",
    "            table[table < 0] = 0\n",
    "            table[table > n_bins - 1] = n_bins - 1\n",
    "        table = table.clip(0, 255).astype(np.uint8)\n",
    "        return table[ch]\n",
    "\n",
    "    channels = [tune_channel(ch) for ch in cv2.split(img)]\n",
    "    out = cv2.merge(channels)\n",
    "    return out\n",
    "\n",
    "\n",
    "def equalize_func(img):\n",
    "    '''\n",
    "        same output as PIL.ImageOps.equalize\n",
    "        PIL's implementation is different from cv2.equalize\n",
    "    '''\n",
    "    n_bins = 256\n",
    "\n",
    "    def tune_channel(ch):\n",
    "        hist = cv2.calcHist([ch], [0], None, [n_bins], [0, n_bins])\n",
    "        non_zero_hist = hist[hist != 0].reshape(-1)\n",
    "        step = np.sum(non_zero_hist[:-1]) // (n_bins - 1)\n",
    "        if step == 0: return ch\n",
    "        n = np.empty_like(hist)\n",
    "        n[0] = step // 2\n",
    "        n[1:] = hist[:-1]\n",
    "        table = (np.cumsum(n) // step).clip(0, 255).astype(np.uint8)\n",
    "        return table[ch]\n",
    "\n",
    "    channels = [tune_channel(ch) for ch in cv2.split(img)]\n",
    "    out = cv2.merge(channels)\n",
    "    return out\n",
    "\n",
    "\n",
    "def rotate_func(img, degree, fill=(0, 0, 0)):\n",
    "    '''\n",
    "    like PIL, rotate by degree, not radians\n",
    "    '''\n",
    "    H, W = img.shape[0], img.shape[1]\n",
    "    center = W / 2, H / 2\n",
    "    M = cv2.getRotationMatrix2D(center, degree, 1)\n",
    "    out = cv2.warpAffine(img, M, (W, H), borderValue=fill)\n",
    "    return out\n",
    "\n",
    "\n",
    "def solarize_func(img, thresh=128):\n",
    "    '''\n",
    "        same output as PIL.ImageOps.posterize\n",
    "    '''\n",
    "    table = np.array([el if el < thresh else 255 - el for el in range(256)])\n",
    "    table = table.clip(0, 255).astype(np.uint8)\n",
    "    out = table[img]\n",
    "    return out\n",
    "\n",
    "\n",
    "def color_func(img, factor):\n",
    "    '''\n",
    "        same output as PIL.ImageEnhance.Color\n",
    "    '''\n",
    "    ## implementation according to PIL definition, quite slow\n",
    "    #  degenerate = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)[:, :, np.newaxis]\n",
    "    #  out = blend(degenerate, img, factor)\n",
    "    #  M = (\n",
    "    #      np.eye(3) * factor\n",
    "    #      + np.float32([0.114, 0.587, 0.299]).reshape(3, 1) * (1. - factor)\n",
    "    #  )[np.newaxis, np.newaxis, :]\n",
    "    M = (\n",
    "            np.float32([\n",
    "                [0.886, -0.114, -0.114],\n",
    "                [-0.587, 0.413, -0.587],\n",
    "                [-0.299, -0.299, 0.701]]) * factor\n",
    "            + np.float32([[0.114], [0.587], [0.299]])\n",
    "    )\n",
    "    out = np.matmul(img, M).clip(0, 255).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "def contrast_func(img, factor):\n",
    "    \"\"\"\n",
    "        same output as PIL.ImageEnhance.Contrast\n",
    "    \"\"\"\n",
    "    mean = np.sum(np.mean(img, axis=(0, 1)) * np.array([0.114, 0.587, 0.299]))\n",
    "    table = np.array([(\n",
    "        el - mean) * factor + mean\n",
    "        for el in range(256)\n",
    "    ]).clip(0, 255).astype(np.uint8)\n",
    "    out = table[img]\n",
    "    return out\n",
    "\n",
    "\n",
    "def brightness_func(img, factor):\n",
    "    '''\n",
    "        same output as PIL.ImageEnhance.Contrast\n",
    "    '''\n",
    "    table = (np.arange(256, dtype=np.float32) * factor).clip(0, 255).astype(np.uint8)\n",
    "    out = table[img]\n",
    "    return out\n",
    "\n",
    "\n",
    "def sharpness_func(img, factor):\n",
    "    '''\n",
    "    The differences the this result and PIL are all on the 4 boundaries, the center\n",
    "    areas are same\n",
    "    '''\n",
    "    kernel = np.ones((3, 3), dtype=np.float32)\n",
    "    kernel[1][1] = 5\n",
    "    kernel /= 13\n",
    "    degenerate = cv2.filter2D(img, -1, kernel)\n",
    "    if factor == 0.0:\n",
    "        out = degenerate\n",
    "    elif factor == 1.0:\n",
    "        out = img\n",
    "    else:\n",
    "        out = img.astype(np.float32)\n",
    "        degenerate = degenerate.astype(np.float32)[1:-1, 1:-1, :]\n",
    "        out[1:-1, 1:-1, :] = degenerate + factor * (out[1:-1, 1:-1, :] - degenerate)\n",
    "        out = out.astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "def shear_x_func(img, factor, fill=(0, 0, 0)):\n",
    "    H, W = img.shape[0], img.shape[1]\n",
    "    M = np.float32([[1, factor, 0], [0, 1, 0]])\n",
    "    out = cv2.warpAffine(img, M, (W, H), borderValue=fill, flags=cv2.INTER_LINEAR).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "def translate_x_func(img, offset, fill=(0, 0, 0)):\n",
    "    '''\n",
    "        same output as PIL.Image.transform\n",
    "    '''\n",
    "    H, W = img.shape[0], img.shape[1]\n",
    "    M = np.float32([[1, 0, -offset], [0, 1, 0]])\n",
    "    out = cv2.warpAffine(img, M, (W, H), borderValue=fill, flags=cv2.INTER_LINEAR).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "def translate_y_func(img, offset, fill=(0, 0, 0)):\n",
    "    '''\n",
    "        same output as PIL.Image.transform\n",
    "    '''\n",
    "    H, W = img.shape[0], img.shape[1]\n",
    "    M = np.float32([[1, 0, 0], [0, 1, -offset]])\n",
    "    out = cv2.warpAffine(img, M, (W, H), borderValue=fill, flags=cv2.INTER_LINEAR).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "def posterize_func(img, bits):\n",
    "    '''\n",
    "        same output as PIL.ImageOps.posterize\n",
    "    '''\n",
    "    out = np.bitwise_and(img, np.uint8(255 << (8 - bits)))\n",
    "    return out\n",
    "\n",
    "\n",
    "def shear_y_func(img, factor, fill=(0, 0, 0)):\n",
    "    H, W = img.shape[0], img.shape[1]\n",
    "    M = np.float32([[1, 0, 0], [factor, 1, 0]])\n",
    "    out = cv2.warpAffine(img, M, (W, H), borderValue=fill, flags=cv2.INTER_LINEAR).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "def cutout_func(img, pad_size, replace=(0, 0, 0)):\n",
    "    replace = np.array(replace, dtype=np.uint8)\n",
    "    H, W = img.shape[0], img.shape[1]\n",
    "    rh, rw = np.random.random(2)\n",
    "    pad_size = pad_size // 2\n",
    "    ch, cw = int(rh * H), int(rw * W)\n",
    "    x1, x2 = max(ch - pad_size, 0), min(ch + pad_size, H)\n",
    "    y1, y2 = max(cw - pad_size, 0), min(cw + pad_size, W)\n",
    "    out = img.copy()\n",
    "    out[x1:x2, y1:y2, :] = replace\n",
    "    return out\n",
    "\n",
    "\n",
    "### level to args\n",
    "def enhance_level_to_args(MAX_LEVEL):\n",
    "    def level_to_args(level):\n",
    "        return ((level / MAX_LEVEL) * 1.8 + 0.1,)\n",
    "    return level_to_args\n",
    "\n",
    "\n",
    "def shear_level_to_args(MAX_LEVEL, replace_value):\n",
    "    def level_to_args(level):\n",
    "        level = (level / MAX_LEVEL) * 0.3\n",
    "        if np.random.random() > 0.5: level = -level\n",
    "        return (level, replace_value)\n",
    "\n",
    "    return level_to_args\n",
    "\n",
    "\n",
    "def translate_level_to_args(translate_const, MAX_LEVEL, replace_value):\n",
    "    def level_to_args(level):\n",
    "        level = (level / MAX_LEVEL) * float(translate_const)\n",
    "        if np.random.random() > 0.5: level = -level\n",
    "        return (level, replace_value)\n",
    "\n",
    "    return level_to_args\n",
    "\n",
    "\n",
    "def cutout_level_to_args(cutout_const, MAX_LEVEL, replace_value):\n",
    "    def level_to_args(level):\n",
    "        level = int((level / MAX_LEVEL) * cutout_const)\n",
    "        return (level, replace_value)\n",
    "\n",
    "    return level_to_args\n",
    "\n",
    "\n",
    "def solarize_level_to_args(MAX_LEVEL):\n",
    "    def level_to_args(level):\n",
    "        level = int((level / MAX_LEVEL) * 256)\n",
    "        return (level, )\n",
    "    return level_to_args\n",
    "\n",
    "\n",
    "def none_level_to_args(level):\n",
    "    return ()\n",
    "\n",
    "\n",
    "def posterize_level_to_args(MAX_LEVEL):\n",
    "    def level_to_args(level):\n",
    "        level = int((level / MAX_LEVEL) * 4)\n",
    "        return (level, )\n",
    "    return level_to_args\n",
    "\n",
    "\n",
    "def rotate_level_to_args(MAX_LEVEL, replace_value):\n",
    "    def level_to_args(level):\n",
    "        level = (level / MAX_LEVEL) * 30\n",
    "        if np.random.random() < 0.5:\n",
    "            level = -level\n",
    "        return (level, replace_value)\n",
    "\n",
    "    return level_to_args\n",
    "\n",
    "\n",
    "func_dict = {\n",
    "    'Identity': identity_func,\n",
    "    'AutoContrast': autocontrast_func,\n",
    "    'Equalize': equalize_func,\n",
    "    'Rotate': rotate_func,\n",
    "    'Solarize': solarize_func,\n",
    "    'Color': color_func,\n",
    "    'Contrast': contrast_func,\n",
    "    'Brightness': brightness_func,\n",
    "    'Sharpness': sharpness_func,\n",
    "    'ShearX': shear_x_func,\n",
    "    'TranslateX': translate_x_func,\n",
    "    'TranslateY': translate_y_func,\n",
    "    'Posterize': posterize_func,\n",
    "    'ShearY': shear_y_func,\n",
    "}\n",
    "\n",
    "translate_const = 10\n",
    "MAX_LEVEL = 10\n",
    "replace_value = (128, 128, 128)\n",
    "arg_dict = {\n",
    "    'Identity': none_level_to_args,\n",
    "    'AutoContrast': none_level_to_args,\n",
    "    'Equalize': none_level_to_args,\n",
    "    'Rotate': rotate_level_to_args(MAX_LEVEL, replace_value),\n",
    "    'Solarize': solarize_level_to_args(MAX_LEVEL),\n",
    "    'Color': enhance_level_to_args(MAX_LEVEL),\n",
    "    'Contrast': enhance_level_to_args(MAX_LEVEL),\n",
    "    'Brightness': enhance_level_to_args(MAX_LEVEL),\n",
    "    'Sharpness': enhance_level_to_args(MAX_LEVEL),\n",
    "    'ShearX': shear_level_to_args(MAX_LEVEL, replace_value),\n",
    "    'TranslateX': translate_level_to_args(\n",
    "        translate_const, MAX_LEVEL, replace_value\n",
    "    ),\n",
    "    'TranslateY': translate_level_to_args(\n",
    "        translate_const, MAX_LEVEL, replace_value\n",
    "    ),\n",
    "    'Posterize': posterize_level_to_args(MAX_LEVEL),\n",
    "    'ShearY': shear_level_to_args(MAX_LEVEL, replace_value),\n",
    "}\n",
    "\n",
    "\n",
    "class RandomAugment(object):\n",
    "\n",
    "    def __init__(self, N=2, M=10):\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "\n",
    "    def get_random_ops(self):\n",
    "        sampled_ops = np.random.choice(list(func_dict.keys()), self.N)\n",
    "        return [(op, 0.5, self.M) for op in sampled_ops]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        ops = self.get_random_ops()\n",
    "        for name, prob, level in ops:\n",
    "            if np.random.random() > prob:\n",
    "                continue\n",
    "            args = arg_dict[name](level)\n",
    "            img = func_dict[name](img, *args)\n",
    "        img = cutout_func(img, 16, replace_value)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self,dataset:Dataset,args,is_train=True):\n",
    "        super().__init__()\n",
    "        self.dataset=dataset\n",
    "        self.is_train=is_train\n",
    "        self.input_size = args.input_size\n",
    "        if self.is_train:\n",
    "            self.trans_weak = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(self.input_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            self.trans_strong = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(self.input_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                RandomAugment(2,10),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(self.input_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    def __getitem__(self,index):\n",
    "        image,label = self.dataset[index]\n",
    "        # image=np.array(image)\n",
    "        # print(image.shape)\n",
    "        if self.is_train:\n",
    "            return self.trans_weak(image),self.trans_strong(image),label\n",
    "        else:\n",
    "            return self.trans(image),label\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self,image_dir,args,is_train=True) ->None:\n",
    "        super().__init__()\n",
    "        self.image_dir = image_dir\n",
    "        self.image_name =os.listdir(self.image_dir)\n",
    "        self.is_train = is_train\n",
    "        self.input_size = args.input_size\n",
    "        if self.is_train:\n",
    "            self.trans_weak = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(self.input_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            self.trans_strong = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(self.input_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                RandomAugment(2,10),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(self.input_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        image_item_name = self.image_name[index]\n",
    "        image_item_path = os.path.join(self.image_dir,image_item_name)\n",
    "        image = Image.open(image_item_path)\n",
    "        # image=np.array(image)\n",
    "        label = 'unlabeled'\n",
    "        if self.is_train:\n",
    "            return self.trans_weak(image),self.trans_strong(image),label\n",
    "        else:\n",
    "            return self.trans(image),label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "\"\"\"\n",
    "为什么 param 和 buffer 要采用不同的的更新策略\n",
    "param 是 指数移动平均数，buffer 不是\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class EMA(object):\n",
    "    def __init__(self, model, alpha=0.999):\n",
    "        self.step = 0\n",
    "        self.model = model\n",
    "        self.alpha = alpha\n",
    "        self.shadow = self.get_model_state()\n",
    "        self.backup = {}\n",
    "        self.param_keys = [k for k, _ in self.model.named_parameters()]\n",
    "        # num_batches_tracked, running_mean, running_var in bn\n",
    "        self.buffer_keys = [k for k, _ in self.model.named_buffers()]\n",
    "\n",
    "    def update_params(self):\n",
    "        # decay = min(self.alpha, (self.step + 1) / (self.step + 10))  # ????\n",
    "        decay = self.alpha\n",
    "        state = self.model.state_dict()  # current params\n",
    "        for name in self.param_keys:\n",
    "            self.shadow[name].copy_(\n",
    "                decay * self.shadow[name] + (1 - decay) * state[name]\n",
    "            )\n",
    "        # for name in self.buffer_keys:\n",
    "        #     self.shadow[name].copy_(\n",
    "        #         decay * self.shadow[name]\n",
    "        #         + (1 - decay) * state[name]\n",
    "        #     )\n",
    "\n",
    "        self.step += 1\n",
    "\n",
    "    def update_buffer(self):\n",
    "        # without EMA\n",
    "        state = self.model.state_dict()\n",
    "        for name in self.buffer_keys:\n",
    "            self.shadow[name].copy_(state[name])\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        self.backup = self.get_model_state()\n",
    "        self.model.load_state_dict(self.shadow)\n",
    "\n",
    "    def restore(self):\n",
    "        self.model.load_state_dict(self.backup)\n",
    "\n",
    "    def get_model_state(self):\n",
    "        return {\n",
    "            k: v.clone().detach()\n",
    "            for k, v in self.model.state_dict().items()\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, RandomSampler, BatchSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "def get_train_loader(args):\n",
    "    num_iters_per_epoch = args.num_images_per_epoch // args.batch_size\n",
    "    datasetPath = os.path.join(args.dataset,'3-Semi-Supervised')\n",
    "    labeledDatasetPath = os.path.join(datasetPath,'labeled')\n",
    "    unlabeledDatasetPath = os.path.join(datasetPath,'unlabeled')\n",
    "    labeledDataset = datasets.ImageFolder(labeledDatasetPath)\n",
    "    unlabeledDataset = UnlabeledDataset(unlabeledDatasetPath,args)\n",
    "    labeledDataset = LabeledDataset(labeledDataset,args)\n",
    "    sampler_x = RandomSampler(labeledDataset, replacement=True, num_samples=num_iters_per_epoch * args.batch_size)\n",
    "    batch_sampler_x = BatchSampler(sampler_x, args.batch_size, drop_last=True)  # yield a batch of samples one time\n",
    "    labeledDatasetDataloader = DataLoader(\n",
    "        labeledDataset,\n",
    "        batch_sampler=batch_sampler_x,\n",
    "        num_workers = args.num_workers\n",
    "    )\n",
    "    sampler_u = RandomSampler(unlabeledDataset, replacement=True, num_samples=args.mu * num_iters_per_epoch * args.batch_size)\n",
    "    batch_sampler_u = BatchSampler(sampler_u, args.batch_size * args.mu, drop_last=True)\n",
    "    unlabeledDatasetDataloader = DataLoader(\n",
    "        unlabeledDataset,\n",
    "        batch_sampler=batch_sampler_u,\n",
    "        num_workers = args.num_workers\n",
    "    )\n",
    "    return labeledDatasetDataloader,unlabeledDatasetDataloader\n",
    "\n",
    "\n",
    "def get_valid_loader(args):\n",
    "    testDataset = datasets.ImageFolder(os.path.join(args.dataset,'test'))\n",
    "    testDataset = LabeledDataset(testDataset,args,is_train=False)\n",
    "    validDatasetDataloader = DataLoader(\n",
    "        testDataset,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        batch_size = 128,\n",
    "        num_workers = args.num_workers\n",
    "    )\n",
    "    return validDatasetDataloader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import _LRScheduler, LambdaLR\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WarmupExpLrScheduler(_LRScheduler):\n",
    "    def __init__(\n",
    "            self,\n",
    "            optimizer,\n",
    "            power,\n",
    "            step_interval=1,\n",
    "            warmup_iter=500,\n",
    "            warmup_ratio=5e-4,\n",
    "            warmup='exp',\n",
    "            last_epoch=-1,\n",
    "    ):\n",
    "        self.power = power\n",
    "        self.step_interval = step_interval\n",
    "        self.warmup_iter = warmup_iter\n",
    "        self.warmup_ratio = warmup_ratio\n",
    "        self.warmup = warmup\n",
    "        super(WarmupExpLrScheduler, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        ratio = self.get_lr_ratio()\n",
    "        lrs = [ratio * lr for lr in self.base_lrs]\n",
    "        return lrs\n",
    "\n",
    "    def get_lr_ratio(self):\n",
    "        if self.last_epoch < self.warmup_iter:\n",
    "            ratio = self.get_warmup_ratio()\n",
    "        else:\n",
    "            real_iter = self.last_epoch - self.warmup_iter\n",
    "            ratio = self.power ** (real_iter // self.step_interval)\n",
    "        return ratio\n",
    "\n",
    "    def get_warmup_ratio(self):\n",
    "        assert self.warmup in ('linear', 'exp')\n",
    "        alpha = self.last_epoch / self.warmup_iter\n",
    "        if self.warmup == 'linear':\n",
    "            ratio = self.warmup_ratio + (1 - self.warmup_ratio) * alpha\n",
    "        elif self.warmup == 'exp':\n",
    "            ratio = self.warmup_ratio ** (1. - alpha)\n",
    "        return ratio\n",
    "\n",
    "\n",
    "class WarmupPolyLrScheduler(_LRScheduler):\n",
    "    def __init__(\n",
    "            self,\n",
    "            optimizer,\n",
    "            power,\n",
    "            max_iter,\n",
    "            warmup_iter,\n",
    "            warmup_ratio=5e-4,\n",
    "            warmup='exp',\n",
    "            last_epoch=-1,\n",
    "    ):\n",
    "        self.power = power\n",
    "        self.max_iter = max_iter\n",
    "        self.warmup_iter = warmup_iter\n",
    "        self.warmup_ratio = warmup_ratio\n",
    "        self.warmup = warmup\n",
    "        super(WarmupPolyLrScheduler, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        ratio = self.get_lr_ratio()\n",
    "        lrs = [ratio * lr for lr in self.base_lrs]\n",
    "        return lrs\n",
    "\n",
    "    def get_lr_ratio(self):\n",
    "        if self.last_epoch < self.warmup_iter:\n",
    "            ratio = self.get_warmup_ratio()\n",
    "        else:\n",
    "            real_iter = self.last_epoch - self.warmup_iter\n",
    "            real_max_iter = self.max_iter - self.warmup_iter\n",
    "            alpha = real_iter / real_max_iter\n",
    "            ratio = (1 - alpha) ** self.power\n",
    "        return ratio\n",
    "\n",
    "    def get_warmup_ratio(self):\n",
    "        assert self.warmup in ('linear', 'exp')\n",
    "        alpha = self.last_epoch / self.warmup_iter\n",
    "        if self.warmup == 'linear':\n",
    "            ratio = self.warmup_ratio + (1 - self.warmup_ratio) * alpha\n",
    "        elif self.warmup == 'exp':\n",
    "            ratio = self.warmup_ratio ** (1. - alpha)\n",
    "        return ratio\n",
    "\n",
    "\n",
    "class WarmupCosineLrScheduler(_LRScheduler):\n",
    "    '''\n",
    "    This is different from official definition, this is implemented according to\n",
    "    the paper of fix-match\n",
    "    '''\n",
    "    def __init__(\n",
    "            self,\n",
    "            optimizer,\n",
    "            max_iter,\n",
    "            warmup_iter,\n",
    "            warmup_ratio=5e-4,\n",
    "            warmup='exp',\n",
    "            last_epoch=-1,\n",
    "    ):\n",
    "        self.max_iter = max_iter\n",
    "        self.warmup_iter = warmup_iter\n",
    "        self.warmup_ratio = warmup_ratio\n",
    "        self.warmup = warmup\n",
    "        super(WarmupCosineLrScheduler, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        ratio = self.get_lr_ratio()\n",
    "        lrs = [ratio * lr for lr in self.base_lrs]\n",
    "        return lrs\n",
    "\n",
    "    def get_lr_ratio(self):\n",
    "        if self.last_epoch < self.warmup_iter:\n",
    "            ratio = self.get_warmup_ratio()\n",
    "        else:\n",
    "            real_iter = self.last_epoch - self.warmup_iter\n",
    "            real_max_iter = self.max_iter - self.warmup_iter\n",
    "            ratio = np.cos((7 * np.pi * real_iter) / (16 * real_max_iter))\n",
    "        return ratio\n",
    "\n",
    "    def get_warmup_ratio(self):\n",
    "        assert self.warmup in ('linear', 'exp')\n",
    "        alpha = self.last_epoch / self.warmup_iter\n",
    "        if self.warmup == 'linear':\n",
    "            ratio = self.warmup_ratio + (1 - self.warmup_ratio) * alpha\n",
    "        elif self.warmup == 'exp':\n",
    "            ratio = self.warmup_ratio ** (1. - alpha)\n",
    "        return ratio\n",
    "\n",
    "\n",
    "# from Fixmatch-pytorch\n",
    "def get_cosine_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps,\n",
    "                                    num_training_steps,\n",
    "                                    num_cycles=7./16.,\n",
    "                                    last_epoch=-1):\n",
    "    def _lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        no_progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        # return max(0., math.cos(math.pi * num_cycles * no_progress))\n",
    "\n",
    "        return max(0., (math.cos(math.pi * num_cycles * no_progress) + 1) * 0.5)\n",
    "\n",
    "    return LambdaLR(optimizer, _lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def interleave(x, bt):\n",
    "    s = list(x.shape)\n",
    "    return torch.reshape(torch.transpose(x.reshape([-1, bt] + s[1:]), 1, 0), [-1] + s[1:])\n",
    "\n",
    "\n",
    "def de_interleave(x, bt):\n",
    "    s = list(x.shape)\n",
    "    return torch.reshape(torch.transpose(x.reshape([bt, -1] + s[1:]), 1, 0), [-1] + s[1:])\n",
    "\n",
    "\n",
    "def setup_default_logging(args, default_level=logging.INFO,\n",
    "                          format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"):\n",
    "    output_dir = os.path.join('output','semi-supervised', f'x{args.num_labeled}')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    writer = SummaryWriter(comment=f'{args.dataset}_{args.num_labeled}')\n",
    "\n",
    "    logger = logging.getLogger('train')\n",
    "\n",
    "    logging.basicConfig(  # unlike the root logger, a custom logger can’t be configured using basicConfig()\n",
    "        filename=os.path.join(output_dir, f'{time_str()}.log'),\n",
    "        format=format,\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=default_level)\n",
    "\n",
    "    # print\n",
    "    # file_handler = logging.FileHandler()\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(default_level)\n",
    "    console_handler.setFormatter(logging.Formatter(format))\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    return logger, writer\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    \n",
    "    _, pred = output.topk(maxk, 1, largest=True, sorted=True)  # return value, indices\n",
    "    # print(pred)\n",
    "    pred = pred.t()\n",
    "    # print(target)\n",
    "    # print(target.view(1, -1).expand_as(pred))\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    # print(correct)\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        # self.avg = self.sum / (self.count + 1e-20)\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def time_str(fmt=None):\n",
    "    if fmt is None:\n",
    "        fmt = '%Y-%m-%d_%H:%M:%S'\n",
    "\n",
    "    #     time.strftime(format[, t])\n",
    "    return datetime.today().strftime(fmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    epoch,\n",
    "    model,\n",
    "    criteria_x,\n",
    "    criteria_u,\n",
    "    optimizer,\n",
    "    lr_schdlr,\n",
    "    ema,\n",
    "    labeledDatasetLoader,\n",
    "    unlabeledDatasetLoader,\n",
    "    lambda_u,\n",
    "    n_iters,\n",
    "    args,\n",
    "    logger\n",
    "    ):\n",
    "    model.train(True)\n",
    "    loss_meter = AverageMeter()\n",
    "    loss_x_meter = AverageMeter()\n",
    "    loss_u_meter = AverageMeter()\n",
    "    # number of gradient-considered strong augmentation of unlabeled samples\n",
    "    mask_meter = AverageMeter()\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    labeledIter,unlabeledIter=iter(labeledDatasetLoader),iter(unlabeledDatasetLoader)\n",
    "    for it in range(n_iters):\n",
    "        image_labeled_weak ,image_labeled_strong, labeled_label = next(labeledIter)\n",
    "        image_unlabeled_weak,image_unlabeled_strong,_ =next(unlabeledIter)\n",
    "        labeled_label = labeled_label.to(args.device)\n",
    "        # print(labeled_label)\n",
    "        batch_size = image_labeled_weak.size(0)\n",
    "        mu = int(image_unlabeled_weak.size(0)//batch_size)\n",
    "        imgs = torch.cat([image_labeled_weak,image_unlabeled_weak,image_unlabeled_strong],dim=0).to(args.device)\n",
    "        imgs = interleave(imgs,2*mu+1)\n",
    "        logits = model(imgs)\n",
    "        logits = de_interleave(logits,2*mu+1)\n",
    "        logits_x = logits[:batch_size]\n",
    "        logits_unlabeled_w,logits_unlabeled_s = torch.split(logits[batch_size:],batch_size*mu)\n",
    "        loss_x = criteria_x(logits_x,labeled_label)\n",
    "        with torch.no_grad():\n",
    "            probs = torch.softmax(logits_unlabeled_w,dim=1)\n",
    "            scores,labels_unlabeled_guess = torch.max(probs,dim=1)\n",
    "            mask =scores.ge(args.threshold).float()\n",
    "        loss_u = (criteria_u(logits_unlabeled_s,labels_unlabeled_guess)*mask).mean()\n",
    "        loss = loss_x+ lambda_u *loss_u\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if args.use_ema == True:\n",
    "            ema.update_params()\n",
    "        lr_schdlr.step()\n",
    "        loss_meter.update(loss.item())\n",
    "        loss_x_meter.update(loss_x.item())\n",
    "        loss_u_meter.update(loss_u.item())\n",
    "        mask_meter.update(mask.mean().item())\n",
    "        \n",
    "        if (it + 1) % (n_iters//4) == 0:\n",
    "            t = time.time() - epoch_start\n",
    "            lr_log = [pg['lr'] for pg in optimizer.param_groups]\n",
    "            lr_log = sum(lr_log) / len(lr_log)\n",
    "            logger.info(\"epoch:{}, iter: {}. loss: {:.4f}. loss_u: {:.4f}. loss_x: {:.4f}. \"\n",
    "                        \"Mask:{:.4f} . LR: {:.4f}. Time: {:.2f}\".format(\n",
    "                epoch, it + 1, loss_meter.avg, loss_u_meter.avg, loss_x_meter.avg, mask_meter.avg, lr_log, t))\n",
    "            epoch_start = time.time()\n",
    "    if args.use_ema == True:\n",
    "        ema.update_buffer()\n",
    "    return loss_meter.avg,loss_x_meter.avg,loss_u_meter.avg,mask_meter.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def evaluate(ema,dataloader,criterion,args):\n",
    "    # ema params to evaluate performance\n",
    "    if args.use_ema == True:\n",
    "        ema.apply_shadow()\n",
    "        ema.model.to(args.device)\n",
    "    ema.model.eval()\n",
    "\n",
    "    loss_meter= AverageMeter()\n",
    "    top1_meter = AverageMeter()\n",
    "    top5_meter = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images,labels in dataloader:\n",
    "            images = images.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            logits = ema.model(images)\n",
    "            # print(images.shape,labels.shape)\n",
    "            loss = criterion(logits,labels)\n",
    "            scores = torch.softmax(logits,dim=1)\n",
    "            top1,top5 = accuracy(scores,labels,(1,5))\n",
    "            loss_meter.update(loss.item())\n",
    "            top1_meter.update(top1.item())\n",
    "            top5_meter.update(top5.item())\n",
    "    if args.use_ema == True:\n",
    "        ema.restore()\n",
    "    return top1_meter.avg,top5_meter.avg,loss_meter.avg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 19:27:45,566 - INFO - train -   ***** Running training *****\n",
      "2022-04-13 19:27:45,568 - INFO - train -     Task = dataset@250\n",
      "2022-04-13 19:27:45,568 - INFO - train -     Num Iters Per Epoch = 256\n",
      "2022-04-13 19:27:45,569 - INFO - train -     Batch size per GPU = 64\n",
      "2022-04-13 19:27:45,570 - INFO - train -     Total optimization steps = 32768\n",
      "2022-04-13 19:27:45,571 - INFO - train -   Total params: 11.18M\n",
      "2022-04-13 19:27:45,572 - INFO - train -   -----------start training--------------\n",
      "2022-04-13 19:28:54,936 - INFO - train -   epoch:0, iter: 64. loss: 1.5007. loss_u: 0.0327. loss_x: 1.4679. Mask:0.0693 . LR: 0.0300. Time: 69.36\n",
      "2022-04-13 19:29:57,516 - INFO - train -   epoch:0, iter: 128. loss: 1.2729. loss_u: 0.0643. loss_x: 1.2086. Mask:0.1043 . LR: 0.0300. Time: 62.58\n",
      "2022-04-13 19:30:59,667 - INFO - train -   epoch:0, iter: 192. loss: 1.1359. loss_u: 0.0889. loss_x: 1.0471. Mask:0.1414 . LR: 0.0300. Time: 62.15\n",
      "2022-04-13 19:32:02,435 - INFO - train -   epoch:0, iter: 256. loss: 1.0300. loss_u: 0.1181. loss_x: 0.9119. Mask:0.1837 . LR: 0.0300. Time: 62.76\n",
      "2022-04-13 19:32:06,412 - INFO - train -   Epoch 0. Top1: 58.0002. Top5: 94.7432. best_acc: 58.0002 in epoch 0\n",
      "2022-04-13 19:33:09,958 - INFO - train -   epoch:1, iter: 64. loss: 0.6580. loss_u: 0.2205. loss_x: 0.4375. Mask:0.3621 . LR: 0.0300. Time: 63.54\n",
      "2022-04-13 19:34:11,076 - INFO - train -   epoch:1, iter: 128. loss: 0.6282. loss_u: 0.2337. loss_x: 0.3945. Mask:0.3747 . LR: 0.0300. Time: 61.12\n",
      "2022-04-13 19:35:11,787 - INFO - train -   epoch:1, iter: 192. loss: 0.6048. loss_u: 0.2439. loss_x: 0.3609. Mask:0.3928 . LR: 0.0300. Time: 60.71\n",
      "2022-04-13 19:36:12,599 - INFO - train -   epoch:1, iter: 256. loss: 0.5946. loss_u: 0.2526. loss_x: 0.3420. Mask:0.4108 . LR: 0.0300. Time: 60.81\n",
      "2022-04-13 19:36:16,757 - INFO - train -   Epoch 1. Top1: 60.3198. Top5: 94.7250. best_acc: 60.3198 in epoch 1\n",
      "2022-04-13 19:37:21,005 - INFO - train -   epoch:2, iter: 64. loss: 0.4970. loss_u: 0.2759. loss_x: 0.2211. Mask:0.4715 . LR: 0.0300. Time: 64.24\n",
      "2022-04-13 19:38:20,537 - INFO - train -   epoch:2, iter: 128. loss: 0.4923. loss_u: 0.2749. loss_x: 0.2173. Mask:0.4753 . LR: 0.0300. Time: 59.53\n",
      "2022-04-13 19:39:23,286 - INFO - train -   epoch:2, iter: 192. loss: 0.4855. loss_u: 0.2765. loss_x: 0.2090. Mask:0.4826 . LR: 0.0300. Time: 62.75\n",
      "2022-04-13 19:40:23,648 - INFO - train -   epoch:2, iter: 256. loss: 0.4779. loss_u: 0.2808. loss_x: 0.1971. Mask:0.4911 . LR: 0.0300. Time: 60.36\n",
      "2022-04-13 19:40:28,022 - INFO - train -   Epoch 2. Top1: 67.7447. Top5: 96.0150. best_acc: 67.7447 in epoch 2\n",
      "2022-04-13 19:41:30,154 - INFO - train -   epoch:3, iter: 64. loss: 0.4562. loss_u: 0.2785. loss_x: 0.1777. Mask:0.5015 . LR: 0.0300. Time: 62.13\n",
      "2022-04-13 19:42:31,486 - INFO - train -   epoch:3, iter: 128. loss: 0.4731. loss_u: 0.2897. loss_x: 0.1834. Mask:0.5055 . LR: 0.0300. Time: 61.33\n",
      "2022-04-13 19:43:30,507 - INFO - train -   epoch:3, iter: 192. loss: 0.4737. loss_u: 0.2900. loss_x: 0.1837. Mask:0.5071 . LR: 0.0300. Time: 59.02\n",
      "2022-04-13 19:44:32,308 - INFO - train -   epoch:3, iter: 256. loss: 0.4692. loss_u: 0.2879. loss_x: 0.1813. Mask:0.5088 . LR: 0.0300. Time: 61.80\n",
      "2022-04-13 19:44:36,402 - INFO - train -   Epoch 3. Top1: 67.0967. Top5: 95.7243. best_acc: 67.7447 in epoch 2\n",
      "2022-04-13 19:45:37,146 - INFO - train -   epoch:4, iter: 64. loss: 0.4367. loss_u: 0.2809. loss_x: 0.1558. Mask:0.5321 . LR: 0.0300. Time: 60.74\n",
      "2022-04-13 19:46:34,649 - INFO - train -   epoch:4, iter: 128. loss: 0.4338. loss_u: 0.2843. loss_x: 0.1495. Mask:0.5316 . LR: 0.0300. Time: 57.50\n",
      "2022-04-13 19:47:33,897 - INFO - train -   epoch:4, iter: 192. loss: 0.4343. loss_u: 0.2889. loss_x: 0.1455. Mask:0.5385 . LR: 0.0300. Time: 59.25\n",
      "2022-04-13 19:48:31,375 - INFO - train -   epoch:4, iter: 256. loss: 0.4273. loss_u: 0.2885. loss_x: 0.1388. Mask:0.5396 . LR: 0.0300. Time: 57.48\n",
      "2022-04-13 19:48:35,340 - INFO - train -   Epoch 4. Top1: 69.8643. Top5: 96.7963. best_acc: 69.8643 in epoch 4\n",
      "2022-04-13 19:49:39,206 - INFO - train -   epoch:5, iter: 64. loss: 0.4043. loss_u: 0.2829. loss_x: 0.1214. Mask:0.5567 . LR: 0.0300. Time: 63.86\n",
      "2022-04-13 19:50:39,619 - INFO - train -   epoch:5, iter: 128. loss: 0.4032. loss_u: 0.2757. loss_x: 0.1275. Mask:0.5522 . LR: 0.0299. Time: 60.41\n",
      "2022-04-13 19:51:39,962 - INFO - train -   epoch:5, iter: 192. loss: 0.4008. loss_u: 0.2785. loss_x: 0.1223. Mask:0.5572 . LR: 0.0299. Time: 60.34\n",
      "2022-04-13 19:52:39,411 - INFO - train -   epoch:5, iter: 256. loss: 0.3919. loss_u: 0.2785. loss_x: 0.1135. Mask:0.5620 . LR: 0.0299. Time: 59.45\n",
      "2022-04-13 19:52:43,584 - INFO - train -   Epoch 5. Top1: 70.5305. Top5: 97.1415. best_acc: 70.5305 in epoch 5\n",
      "2022-04-13 19:53:44,878 - INFO - train -   epoch:6, iter: 64. loss: 0.4037. loss_u: 0.2895. loss_x: 0.1142. Mask:0.5692 . LR: 0.0299. Time: 61.29\n",
      "2022-04-13 19:54:44,700 - INFO - train -   epoch:6, iter: 128. loss: 0.3870. loss_u: 0.2866. loss_x: 0.1003. Mask:0.5748 . LR: 0.0299. Time: 59.82\n",
      "2022-04-13 19:55:42,103 - INFO - train -   epoch:6, iter: 192. loss: 0.3766. loss_u: 0.2837. loss_x: 0.0929. Mask:0.5798 . LR: 0.0299. Time: 57.40\n",
      "2022-04-13 19:56:42,233 - INFO - train -   epoch:6, iter: 256. loss: 0.3740. loss_u: 0.2867. loss_x: 0.0874. Mask:0.5819 . LR: 0.0299. Time: 60.13\n",
      "2022-04-13 19:56:46,221 - INFO - train -   Epoch 6. Top1: 71.7720. Top5: 96.0877. best_acc: 71.7720 in epoch 6\n",
      "2022-04-13 19:57:47,764 - INFO - train -   epoch:7, iter: 64. loss: 0.3754. loss_u: 0.2803. loss_x: 0.0952. Mask:0.5836 . LR: 0.0299. Time: 61.54\n",
      "2022-04-13 19:58:46,211 - INFO - train -   epoch:7, iter: 128. loss: 0.3749. loss_u: 0.2771. loss_x: 0.0978. Mask:0.5802 . LR: 0.0299. Time: 58.44\n",
      "2022-04-13 19:59:43,284 - INFO - train -   epoch:7, iter: 192. loss: 0.3630. loss_u: 0.2738. loss_x: 0.0892. Mask:0.5812 . LR: 0.0299. Time: 57.07\n",
      "2022-04-13 20:00:42,353 - INFO - train -   epoch:7, iter: 256. loss: 0.3601. loss_u: 0.2729. loss_x: 0.0872. Mask:0.5833 . LR: 0.0299. Time: 59.07\n",
      "2022-04-13 20:00:46,520 - INFO - train -   Epoch 7. Top1: 73.6131. Top5: 97.2323. best_acc: 73.6131 in epoch 7\n",
      "2022-04-13 20:01:48,641 - INFO - train -   epoch:8, iter: 64. loss: 0.3714. loss_u: 0.2709. loss_x: 0.1005. Mask:0.5899 . LR: 0.0299. Time: 62.12\n",
      "2022-04-13 20:02:49,944 - INFO - train -   epoch:8, iter: 128. loss: 0.3720. loss_u: 0.2684. loss_x: 0.1036. Mask:0.5758 . LR: 0.0299. Time: 61.30\n",
      "2022-04-13 20:03:48,824 - INFO - train -   epoch:8, iter: 192. loss: 0.3709. loss_u: 0.2753. loss_x: 0.0956. Mask:0.5841 . LR: 0.0299. Time: 58.88\n",
      "2022-04-13 20:04:47,863 - INFO - train -   epoch:8, iter: 256. loss: 0.3628. loss_u: 0.2743. loss_x: 0.0885. Mask:0.5855 . LR: 0.0299. Time: 59.04\n",
      "2022-04-13 20:04:52,165 - INFO - train -   Epoch 8. Top1: 71.0271. Top5: 97.0203. best_acc: 73.6131 in epoch 7\n",
      "2022-04-13 20:05:56,051 - INFO - train -   epoch:9, iter: 64. loss: 0.3464. loss_u: 0.2841. loss_x: 0.0623. Mask:0.6152 . LR: 0.0299. Time: 63.88\n",
      "2022-04-13 20:06:53,152 - INFO - train -   epoch:9, iter: 128. loss: 0.3494. loss_u: 0.2814. loss_x: 0.0680. Mask:0.6129 . LR: 0.0298. Time: 57.10\n",
      "2022-04-13 20:07:52,074 - INFO - train -   epoch:9, iter: 192. loss: 0.3454. loss_u: 0.2747. loss_x: 0.0707. Mask:0.6034 . LR: 0.0298. Time: 58.92\n",
      "2022-04-13 20:08:50,018 - INFO - train -   epoch:9, iter: 256. loss: 0.3448. loss_u: 0.2760. loss_x: 0.0688. Mask:0.6061 . LR: 0.0298. Time: 57.94\n",
      "2022-04-13 20:08:54,209 - INFO - train -   Epoch 9. Top1: 73.3830. Top5: 96.8387. best_acc: 73.6131 in epoch 7\n",
      "2022-04-13 20:09:56,723 - INFO - train -   epoch:10, iter: 64. loss: 0.3513. loss_u: 0.2770. loss_x: 0.0743. Mask:0.6181 . LR: 0.0298. Time: 62.51\n",
      "2022-04-13 20:10:57,014 - INFO - train -   epoch:10, iter: 128. loss: 0.3486. loss_u: 0.2726. loss_x: 0.0759. Mask:0.6104 . LR: 0.0298. Time: 60.29\n",
      "2022-04-13 20:11:56,944 - INFO - train -   epoch:10, iter: 192. loss: 0.3454. loss_u: 0.2713. loss_x: 0.0740. Mask:0.6075 . LR: 0.0298. Time: 59.93\n",
      "2022-04-13 20:12:56,136 - INFO - train -   epoch:10, iter: 256. loss: 0.3394. loss_u: 0.2659. loss_x: 0.0735. Mask:0.6045 . LR: 0.0298. Time: 59.19\n",
      "2022-04-13 20:13:00,269 - INFO - train -   Epoch 10. Top1: 75.0727. Top5: 98.0499. best_acc: 75.0727 in epoch 10\n",
      "2022-04-13 20:14:01,786 - INFO - train -   epoch:11, iter: 64. loss: 0.3191. loss_u: 0.2664. loss_x: 0.0526. Mask:0.6150 . LR: 0.0298. Time: 61.51\n",
      "2022-04-13 20:15:00,471 - INFO - train -   epoch:11, iter: 128. loss: 0.3166. loss_u: 0.2640. loss_x: 0.0526. Mask:0.6128 . LR: 0.0298. Time: 58.68\n",
      "2022-04-13 20:15:57,534 - INFO - train -   epoch:11, iter: 192. loss: 0.3225. loss_u: 0.2671. loss_x: 0.0554. Mask:0.6154 . LR: 0.0298. Time: 57.06\n",
      "2022-04-13 20:16:57,023 - INFO - train -   epoch:11, iter: 256. loss: 0.3248. loss_u: 0.2688. loss_x: 0.0560. Mask:0.6199 . LR: 0.0298. Time: 59.49\n",
      "2022-04-13 20:17:01,143 - INFO - train -   Epoch 11. Top1: 67.6175. Top5: 95.5305. best_acc: 75.0727 in epoch 10\n",
      "2022-04-13 20:18:04,287 - INFO - train -   epoch:12, iter: 64. loss: 0.3352. loss_u: 0.2811. loss_x: 0.0542. Mask:0.6280 . LR: 0.0297. Time: 63.14\n",
      "2022-04-13 20:19:04,415 - INFO - train -   epoch:12, iter: 128. loss: 0.3313. loss_u: 0.2767. loss_x: 0.0546. Mask:0.6291 . LR: 0.0297. Time: 60.13\n",
      "2022-04-13 20:20:03,971 - INFO - train -   epoch:12, iter: 192. loss: 0.3295. loss_u: 0.2771. loss_x: 0.0525. Mask:0.6327 . LR: 0.0297. Time: 59.55\n",
      "2022-04-13 20:21:03,455 - INFO - train -   epoch:12, iter: 256. loss: 0.3271. loss_u: 0.2756. loss_x: 0.0516. Mask:0.6331 . LR: 0.0297. Time: 59.48\n",
      "2022-04-13 20:21:07,526 - INFO - train -   Epoch 12. Top1: 72.6986. Top5: 96.8871. best_acc: 75.0727 in epoch 10\n",
      "2022-04-13 20:22:10,126 - INFO - train -   epoch:13, iter: 64. loss: 0.3101. loss_u: 0.2680. loss_x: 0.0422. Mask:0.6318 . LR: 0.0297. Time: 62.60\n",
      "2022-04-13 20:23:10,478 - INFO - train -   epoch:13, iter: 128. loss: 0.3143. loss_u: 0.2676. loss_x: 0.0467. Mask:0.6357 . LR: 0.0297. Time: 60.35\n",
      "2022-04-13 20:24:10,404 - INFO - train -   epoch:13, iter: 192. loss: 0.3188. loss_u: 0.2690. loss_x: 0.0498. Mask:0.6313 . LR: 0.0297. Time: 59.92\n",
      "2022-04-13 20:25:09,808 - INFO - train -   epoch:13, iter: 256. loss: 0.3160. loss_u: 0.2677. loss_x: 0.0484. Mask:0.6314 . LR: 0.0297. Time: 59.40\n",
      "2022-04-13 20:25:14,069 - INFO - train -   Epoch 13. Top1: 77.4528. Top5: 98.0378. best_acc: 77.4528 in epoch 13\n",
      "2022-04-13 20:26:16,502 - INFO - train -   epoch:14, iter: 64. loss: 0.3191. loss_u: 0.2636. loss_x: 0.0555. Mask:0.6229 . LR: 0.0296. Time: 62.43\n",
      "2022-04-13 20:27:16,115 - INFO - train -   epoch:14, iter: 128. loss: 0.3270. loss_u: 0.2717. loss_x: 0.0554. Mask:0.6345 . LR: 0.0296. Time: 59.61\n",
      "2022-04-13 20:28:16,534 - INFO - train -   epoch:14, iter: 192. loss: 0.3234. loss_u: 0.2710. loss_x: 0.0525. Mask:0.6364 . LR: 0.0296. Time: 60.42\n",
      "2022-04-13 20:29:17,371 - INFO - train -   epoch:14, iter: 256. loss: 0.3210. loss_u: 0.2691. loss_x: 0.0519. Mask:0.6360 . LR: 0.0296. Time: 60.84\n",
      "2022-04-13 20:29:21,445 - INFO - train -   Epoch 14. Top1: 76.0962. Top5: 97.7410. best_acc: 77.4528 in epoch 13\n",
      "2022-04-13 20:30:25,571 - INFO - train -   epoch:15, iter: 64. loss: 0.3151. loss_u: 0.2672. loss_x: 0.0479. Mask:0.6417 . LR: 0.0296. Time: 64.12\n",
      "2022-04-13 20:31:27,534 - INFO - train -   epoch:15, iter: 128. loss: 0.3132. loss_u: 0.2633. loss_x: 0.0499. Mask:0.6406 . LR: 0.0296. Time: 61.96\n",
      "2022-04-13 20:32:26,704 - INFO - train -   epoch:15, iter: 192. loss: 0.3153. loss_u: 0.2664. loss_x: 0.0489. Mask:0.6442 . LR: 0.0296. Time: 59.17\n",
      "2022-04-13 20:33:24,135 - INFO - train -   epoch:15, iter: 256. loss: 0.3143. loss_u: 0.2670. loss_x: 0.0473. Mask:0.6449 . LR: 0.0296. Time: 57.43\n",
      "2022-04-13 20:33:28,298 - INFO - train -   Epoch 15. Top1: 76.2355. Top5: 97.4685. best_acc: 77.4528 in epoch 13\n",
      "2022-04-13 20:34:29,728 - INFO - train -   epoch:16, iter: 64. loss: 0.3251. loss_u: 0.2638. loss_x: 0.0613. Mask:0.6393 . LR: 0.0295. Time: 61.43\n",
      "2022-04-13 20:35:27,261 - INFO - train -   epoch:16, iter: 128. loss: 0.3335. loss_u: 0.2710. loss_x: 0.0625. Mask:0.6367 . LR: 0.0295. Time: 57.53\n",
      "2022-04-13 20:36:26,412 - INFO - train -   epoch:16, iter: 192. loss: 0.3322. loss_u: 0.2663. loss_x: 0.0659. Mask:0.6296 . LR: 0.0295. Time: 59.15\n",
      "2022-04-13 20:37:23,664 - INFO - train -   epoch:16, iter: 256. loss: 0.3320. loss_u: 0.2677. loss_x: 0.0643. Mask:0.6327 . LR: 0.0295. Time: 57.25\n",
      "2022-04-13 20:37:27,890 - INFO - train -   Epoch 16. Top1: 72.7531. Top5: 97.4140. best_acc: 77.4528 in epoch 13\n",
      "2022-04-13 20:38:31,369 - INFO - train -   epoch:17, iter: 64. loss: 0.3145. loss_u: 0.2747. loss_x: 0.0398. Mask:0.6553 . LR: 0.0295. Time: 63.47\n",
      "2022-04-13 20:39:30,586 - INFO - train -   epoch:17, iter: 128. loss: 0.3112. loss_u: 0.2640. loss_x: 0.0472. Mask:0.6469 . LR: 0.0295. Time: 59.21\n",
      "2022-04-13 20:40:29,032 - INFO - train -   epoch:17, iter: 192. loss: 0.3083. loss_u: 0.2649. loss_x: 0.0434. Mask:0.6538 . LR: 0.0295. Time: 58.45\n",
      "2022-04-13 20:41:27,130 - INFO - train -   epoch:17, iter: 256. loss: 0.3061. loss_u: 0.2636. loss_x: 0.0425. Mask:0.6548 . LR: 0.0294. Time: 58.10\n",
      "2022-04-13 20:41:31,394 - INFO - train -   Epoch 17. Top1: 76.5746. Top5: 97.7289. best_acc: 77.4528 in epoch 13\n",
      "2022-04-13 20:42:35,219 - INFO - train -   epoch:18, iter: 64. loss: 0.3213. loss_u: 0.2774. loss_x: 0.0439. Mask:0.6626 . LR: 0.0294. Time: 63.82\n",
      "2022-04-13 20:43:32,794 - INFO - train -   epoch:18, iter: 128. loss: 0.3202. loss_u: 0.2757. loss_x: 0.0444. Mask:0.6602 . LR: 0.0294. Time: 57.57\n",
      "2022-04-13 20:44:32,923 - INFO - train -   epoch:18, iter: 192. loss: 0.3211. loss_u: 0.2756. loss_x: 0.0455. Mask:0.6615 . LR: 0.0294. Time: 60.13\n",
      "2022-04-13 20:45:33,350 - INFO - train -   epoch:18, iter: 256. loss: 0.3145. loss_u: 0.2699. loss_x: 0.0446. Mask:0.6621 . LR: 0.0294. Time: 60.43\n",
      "2022-04-13 20:45:37,598 - INFO - train -   Epoch 18. Top1: 74.5337. Top5: 97.8561. best_acc: 77.4528 in epoch 13\n",
      "2022-04-13 20:46:39,986 - INFO - train -   epoch:19, iter: 64. loss: 0.3052. loss_u: 0.2625. loss_x: 0.0427. Mask:0.6665 . LR: 0.0294. Time: 62.38\n",
      "2022-04-13 20:47:39,929 - INFO - train -   epoch:19, iter: 128. loss: 0.3026. loss_u: 0.2594. loss_x: 0.0432. Mask:0.6644 . LR: 0.0293. Time: 59.94\n",
      "2022-04-13 20:48:39,779 - INFO - train -   epoch:19, iter: 192. loss: 0.3062. loss_u: 0.2610. loss_x: 0.0452. Mask:0.6662 . LR: 0.0293. Time: 59.85\n",
      "2022-04-13 20:49:39,669 - INFO - train -   epoch:19, iter: 256. loss: 0.3038. loss_u: 0.2606. loss_x: 0.0432. Mask:0.6670 . LR: 0.0293. Time: 59.89\n",
      "2022-04-13 20:49:43,694 - INFO - train -   Epoch 19. Top1: 78.8275. Top5: 98.1105. best_acc: 78.8275 in epoch 19\n",
      "2022-04-13 20:50:46,115 - INFO - train -   epoch:20, iter: 64. loss: 0.3072. loss_u: 0.2656. loss_x: 0.0416. Mask:0.6712 . LR: 0.0293. Time: 62.42\n",
      "2022-04-13 20:51:48,329 - INFO - train -   epoch:20, iter: 128. loss: 0.2991. loss_u: 0.2599. loss_x: 0.0392. Mask:0.6692 . LR: 0.0293. Time: 62.21\n",
      "2022-04-13 20:52:49,972 - INFO - train -   epoch:20, iter: 192. loss: 0.2986. loss_u: 0.2601. loss_x: 0.0385. Mask:0.6706 . LR: 0.0293. Time: 61.64\n",
      "2022-04-13 20:53:54,035 - INFO - train -   epoch:20, iter: 256. loss: 0.3030. loss_u: 0.2613. loss_x: 0.0418. Mask:0.6698 . LR: 0.0292. Time: 64.06\n",
      "2022-04-13 20:53:58,335 - INFO - train -   Epoch 20. Top1: 76.0356. Top5: 97.6381. best_acc: 78.8275 in epoch 19\n",
      "2022-04-13 20:55:00,846 - INFO - train -   epoch:21, iter: 64. loss: 0.3034. loss_u: 0.2662. loss_x: 0.0372. Mask:0.6600 . LR: 0.0292. Time: 62.51\n",
      "2022-04-13 20:55:58,018 - INFO - train -   epoch:21, iter: 128. loss: 0.3105. loss_u: 0.2678. loss_x: 0.0427. Mask:0.6722 . LR: 0.0292. Time: 57.17\n",
      "2022-04-13 20:56:56,015 - INFO - train -   epoch:21, iter: 192. loss: 0.3078. loss_u: 0.2660. loss_x: 0.0418. Mask:0.6716 . LR: 0.0292. Time: 58.00\n",
      "2022-04-13 20:57:55,890 - INFO - train -   epoch:21, iter: 256. loss: 0.3067. loss_u: 0.2657. loss_x: 0.0410. Mask:0.6726 . LR: 0.0292. Time: 59.87\n",
      "2022-04-13 20:57:59,916 - INFO - train -   Epoch 21. Top1: 77.3801. Top5: 97.9772. best_acc: 78.8275 in epoch 19\n",
      "2022-04-13 20:59:01,300 - INFO - train -   epoch:22, iter: 64. loss: 0.3110. loss_u: 0.2637. loss_x: 0.0472. Mask:0.6635 . LR: 0.0291. Time: 61.38\n",
      "2022-04-13 20:59:59,574 - INFO - train -   epoch:22, iter: 128. loss: 0.3017. loss_u: 0.2610. loss_x: 0.0407. Mask:0.6725 . LR: 0.0291. Time: 58.27\n",
      "2022-04-13 21:00:58,215 - INFO - train -   epoch:22, iter: 192. loss: 0.3006. loss_u: 0.2615. loss_x: 0.0391. Mask:0.6754 . LR: 0.0291. Time: 58.64\n",
      "2022-04-13 21:01:58,786 - INFO - train -   epoch:22, iter: 256. loss: 0.3014. loss_u: 0.2614. loss_x: 0.0400. Mask:0.6760 . LR: 0.0291. Time: 60.57\n",
      "2022-04-13 21:02:02,942 - INFO - train -   Epoch 22. Top1: 80.5899. Top5: 98.0741. best_acc: 80.5899 in epoch 22\n",
      "2022-04-13 21:03:03,416 - INFO - train -   epoch:23, iter: 64. loss: 0.3064. loss_u: 0.2659. loss_x: 0.0405. Mask:0.6813 . LR: 0.0291. Time: 60.47\n",
      "2022-04-13 21:04:02,599 - INFO - train -   epoch:23, iter: 128. loss: 0.3024. loss_u: 0.2608. loss_x: 0.0416. Mask:0.6743 . LR: 0.0290. Time: 59.18\n",
      "2022-04-13 21:05:01,341 - INFO - train -   epoch:23, iter: 192. loss: 0.3007. loss_u: 0.2600. loss_x: 0.0407. Mask:0.6735 . LR: 0.0290. Time: 58.74\n",
      "2022-04-13 21:06:00,562 - INFO - train -   epoch:23, iter: 256. loss: 0.2994. loss_u: 0.2595. loss_x: 0.0399. Mask:0.6764 . LR: 0.0290. Time: 59.22\n",
      "2022-04-13 21:06:04,740 - INFO - train -   Epoch 23. Top1: 79.9782. Top5: 98.5041. best_acc: 80.5899 in epoch 22\n",
      "2022-04-13 21:07:06,881 - INFO - train -   epoch:24, iter: 64. loss: 0.3061. loss_u: 0.2608. loss_x: 0.0453. Mask:0.6641 . LR: 0.0290. Time: 62.14\n",
      "2022-04-13 21:08:07,254 - INFO - train -   epoch:24, iter: 128. loss: 0.3084. loss_u: 0.2654. loss_x: 0.0430. Mask:0.6758 . LR: 0.0290. Time: 60.37\n",
      "2022-04-13 21:09:06,202 - INFO - train -   epoch:24, iter: 192. loss: 0.2987. loss_u: 0.2612. loss_x: 0.0375. Mask:0.6812 . LR: 0.0289. Time: 58.95\n",
      "2022-04-13 21:10:04,711 - INFO - train -   epoch:24, iter: 256. loss: 0.3006. loss_u: 0.2616. loss_x: 0.0390. Mask:0.6813 . LR: 0.0289. Time: 58.51\n",
      "2022-04-13 21:10:08,918 - INFO - train -   Epoch 24. Top1: 79.3423. Top5: 97.3110. best_acc: 80.5899 in epoch 22\n",
      "2022-04-13 21:11:08,848 - INFO - train -   epoch:25, iter: 64. loss: 0.2889. loss_u: 0.2503. loss_x: 0.0387. Mask:0.6700 . LR: 0.0289. Time: 59.93\n",
      "2022-04-13 21:12:07,372 - INFO - train -   epoch:25, iter: 128. loss: 0.2925. loss_u: 0.2536. loss_x: 0.0389. Mask:0.6764 . LR: 0.0289. Time: 58.52\n",
      "2022-04-13 21:13:04,497 - INFO - train -   epoch:25, iter: 192. loss: 0.2932. loss_u: 0.2569. loss_x: 0.0363. Mask:0.6815 . LR: 0.0289. Time: 57.12\n",
      "2022-04-13 21:14:04,689 - INFO - train -   epoch:25, iter: 256. loss: 0.2909. loss_u: 0.2570. loss_x: 0.0339. Mask:0.6882 . LR: 0.0288. Time: 60.19\n",
      "2022-04-13 21:14:08,886 - INFO - train -   Epoch 25. Top1: 79.9843. Top5: 98.4375. best_acc: 80.5899 in epoch 22\n",
      "2022-04-13 21:15:10,636 - INFO - train -   epoch:26, iter: 64. loss: 0.2874. loss_u: 0.2520. loss_x: 0.0355. Mask:0.7002 . LR: 0.0288. Time: 61.75\n",
      "2022-04-13 21:16:08,862 - INFO - train -   epoch:26, iter: 128. loss: 0.2899. loss_u: 0.2572. loss_x: 0.0327. Mask:0.7004 . LR: 0.0288. Time: 58.22\n",
      "2022-04-13 21:17:08,457 - INFO - train -   epoch:26, iter: 192. loss: 0.2867. loss_u: 0.2547. loss_x: 0.0320. Mask:0.6992 . LR: 0.0288. Time: 59.59\n",
      "2022-04-13 21:18:06,433 - INFO - train -   epoch:26, iter: 256. loss: 0.2865. loss_u: 0.2559. loss_x: 0.0306. Mask:0.6983 . LR: 0.0287. Time: 57.97\n",
      "2022-04-13 21:18:10,587 - INFO - train -   Epoch 26. Top1: 81.5225. Top5: 98.1468. best_acc: 81.5225 in epoch 26\n",
      "2022-04-13 21:19:16,828 - INFO - train -   epoch:27, iter: 64. loss: 0.2949. loss_u: 0.2558. loss_x: 0.0391. Mask:0.6957 . LR: 0.0287. Time: 66.24\n",
      "2022-04-13 21:20:16,995 - INFO - train -   epoch:27, iter: 128. loss: 0.2965. loss_u: 0.2585. loss_x: 0.0380. Mask:0.6973 . LR: 0.0287. Time: 60.16\n",
      "2022-04-13 21:21:16,401 - INFO - train -   epoch:27, iter: 192. loss: 0.2977. loss_u: 0.2589. loss_x: 0.0388. Mask:0.6948 . LR: 0.0287. Time: 59.40\n",
      "2022-04-13 21:22:17,318 - INFO - train -   epoch:27, iter: 256. loss: 0.2953. loss_u: 0.2592. loss_x: 0.0361. Mask:0.6936 . LR: 0.0287. Time: 60.91\n",
      "2022-04-13 21:22:21,529 - INFO - train -   Epoch 27. Top1: 82.1827. Top5: 98.3103. best_acc: 82.1827 in epoch 27\n",
      "2022-04-13 21:23:23,423 - INFO - train -   epoch:28, iter: 64. loss: 0.2869. loss_u: 0.2531. loss_x: 0.0338. Mask:0.7041 . LR: 0.0286. Time: 61.89\n",
      "2022-04-13 21:24:20,551 - INFO - train -   epoch:28, iter: 128. loss: 0.2904. loss_u: 0.2559. loss_x: 0.0345. Mask:0.6988 . LR: 0.0286. Time: 57.13\n",
      "2022-04-13 21:25:18,444 - INFO - train -   epoch:28, iter: 192. loss: 0.2884. loss_u: 0.2577. loss_x: 0.0306. Mask:0.7023 . LR: 0.0286. Time: 57.89\n",
      "2022-04-13 21:26:16,935 - INFO - train -   epoch:28, iter: 256. loss: 0.2881. loss_u: 0.2585. loss_x: 0.0295. Mask:0.7042 . LR: 0.0286. Time: 58.49\n",
      "2022-04-13 21:26:21,050 - INFO - train -   Epoch 28. Top1: 79.9661. Top5: 98.3467. best_acc: 82.1827 in epoch 27\n",
      "2022-04-13 21:27:22,943 - INFO - train -   epoch:29, iter: 64. loss: 0.2807. loss_u: 0.2535. loss_x: 0.0273. Mask:0.7140 . LR: 0.0285. Time: 61.89\n",
      "2022-04-13 21:28:22,292 - INFO - train -   epoch:29, iter: 128. loss: 0.2939. loss_u: 0.2592. loss_x: 0.0348. Mask:0.7053 . LR: 0.0285. Time: 59.35\n",
      "2022-04-13 21:29:24,697 - INFO - train -   epoch:29, iter: 192. loss: 0.2965. loss_u: 0.2598. loss_x: 0.0367. Mask:0.7030 . LR: 0.0285. Time: 62.40\n",
      "2022-04-13 21:30:23,166 - INFO - train -   epoch:29, iter: 256. loss: 0.2953. loss_u: 0.2612. loss_x: 0.0341. Mask:0.7072 . LR: 0.0285. Time: 58.47\n",
      "2022-04-13 21:30:27,328 - INFO - train -   Epoch 29. Top1: 81.8435. Top5: 98.7040. best_acc: 82.1827 in epoch 27\n",
      "2022-04-13 21:31:33,869 - INFO - train -   epoch:30, iter: 64. loss: 0.2846. loss_u: 0.2479. loss_x: 0.0367. Mask:0.7015 . LR: 0.0284. Time: 66.54\n",
      "2022-04-13 21:32:34,249 - INFO - train -   epoch:30, iter: 128. loss: 0.2815. loss_u: 0.2494. loss_x: 0.0320. Mask:0.7066 . LR: 0.0284. Time: 60.38\n",
      "2022-04-13 21:33:37,349 - INFO - train -   epoch:30, iter: 192. loss: 0.2800. loss_u: 0.2503. loss_x: 0.0297. Mask:0.7098 . LR: 0.0284. Time: 63.10\n",
      "2022-04-13 21:34:38,571 - INFO - train -   epoch:30, iter: 256. loss: 0.2781. loss_u: 0.2501. loss_x: 0.0280. Mask:0.7109 . LR: 0.0284. Time: 61.22\n",
      "2022-04-13 21:34:42,705 - INFO - train -   Epoch 30. Top1: 82.7943. Top5: 98.4314. best_acc: 82.7943 in epoch 30\n",
      "2022-04-13 21:35:45,584 - INFO - train -   epoch:31, iter: 64. loss: 0.2874. loss_u: 0.2622. loss_x: 0.0252. Mask:0.7148 . LR: 0.0283. Time: 62.87\n",
      "2022-04-13 21:36:46,946 - INFO - train -   epoch:31, iter: 128. loss: 0.2821. loss_u: 0.2577. loss_x: 0.0244. Mask:0.7238 . LR: 0.0283. Time: 61.36\n",
      "2022-04-13 21:37:47,523 - INFO - train -   epoch:31, iter: 192. loss: 0.2786. loss_u: 0.2550. loss_x: 0.0236. Mask:0.7205 . LR: 0.0283. Time: 60.57\n",
      "2022-04-13 21:38:49,005 - INFO - train -   epoch:31, iter: 256. loss: 0.2798. loss_u: 0.2543. loss_x: 0.0256. Mask:0.7216 . LR: 0.0282. Time: 61.48\n",
      "2022-04-13 21:38:53,146 - INFO - train -   Epoch 31. Top1: 80.5414. Top5: 98.3467. best_acc: 82.7943 in epoch 30\n",
      "2022-04-13 21:39:55,640 - INFO - train -   epoch:32, iter: 64. loss: 0.2837. loss_u: 0.2558. loss_x: 0.0278. Mask:0.7252 . LR: 0.0282. Time: 62.49\n",
      "2022-04-13 21:40:53,065 - INFO - train -   epoch:32, iter: 128. loss: 0.2855. loss_u: 0.2564. loss_x: 0.0291. Mask:0.7203 . LR: 0.0282. Time: 57.42\n",
      "2022-04-13 21:41:50,233 - INFO - train -   epoch:32, iter: 192. loss: 0.2828. loss_u: 0.2535. loss_x: 0.0293. Mask:0.7186 . LR: 0.0282. Time: 57.17\n",
      "2022-04-13 21:42:47,839 - INFO - train -   epoch:32, iter: 256. loss: 0.2820. loss_u: 0.2534. loss_x: 0.0286. Mask:0.7195 . LR: 0.0281. Time: 57.60\n",
      "2022-04-13 21:42:52,038 - INFO - train -   Epoch 32. Top1: 82.2674. Top5: 98.8190. best_acc: 82.7943 in epoch 30\n",
      "2022-04-13 21:43:54,237 - INFO - train -   epoch:33, iter: 64. loss: 0.2944. loss_u: 0.2620. loss_x: 0.0324. Mask:0.7167 . LR: 0.0281. Time: 62.20\n",
      "2022-04-13 21:44:55,336 - INFO - train -   epoch:33, iter: 128. loss: 0.2887. loss_u: 0.2539. loss_x: 0.0348. Mask:0.7145 . LR: 0.0281. Time: 61.10\n",
      "2022-04-13 21:45:53,796 - INFO - train -   epoch:33, iter: 192. loss: 0.2889. loss_u: 0.2528. loss_x: 0.0361. Mask:0.7063 . LR: 0.0281. Time: 58.46\n",
      "2022-04-13 21:46:53,736 - INFO - train -   epoch:33, iter: 256. loss: 0.2873. loss_u: 0.2512. loss_x: 0.0362. Mask:0.7082 . LR: 0.0280. Time: 59.94\n",
      "2022-04-13 21:46:57,857 - INFO - train -   Epoch 33. Top1: 81.1955. Top5: 99.0007. best_acc: 82.7943 in epoch 30\n",
      "2022-04-13 21:48:01,683 - INFO - train -   epoch:34, iter: 64. loss: 0.2848. loss_u: 0.2461. loss_x: 0.0387. Mask:0.7069 . LR: 0.0280. Time: 63.82\n",
      "2022-04-13 21:48:59,428 - INFO - train -   epoch:34, iter: 128. loss: 0.2851. loss_u: 0.2499. loss_x: 0.0352. Mask:0.7125 . LR: 0.0280. Time: 57.74\n",
      "2022-04-13 21:49:59,050 - INFO - train -   epoch:34, iter: 192. loss: 0.2818. loss_u: 0.2508. loss_x: 0.0310. Mask:0.7162 . LR: 0.0279. Time: 59.62\n",
      "2022-04-13 21:50:58,747 - INFO - train -   epoch:34, iter: 256. loss: 0.2828. loss_u: 0.2507. loss_x: 0.0321. Mask:0.7165 . LR: 0.0279. Time: 59.69\n",
      "2022-04-13 21:51:02,822 - INFO - train -   Epoch 34. Top1: 83.7088. Top5: 98.6555. best_acc: 83.7088 in epoch 34\n",
      "2022-04-13 21:52:05,606 - INFO - train -   epoch:35, iter: 64. loss: 0.2829. loss_u: 0.2510. loss_x: 0.0320. Mask:0.7141 . LR: 0.0279. Time: 62.78\n",
      "2022-04-13 21:53:06,080 - INFO - train -   epoch:35, iter: 128. loss: 0.2832. loss_u: 0.2509. loss_x: 0.0323. Mask:0.7146 . LR: 0.0278. Time: 60.47\n",
      "2022-04-13 21:54:08,112 - INFO - train -   epoch:35, iter: 192. loss: 0.2838. loss_u: 0.2533. loss_x: 0.0305. Mask:0.7189 . LR: 0.0278. Time: 62.03\n",
      "2022-04-13 21:55:10,033 - INFO - train -   epoch:35, iter: 256. loss: 0.2859. loss_u: 0.2541. loss_x: 0.0318. Mask:0.7212 . LR: 0.0278. Time: 61.92\n",
      "2022-04-13 21:55:14,181 - INFO - train -   Epoch 35. Top1: 84.2297. Top5: 99.0189. best_acc: 84.2297 in epoch 35\n",
      "2022-04-13 21:56:18,663 - INFO - train -   epoch:36, iter: 64. loss: 0.2656. loss_u: 0.2440. loss_x: 0.0216. Mask:0.7354 . LR: 0.0278. Time: 64.48\n",
      "2022-04-13 21:57:18,815 - INFO - train -   epoch:36, iter: 128. loss: 0.2625. loss_u: 0.2430. loss_x: 0.0195. Mask:0.7400 . LR: 0.0277. Time: 60.15\n",
      "2022-04-13 21:58:19,204 - INFO - train -   epoch:36, iter: 192. loss: 0.2654. loss_u: 0.2448. loss_x: 0.0206. Mask:0.7411 . LR: 0.0277. Time: 60.39\n",
      "2022-04-13 21:59:19,058 - INFO - train -   epoch:36, iter: 256. loss: 0.2680. loss_u: 0.2465. loss_x: 0.0215. Mask:0.7388 . LR: 0.0277. Time: 59.85\n",
      "2022-04-13 21:59:23,412 - INFO - train -   Epoch 36. Top1: 80.8685. Top5: 98.5465. best_acc: 84.2297 in epoch 35\n",
      "2022-04-13 22:00:26,271 - INFO - train -   epoch:37, iter: 64. loss: 0.2778. loss_u: 0.2569. loss_x: 0.0209. Mask:0.7544 . LR: 0.0276. Time: 62.86\n",
      "2022-04-13 22:01:25,000 - INFO - train -   epoch:37, iter: 128. loss: 0.2799. loss_u: 0.2567. loss_x: 0.0232. Mask:0.7442 . LR: 0.0276. Time: 58.73\n",
      "2022-04-13 22:02:23,048 - INFO - train -   epoch:37, iter: 192. loss: 0.2845. loss_u: 0.2569. loss_x: 0.0276. Mask:0.7376 . LR: 0.0276. Time: 58.05\n",
      "2022-04-13 22:03:21,586 - INFO - train -   epoch:37, iter: 256. loss: 0.2813. loss_u: 0.2531. loss_x: 0.0282. Mask:0.7376 . LR: 0.0275. Time: 58.54\n",
      "2022-04-13 22:03:25,807 - INFO - train -   Epoch 37. Top1: 84.5203. Top5: 98.5647. best_acc: 84.5203 in epoch 37\n",
      "2022-04-13 22:04:30,589 - INFO - train -   epoch:38, iter: 64. loss: 0.2862. loss_u: 0.2514. loss_x: 0.0348. Mask:0.7250 . LR: 0.0275. Time: 64.78\n",
      "2022-04-13 22:05:31,293 - INFO - train -   epoch:38, iter: 128. loss: 0.2824. loss_u: 0.2481. loss_x: 0.0343. Mask:0.7245 . LR: 0.0275. Time: 60.70\n",
      "2022-04-13 22:06:31,946 - INFO - train -   epoch:38, iter: 192. loss: 0.2856. loss_u: 0.2523. loss_x: 0.0333. Mask:0.7201 . LR: 0.0274. Time: 60.65\n",
      "2022-04-13 22:07:34,480 - INFO - train -   epoch:38, iter: 256. loss: 0.2864. loss_u: 0.2532. loss_x: 0.0333. Mask:0.7235 . LR: 0.0274. Time: 62.53\n",
      "2022-04-13 22:07:38,615 - INFO - train -   Epoch 38. Top1: 83.5514. Top5: 99.0007. best_acc: 84.5203 in epoch 37\n",
      "2022-04-13 22:08:44,307 - INFO - train -   epoch:39, iter: 64. loss: 0.2757. loss_u: 0.2532. loss_x: 0.0225. Mask:0.7414 . LR: 0.0274. Time: 65.69\n",
      "2022-04-13 22:09:46,185 - INFO - train -   epoch:39, iter: 128. loss: 0.2733. loss_u: 0.2476. loss_x: 0.0257. Mask:0.7362 . LR: 0.0273. Time: 61.87\n",
      "2022-04-13 22:10:48,559 - INFO - train -   epoch:39, iter: 192. loss: 0.2719. loss_u: 0.2470. loss_x: 0.0249. Mask:0.7347 . LR: 0.0273. Time: 62.37\n",
      "2022-04-13 22:11:51,298 - INFO - train -   epoch:39, iter: 256. loss: 0.2726. loss_u: 0.2456. loss_x: 0.0270. Mask:0.7306 . LR: 0.0273. Time: 62.74\n",
      "2022-04-13 22:11:55,186 - INFO - train -   Epoch 39. Top1: 82.9336. Top5: 98.7827. best_acc: 84.5203 in epoch 37\n",
      "2022-04-13 22:13:00,622 - INFO - train -   epoch:40, iter: 64. loss: 0.2691. loss_u: 0.2440. loss_x: 0.0251. Mask:0.7384 . LR: 0.0272. Time: 65.43\n",
      "2022-04-13 22:14:02,485 - INFO - train -   epoch:40, iter: 128. loss: 0.2645. loss_u: 0.2417. loss_x: 0.0229. Mask:0.7461 . LR: 0.0272. Time: 61.86\n",
      "2022-04-13 22:15:07,978 - INFO - train -   epoch:40, iter: 192. loss: 0.2665. loss_u: 0.2432. loss_x: 0.0233. Mask:0.7462 . LR: 0.0272. Time: 65.49\n",
      "2022-04-13 22:16:09,403 - INFO - train -   epoch:40, iter: 256. loss: 0.2685. loss_u: 0.2450. loss_x: 0.0236. Mask:0.7456 . LR: 0.0271. Time: 61.42\n",
      "2022-04-13 22:16:13,598 - INFO - train -   Epoch 40. Top1: 83.2667. Top5: 98.7645. best_acc: 84.5203 in epoch 37\n",
      "2022-04-13 22:17:14,510 - INFO - train -   epoch:41, iter: 64. loss: 0.2676. loss_u: 0.2490. loss_x: 0.0186. Mask:0.7501 . LR: 0.0271. Time: 60.91\n",
      "2022-04-13 22:18:12,181 - INFO - train -   epoch:41, iter: 128. loss: 0.2637. loss_u: 0.2427. loss_x: 0.0210. Mask:0.7488 . LR: 0.0271. Time: 57.67\n",
      "2022-04-13 22:19:13,477 - INFO - train -   epoch:41, iter: 192. loss: 0.2667. loss_u: 0.2443. loss_x: 0.0224. Mask:0.7479 . LR: 0.0270. Time: 61.29\n",
      "2022-04-13 22:20:11,674 - INFO - train -   epoch:41, iter: 256. loss: 0.2691. loss_u: 0.2446. loss_x: 0.0245. Mask:0.7461 . LR: 0.0270. Time: 58.20\n",
      "2022-04-13 22:20:15,801 - INFO - train -   Epoch 41. Top1: 83.0366. Top5: 98.8735. best_acc: 84.5203 in epoch 37\n",
      "2022-04-13 22:21:18,483 - INFO - train -   epoch:42, iter: 64. loss: 0.2754. loss_u: 0.2542. loss_x: 0.0212. Mask:0.7492 . LR: 0.0270. Time: 62.68\n",
      "2022-04-13 22:22:15,563 - INFO - train -   epoch:42, iter: 128. loss: 0.2740. loss_u: 0.2543. loss_x: 0.0197. Mask:0.7529 . LR: 0.0269. Time: 57.08\n",
      "2022-04-13 22:23:13,824 - INFO - train -   epoch:42, iter: 192. loss: 0.2748. loss_u: 0.2529. loss_x: 0.0218. Mask:0.7483 . LR: 0.0269. Time: 58.26\n",
      "2022-04-13 22:24:10,215 - INFO - train -   epoch:42, iter: 256. loss: 0.2720. loss_u: 0.2505. loss_x: 0.0215. Mask:0.7495 . LR: 0.0269. Time: 56.39\n",
      "2022-04-13 22:24:14,285 - INFO - train -   Epoch 42. Top1: 84.7808. Top5: 99.0552. best_acc: 84.7808 in epoch 42\n",
      "2022-04-13 22:25:16,731 - INFO - train -   epoch:43, iter: 64. loss: 0.2615. loss_u: 0.2407. loss_x: 0.0208. Mask:0.7476 . LR: 0.0268. Time: 62.44\n",
      "2022-04-13 22:26:19,563 - INFO - train -   epoch:43, iter: 128. loss: 0.2644. loss_u: 0.2439. loss_x: 0.0205. Mask:0.7505 . LR: 0.0268. Time: 62.83\n",
      "2022-04-13 22:27:19,932 - INFO - train -   epoch:43, iter: 192. loss: 0.2716. loss_u: 0.2460. loss_x: 0.0256. Mask:0.7473 . LR: 0.0268. Time: 60.37\n",
      "2022-04-13 22:28:24,126 - INFO - train -   epoch:43, iter: 256. loss: 0.2698. loss_u: 0.2446. loss_x: 0.0251. Mask:0.7454 . LR: 0.0267. Time: 64.19\n",
      "2022-04-13 22:28:28,317 - INFO - train -   Epoch 43. Top1: 85.0896. Top5: 99.2733. best_acc: 85.0896 in epoch 43\n",
      "2022-04-13 22:29:30,144 - INFO - train -   epoch:44, iter: 64. loss: 0.2639. loss_u: 0.2454. loss_x: 0.0185. Mask:0.7595 . LR: 0.0267. Time: 61.82\n",
      "2022-04-13 22:30:30,188 - INFO - train -   epoch:44, iter: 128. loss: 0.2757. loss_u: 0.2504. loss_x: 0.0252. Mask:0.7553 . LR: 0.0266. Time: 60.04\n",
      "2022-04-13 22:31:28,761 - INFO - train -   epoch:44, iter: 192. loss: 0.2708. loss_u: 0.2462. loss_x: 0.0246. Mask:0.7524 . LR: 0.0266. Time: 58.57\n",
      "2022-04-13 22:32:27,536 - INFO - train -   epoch:44, iter: 256. loss: 0.2720. loss_u: 0.2474. loss_x: 0.0246. Mask:0.7524 . LR: 0.0266. Time: 58.77\n",
      "2022-04-13 22:32:31,738 - INFO - train -   Epoch 44. Top1: 86.1919. Top5: 99.2914. best_acc: 86.1919 in epoch 44\n",
      "2022-04-13 22:33:35,626 - INFO - train -   epoch:45, iter: 64. loss: 0.2684. loss_u: 0.2456. loss_x: 0.0228. Mask:0.7526 . LR: 0.0265. Time: 63.88\n",
      "2022-04-13 22:34:35,472 - INFO - train -   epoch:45, iter: 128. loss: 0.2759. loss_u: 0.2471. loss_x: 0.0288. Mask:0.7490 . LR: 0.0265. Time: 59.84\n",
      "2022-04-13 22:35:34,190 - INFO - train -   epoch:45, iter: 192. loss: 0.2767. loss_u: 0.2480. loss_x: 0.0287. Mask:0.7528 . LR: 0.0265. Time: 58.72\n",
      "2022-04-13 22:36:33,135 - INFO - train -   epoch:45, iter: 256. loss: 0.2787. loss_u: 0.2483. loss_x: 0.0304. Mask:0.7512 . LR: 0.0264. Time: 58.94\n",
      "2022-04-13 22:36:37,113 - INFO - train -   Epoch 45. Top1: 83.0608. Top5: 98.8009. best_acc: 86.1919 in epoch 44\n",
      "2022-04-13 22:37:39,733 - INFO - train -   epoch:46, iter: 64. loss: 0.2766. loss_u: 0.2521. loss_x: 0.0245. Mask:0.7516 . LR: 0.0264. Time: 62.62\n",
      "2022-04-13 22:38:39,355 - INFO - train -   epoch:46, iter: 128. loss: 0.2721. loss_u: 0.2485. loss_x: 0.0235. Mask:0.7518 . LR: 0.0263. Time: 59.62\n",
      "2022-04-13 22:39:38,818 - INFO - train -   epoch:46, iter: 192. loss: 0.2669. loss_u: 0.2450. loss_x: 0.0220. Mask:0.7550 . LR: 0.0263. Time: 59.46\n",
      "2022-04-13 22:40:39,702 - INFO - train -   epoch:46, iter: 256. loss: 0.2659. loss_u: 0.2450. loss_x: 0.0209. Mask:0.7553 . LR: 0.0263. Time: 60.88\n",
      "2022-04-13 22:40:43,894 - INFO - train -   Epoch 46. Top1: 84.3932. Top5: 99.2188. best_acc: 86.1919 in epoch 44\n",
      "2022-04-13 22:41:45,707 - INFO - train -   epoch:47, iter: 64. loss: 0.2654. loss_u: 0.2428. loss_x: 0.0227. Mask:0.7704 . LR: 0.0262. Time: 61.81\n",
      "2022-04-13 22:42:42,924 - INFO - train -   epoch:47, iter: 128. loss: 0.2633. loss_u: 0.2438. loss_x: 0.0195. Mask:0.7725 . LR: 0.0262. Time: 57.21\n",
      "2022-04-13 22:43:40,673 - INFO - train -   epoch:47, iter: 192. loss: 0.2649. loss_u: 0.2447. loss_x: 0.0201. Mask:0.7733 . LR: 0.0261. Time: 57.75\n",
      "2022-04-13 22:44:40,345 - INFO - train -   epoch:47, iter: 256. loss: 0.2650. loss_u: 0.2458. loss_x: 0.0193. Mask:0.7726 . LR: 0.0261. Time: 59.67\n",
      "2022-04-13 22:44:44,461 - INFO - train -   Epoch 47. Top1: 83.0608. Top5: 99.4004. best_acc: 86.1919 in epoch 44\n",
      "2022-04-13 22:45:48,784 - INFO - train -   epoch:48, iter: 64. loss: 0.2687. loss_u: 0.2415. loss_x: 0.0272. Mask:0.7614 . LR: 0.0261. Time: 64.32\n",
      "2022-04-13 22:46:49,965 - INFO - train -   epoch:48, iter: 128. loss: 0.2752. loss_u: 0.2449. loss_x: 0.0304. Mask:0.7533 . LR: 0.0260. Time: 61.18\n",
      "2022-04-13 22:47:50,701 - INFO - train -   epoch:48, iter: 192. loss: 0.2755. loss_u: 0.2473. loss_x: 0.0282. Mask:0.7539 . LR: 0.0260. Time: 60.73\n",
      "2022-04-13 22:48:50,971 - INFO - train -   epoch:48, iter: 256. loss: 0.2762. loss_u: 0.2483. loss_x: 0.0280. Mask:0.7586 . LR: 0.0259. Time: 60.27\n",
      "2022-04-13 22:48:55,252 - INFO - train -   Epoch 48. Top1: 84.8656. Top5: 99.1461. best_acc: 86.1919 in epoch 44\n",
      "2022-04-13 22:49:57,099 - INFO - train -   epoch:49, iter: 64. loss: 0.2771. loss_u: 0.2483. loss_x: 0.0289. Mask:0.7603 . LR: 0.0259. Time: 61.84\n",
      "2022-04-13 22:50:55,092 - INFO - train -   epoch:49, iter: 128. loss: 0.2754. loss_u: 0.2519. loss_x: 0.0235. Mask:0.7636 . LR: 0.0259. Time: 57.99\n",
      "2022-04-13 22:51:53,208 - INFO - train -   epoch:49, iter: 192. loss: 0.2771. loss_u: 0.2517. loss_x: 0.0255. Mask:0.7618 . LR: 0.0258. Time: 58.11\n",
      "2022-04-13 22:52:50,681 - INFO - train -   epoch:49, iter: 256. loss: 0.2740. loss_u: 0.2498. loss_x: 0.0242. Mask:0.7636 . LR: 0.0258. Time: 57.47\n",
      "2022-04-13 22:52:54,632 - INFO - train -   Epoch 49. Top1: 85.4651. Top5: 98.9826. best_acc: 86.1919 in epoch 44\n",
      "2022-04-13 22:53:56,951 - INFO - train -   epoch:50, iter: 64. loss: 0.2627. loss_u: 0.2415. loss_x: 0.0212. Mask:0.7697 . LR: 0.0257. Time: 62.32\n",
      "2022-04-13 22:54:56,901 - INFO - train -   epoch:50, iter: 128. loss: 0.2643. loss_u: 0.2408. loss_x: 0.0235. Mask:0.7691 . LR: 0.0257. Time: 59.95\n",
      "2022-04-13 22:55:55,617 - INFO - train -   epoch:50, iter: 192. loss: 0.2663. loss_u: 0.2431. loss_x: 0.0232. Mask:0.7701 . LR: 0.0257. Time: 58.71\n",
      "2022-04-13 22:56:55,904 - INFO - train -   epoch:50, iter: 256. loss: 0.2672. loss_u: 0.2451. loss_x: 0.0221. Mask:0.7710 . LR: 0.0256. Time: 60.29\n",
      "2022-04-13 22:56:59,977 - INFO - train -   Epoch 50. Top1: 87.3365. Top5: 99.2006. best_acc: 87.3365 in epoch 50\n",
      "2022-04-13 22:58:03,301 - INFO - train -   epoch:51, iter: 64. loss: 0.2844. loss_u: 0.2488. loss_x: 0.0357. Mask:0.7648 . LR: 0.0256. Time: 63.32\n",
      "2022-04-13 22:59:02,121 - INFO - train -   epoch:51, iter: 128. loss: 0.2736. loss_u: 0.2467. loss_x: 0.0268. Mask:0.7675 . LR: 0.0255. Time: 58.82\n",
      "2022-04-13 23:00:01,851 - INFO - train -   epoch:51, iter: 192. loss: 0.2671. loss_u: 0.2436. loss_x: 0.0235. Mask:0.7723 . LR: 0.0255. Time: 59.73\n",
      "2022-04-13 23:00:59,632 - INFO - train -   epoch:51, iter: 256. loss: 0.2700. loss_u: 0.2449. loss_x: 0.0251. Mask:0.7710 . LR: 0.0254. Time: 57.78\n",
      "2022-04-13 23:01:03,784 - INFO - train -   Epoch 51. Top1: 84.7202. Top5: 99.3823. best_acc: 87.3365 in epoch 50\n",
      "2022-04-13 23:02:08,800 - INFO - train -   epoch:52, iter: 64. loss: 0.2722. loss_u: 0.2430. loss_x: 0.0292. Mask:0.7584 . LR: 0.0254. Time: 65.01\n",
      "2022-04-13 23:03:08,520 - INFO - train -   epoch:52, iter: 128. loss: 0.2719. loss_u: 0.2440. loss_x: 0.0279. Mask:0.7657 . LR: 0.0254. Time: 59.72\n",
      "2022-04-13 23:04:08,245 - INFO - train -   epoch:52, iter: 192. loss: 0.2694. loss_u: 0.2435. loss_x: 0.0259. Mask:0.7657 . LR: 0.0253. Time: 59.72\n",
      "2022-04-13 23:05:07,673 - INFO - train -   epoch:52, iter: 256. loss: 0.2706. loss_u: 0.2444. loss_x: 0.0261. Mask:0.7679 . LR: 0.0253. Time: 59.43\n",
      "2022-04-13 23:05:11,721 - INFO - train -   Epoch 52. Top1: 86.4826. Top5: 99.2551. best_acc: 87.3365 in epoch 50\n",
      "2022-04-13 23:06:15,260 - INFO - train -   epoch:53, iter: 64. loss: 0.2704. loss_u: 0.2423. loss_x: 0.0281. Mask:0.7682 . LR: 0.0252. Time: 63.54\n",
      "2022-04-13 23:07:16,971 - INFO - train -   epoch:53, iter: 128. loss: 0.2751. loss_u: 0.2458. loss_x: 0.0293. Mask:0.7674 . LR: 0.0252. Time: 61.71\n",
      "2022-04-13 23:08:14,679 - INFO - train -   epoch:53, iter: 192. loss: 0.2744. loss_u: 0.2470. loss_x: 0.0274. Mask:0.7681 . LR: 0.0251. Time: 57.71\n",
      "2022-04-13 23:09:13,105 - INFO - train -   epoch:53, iter: 256. loss: 0.2740. loss_u: 0.2465. loss_x: 0.0275. Mask:0.7678 . LR: 0.0251. Time: 58.42\n",
      "2022-04-13 23:09:17,161 - INFO - train -   Epoch 53. Top1: 86.6642. Top5: 99.5094. best_acc: 87.3365 in epoch 50\n",
      "2022-04-13 23:10:20,744 - INFO - train -   epoch:54, iter: 64. loss: 0.2643. loss_u: 0.2437. loss_x: 0.0206. Mask:0.7798 . LR: 0.0251. Time: 63.58\n",
      "2022-04-13 23:11:23,492 - INFO - train -   epoch:54, iter: 128. loss: 0.2682. loss_u: 0.2476. loss_x: 0.0206. Mask:0.7779 . LR: 0.0250. Time: 62.75\n",
      "2022-04-13 23:12:24,687 - INFO - train -   epoch:54, iter: 192. loss: 0.2685. loss_u: 0.2478. loss_x: 0.0207. Mask:0.7794 . LR: 0.0250. Time: 61.19\n",
      "2022-04-13 23:13:26,810 - INFO - train -   epoch:54, iter: 256. loss: 0.2675. loss_u: 0.2479. loss_x: 0.0197. Mask:0.7826 . LR: 0.0249. Time: 62.12\n",
      "2022-04-13 23:13:30,787 - INFO - train -   Epoch 54. Top1: 88.2146. Top5: 99.4004. best_acc: 88.2146 in epoch 54\n",
      "2022-04-13 23:14:31,017 - INFO - train -   epoch:55, iter: 64. loss: 0.2670. loss_u: 0.2442. loss_x: 0.0228. Mask:0.7908 . LR: 0.0249. Time: 60.22\n",
      "2022-04-13 23:15:30,554 - INFO - train -   epoch:55, iter: 128. loss: 0.2709. loss_u: 0.2457. loss_x: 0.0252. Mask:0.7851 . LR: 0.0248. Time: 59.54\n",
      "2022-04-13 23:16:30,222 - INFO - train -   epoch:55, iter: 192. loss: 0.2718. loss_u: 0.2454. loss_x: 0.0265. Mask:0.7818 . LR: 0.0248. Time: 59.67\n",
      "2022-04-13 23:17:28,756 - INFO - train -   epoch:55, iter: 256. loss: 0.2743. loss_u: 0.2464. loss_x: 0.0279. Mask:0.7808 . LR: 0.0247. Time: 58.53\n",
      "2022-04-13 23:17:32,788 - INFO - train -   Epoch 55. Top1: 87.2214. Top5: 99.4731. best_acc: 88.2146 in epoch 54\n",
      "2022-04-13 23:18:36,030 - INFO - train -   epoch:56, iter: 64. loss: 0.2760. loss_u: 0.2443. loss_x: 0.0318. Mask:0.7658 . LR: 0.0247. Time: 63.24\n",
      "2022-04-13 23:19:36,207 - INFO - train -   epoch:56, iter: 128. loss: 0.2714. loss_u: 0.2440. loss_x: 0.0274. Mask:0.7686 . LR: 0.0246. Time: 60.18\n",
      "2022-04-13 23:20:33,897 - INFO - train -   epoch:56, iter: 192. loss: 0.2682. loss_u: 0.2448. loss_x: 0.0234. Mask:0.7762 . LR: 0.0246. Time: 57.69\n",
      "2022-04-13 23:21:34,429 - INFO - train -   epoch:56, iter: 256. loss: 0.2661. loss_u: 0.2432. loss_x: 0.0229. Mask:0.7779 . LR: 0.0246. Time: 60.53\n",
      "2022-04-13 23:21:38,630 - INFO - train -   Epoch 56. Top1: 87.6635. Top5: 99.0371. best_acc: 88.2146 in epoch 54\n",
      "2022-04-13 23:22:39,730 - INFO - train -   epoch:57, iter: 64. loss: 0.2736. loss_u: 0.2494. loss_x: 0.0241. Mask:0.7873 . LR: 0.0245. Time: 61.10\n",
      "2022-04-13 23:23:38,056 - INFO - train -   epoch:57, iter: 128. loss: 0.2707. loss_u: 0.2467. loss_x: 0.0240. Mask:0.7846 . LR: 0.0245. Time: 58.32\n",
      "2022-04-13 23:24:38,590 - INFO - train -   epoch:57, iter: 192. loss: 0.2697. loss_u: 0.2466. loss_x: 0.0231. Mask:0.7852 . LR: 0.0244. Time: 60.53\n",
      "2022-04-13 23:25:37,455 - INFO - train -   epoch:57, iter: 256. loss: 0.2692. loss_u: 0.2471. loss_x: 0.0221. Mask:0.7872 . LR: 0.0244. Time: 58.86\n",
      "2022-04-13 23:25:41,626 - INFO - train -   Epoch 57. Top1: 87.4516. Top5: 99.4186. best_acc: 88.2146 in epoch 54\n",
      "2022-04-13 23:26:43,958 - INFO - train -   epoch:58, iter: 64. loss: 0.2537. loss_u: 0.2371. loss_x: 0.0166. Mask:0.7881 . LR: 0.0243. Time: 62.33\n",
      "2022-04-13 23:27:41,721 - INFO - train -   epoch:58, iter: 128. loss: 0.2608. loss_u: 0.2416. loss_x: 0.0191. Mask:0.7848 . LR: 0.0243. Time: 57.76\n",
      "2022-04-13 23:28:40,615 - INFO - train -   epoch:58, iter: 192. loss: 0.2643. loss_u: 0.2453. loss_x: 0.0190. Mask:0.7848 . LR: 0.0242. Time: 58.89\n",
      "2022-04-13 23:29:41,377 - INFO - train -   epoch:58, iter: 256. loss: 0.2642. loss_u: 0.2430. loss_x: 0.0211. Mask:0.7824 . LR: 0.0242. Time: 60.76\n",
      "2022-04-13 23:29:45,629 - INFO - train -   Epoch 58. Top1: 86.0344. Top5: 98.7766. best_acc: 88.2146 in epoch 54\n",
      "2022-04-13 23:30:48,859 - INFO - train -   epoch:59, iter: 64. loss: 0.2823. loss_u: 0.2516. loss_x: 0.0307. Mask:0.7642 . LR: 0.0241. Time: 63.23\n",
      "2022-04-13 23:31:51,605 - INFO - train -   epoch:59, iter: 128. loss: 0.2807. loss_u: 0.2506. loss_x: 0.0301. Mask:0.7669 . LR: 0.0241. Time: 62.74\n",
      "2022-04-13 23:32:53,421 - INFO - train -   epoch:59, iter: 192. loss: 0.2744. loss_u: 0.2474. loss_x: 0.0270. Mask:0.7755 . LR: 0.0240. Time: 61.81\n",
      "2022-04-13 23:33:54,093 - INFO - train -   epoch:59, iter: 256. loss: 0.2701. loss_u: 0.2454. loss_x: 0.0248. Mask:0.7789 . LR: 0.0240. Time: 60.67\n",
      "2022-04-13 23:33:58,048 - INFO - train -   Epoch 59. Top1: 86.6097. Top5: 98.8917. best_acc: 88.2146 in epoch 54\n",
      "2022-04-13 23:35:02,274 - INFO - train -   epoch:60, iter: 64. loss: 0.2512. loss_u: 0.2337. loss_x: 0.0175. Mask:0.7875 . LR: 0.0239. Time: 64.22\n",
      "2022-04-13 23:36:03,816 - INFO - train -   epoch:60, iter: 128. loss: 0.2526. loss_u: 0.2359. loss_x: 0.0168. Mask:0.7937 . LR: 0.0239. Time: 61.54\n",
      "2022-04-13 23:37:06,102 - INFO - train -   epoch:60, iter: 192. loss: 0.2527. loss_u: 0.2372. loss_x: 0.0155. Mask:0.7934 . LR: 0.0238. Time: 62.28\n",
      "2022-04-13 23:38:08,626 - INFO - train -   epoch:60, iter: 256. loss: 0.2549. loss_u: 0.2391. loss_x: 0.0158. Mask:0.7943 . LR: 0.0238. Time: 62.52\n",
      "2022-04-13 23:38:12,784 - INFO - train -   Epoch 60. Top1: 87.3849. Top5: 99.0371. best_acc: 88.2146 in epoch 54\n",
      "2022-04-13 23:39:17,676 - INFO - train -   epoch:61, iter: 64. loss: 0.2552. loss_u: 0.2399. loss_x: 0.0152. Mask:0.7967 . LR: 0.0237. Time: 64.89\n",
      "2022-04-13 23:40:19,876 - INFO - train -   epoch:61, iter: 128. loss: 0.2630. loss_u: 0.2438. loss_x: 0.0191. Mask:0.7926 . LR: 0.0237. Time: 62.20\n",
      "2022-04-13 23:41:21,323 - INFO - train -   epoch:61, iter: 192. loss: 0.2658. loss_u: 0.2433. loss_x: 0.0224. Mask:0.7867 . LR: 0.0236. Time: 61.45\n",
      "2022-04-13 23:42:24,472 - INFO - train -   epoch:61, iter: 256. loss: 0.2645. loss_u: 0.2438. loss_x: 0.0207. Mask:0.7864 . LR: 0.0236. Time: 63.15\n",
      "2022-04-13 23:42:28,534 - INFO - train -   Epoch 61. Top1: 87.7786. Top5: 99.2369. best_acc: 88.2146 in epoch 54\n",
      "2022-04-13 23:43:32,931 - INFO - train -   epoch:62, iter: 64. loss: 0.2585. loss_u: 0.2392. loss_x: 0.0192. Mask:0.7944 . LR: 0.0235. Time: 64.39\n",
      "2022-04-13 23:44:33,147 - INFO - train -   epoch:62, iter: 128. loss: 0.2589. loss_u: 0.2389. loss_x: 0.0200. Mask:0.7939 . LR: 0.0235. Time: 60.21\n",
      "2022-04-13 23:45:31,866 - INFO - train -   epoch:62, iter: 192. loss: 0.2586. loss_u: 0.2389. loss_x: 0.0197. Mask:0.7927 . LR: 0.0234. Time: 58.72\n",
      "2022-04-13 23:46:32,999 - INFO - train -   epoch:62, iter: 256. loss: 0.2579. loss_u: 0.2388. loss_x: 0.0191. Mask:0.7919 . LR: 0.0234. Time: 61.13\n",
      "2022-04-13 23:46:36,997 - INFO - train -   Epoch 62. Top1: 85.5560. Top5: 99.0007. best_acc: 88.2146 in epoch 54\n",
      "2022-04-13 23:47:39,728 - INFO - train -   epoch:63, iter: 64. loss: 0.2675. loss_u: 0.2488. loss_x: 0.0187. Mask:0.7916 . LR: 0.0233. Time: 62.73\n",
      "2022-04-13 23:48:41,004 - INFO - train -   epoch:63, iter: 128. loss: 0.2633. loss_u: 0.2447. loss_x: 0.0186. Mask:0.7912 . LR: 0.0233. Time: 61.27\n",
      "2022-04-13 23:49:42,060 - INFO - train -   epoch:63, iter: 192. loss: 0.2640. loss_u: 0.2447. loss_x: 0.0193. Mask:0.7918 . LR: 0.0232. Time: 61.05\n",
      "2022-04-13 23:50:40,205 - INFO - train -   epoch:63, iter: 256. loss: 0.2609. loss_u: 0.2425. loss_x: 0.0184. Mask:0.7943 . LR: 0.0232. Time: 58.14\n",
      "2022-04-13 23:50:44,312 - INFO - train -   Epoch 63. Top1: 88.6810. Top5: 99.3823. best_acc: 88.6810 in epoch 63\n",
      "2022-04-13 23:51:44,610 - INFO - train -   epoch:64, iter: 64. loss: 0.2732. loss_u: 0.2474. loss_x: 0.0258. Mask:0.7872 . LR: 0.0231. Time: 60.29\n",
      "2022-04-13 23:52:44,073 - INFO - train -   epoch:64, iter: 128. loss: 0.2689. loss_u: 0.2445. loss_x: 0.0244. Mask:0.7852 . LR: 0.0231. Time: 59.46\n",
      "2022-04-13 23:53:42,683 - INFO - train -   epoch:64, iter: 192. loss: 0.2706. loss_u: 0.2451. loss_x: 0.0255. Mask:0.7841 . LR: 0.0230. Time: 58.61\n",
      "2022-04-13 23:54:42,893 - INFO - train -   epoch:64, iter: 256. loss: 0.2678. loss_u: 0.2457. loss_x: 0.0221. Mask:0.7892 . LR: 0.0230. Time: 60.21\n",
      "2022-04-13 23:54:47,102 - INFO - train -   Epoch 64. Top1: 87.1669. Top5: 99.2369. best_acc: 88.6810 in epoch 63\n",
      "2022-04-13 23:55:47,562 - INFO - train -   epoch:65, iter: 64. loss: 0.2618. loss_u: 0.2413. loss_x: 0.0205. Mask:0.7975 . LR: 0.0229. Time: 60.46\n",
      "2022-04-13 23:56:47,365 - INFO - train -   epoch:65, iter: 128. loss: 0.2626. loss_u: 0.2405. loss_x: 0.0221. Mask:0.7949 . LR: 0.0229. Time: 59.80\n",
      "2022-04-13 23:57:45,699 - INFO - train -   epoch:65, iter: 192. loss: 0.2615. loss_u: 0.2409. loss_x: 0.0206. Mask:0.7943 . LR: 0.0228. Time: 58.33\n",
      "2022-04-13 23:58:44,610 - INFO - train -   epoch:65, iter: 256. loss: 0.2581. loss_u: 0.2387. loss_x: 0.0194. Mask:0.7930 . LR: 0.0228. Time: 58.91\n",
      "2022-04-13 23:58:48,848 - INFO - train -   Epoch 65. Top1: 88.7657. Top5: 99.5458. best_acc: 88.7657 in epoch 65\n",
      "2022-04-13 23:59:52,257 - INFO - train -   epoch:66, iter: 64. loss: 0.2601. loss_u: 0.2378. loss_x: 0.0223. Mask:0.7803 . LR: 0.0227. Time: 63.40\n",
      "2022-04-14 00:00:52,975 - INFO - train -   epoch:66, iter: 128. loss: 0.2559. loss_u: 0.2365. loss_x: 0.0194. Mask:0.7871 . LR: 0.0227. Time: 60.72\n",
      "2022-04-14 00:01:54,862 - INFO - train -   epoch:66, iter: 192. loss: 0.2611. loss_u: 0.2389. loss_x: 0.0222. Mask:0.7843 . LR: 0.0226. Time: 61.88\n",
      "2022-04-14 00:02:57,041 - INFO - train -   epoch:66, iter: 256. loss: 0.2577. loss_u: 0.2373. loss_x: 0.0204. Mask:0.7872 . LR: 0.0226. Time: 62.18\n",
      "2022-04-14 00:03:01,036 - INFO - train -   Epoch 66. Top1: 86.0223. Top5: 99.1824. best_acc: 88.7657 in epoch 65\n",
      "2022-04-14 00:04:04,573 - INFO - train -   epoch:67, iter: 64. loss: 0.2633. loss_u: 0.2426. loss_x: 0.0207. Mask:0.7966 . LR: 0.0225. Time: 63.53\n",
      "2022-04-14 00:05:05,619 - INFO - train -   epoch:67, iter: 128. loss: 0.2632. loss_u: 0.2425. loss_x: 0.0207. Mask:0.7935 . LR: 0.0225. Time: 61.04\n",
      "2022-04-14 00:06:06,216 - INFO - train -   epoch:67, iter: 192. loss: 0.2646. loss_u: 0.2435. loss_x: 0.0211. Mask:0.7959 . LR: 0.0224. Time: 60.59\n",
      "2022-04-14 00:07:08,319 - INFO - train -   epoch:67, iter: 256. loss: 0.2635. loss_u: 0.2425. loss_x: 0.0211. Mask:0.7948 . LR: 0.0224. Time: 62.10\n",
      "2022-04-14 00:07:12,485 - INFO - train -   Epoch 67. Top1: 87.0882. Top5: 99.2551. best_acc: 88.7657 in epoch 65\n",
      "2022-04-14 00:08:14,497 - INFO - train -   epoch:68, iter: 64. loss: 0.2483. loss_u: 0.2345. loss_x: 0.0138. Mask:0.8058 . LR: 0.0223. Time: 62.01\n",
      "2022-04-14 00:09:14,723 - INFO - train -   epoch:68, iter: 128. loss: 0.2535. loss_u: 0.2377. loss_x: 0.0158. Mask:0.8061 . LR: 0.0222. Time: 60.22\n",
      "2022-04-14 00:10:14,037 - INFO - train -   epoch:68, iter: 192. loss: 0.2556. loss_u: 0.2370. loss_x: 0.0185. Mask:0.8004 . LR: 0.0222. Time: 59.31\n",
      "2022-04-14 00:11:14,111 - INFO - train -   epoch:68, iter: 256. loss: 0.2554. loss_u: 0.2363. loss_x: 0.0191. Mask:0.8012 . LR: 0.0221. Time: 60.07\n",
      "2022-04-14 00:11:18,321 - INFO - train -   Epoch 68. Top1: 86.1555. Top5: 99.1642. best_acc: 88.7657 in epoch 65\n",
      "2022-04-14 00:12:20,632 - INFO - train -   epoch:69, iter: 64. loss: 0.2674. loss_u: 0.2453. loss_x: 0.0221. Mask:0.7906 . LR: 0.0221. Time: 62.31\n",
      "2022-04-14 00:13:20,796 - INFO - train -   epoch:69, iter: 128. loss: 0.2640. loss_u: 0.2377. loss_x: 0.0263. Mask:0.7822 . LR: 0.0220. Time: 60.16\n",
      "2022-04-14 00:14:20,274 - INFO - train -   epoch:69, iter: 192. loss: 0.2636. loss_u: 0.2396. loss_x: 0.0240. Mask:0.7884 . LR: 0.0220. Time: 59.48\n",
      "2022-04-14 00:15:19,667 - INFO - train -   epoch:69, iter: 256. loss: 0.2618. loss_u: 0.2382. loss_x: 0.0236. Mask:0.7919 . LR: 0.0219. Time: 59.39\n",
      "2022-04-14 00:15:23,784 - INFO - train -   Epoch 69. Top1: 85.7558. Top5: 99.2733. best_acc: 88.7657 in epoch 65\n",
      "2022-04-14 00:16:27,402 - INFO - train -   epoch:70, iter: 64. loss: 0.2593. loss_u: 0.2339. loss_x: 0.0254. Mask:0.7856 . LR: 0.0219. Time: 63.61\n",
      "2022-04-14 00:17:27,439 - INFO - train -   epoch:70, iter: 128. loss: 0.2683. loss_u: 0.2388. loss_x: 0.0295. Mask:0.7795 . LR: 0.0218. Time: 60.03\n",
      "2022-04-14 00:18:28,099 - INFO - train -   epoch:70, iter: 192. loss: 0.2706. loss_u: 0.2412. loss_x: 0.0294. Mask:0.7823 . LR: 0.0218. Time: 60.66\n",
      "2022-04-14 00:19:28,689 - INFO - train -   epoch:70, iter: 256. loss: 0.2666. loss_u: 0.2410. loss_x: 0.0256. Mask:0.7871 . LR: 0.0217. Time: 60.59\n",
      "2022-04-14 00:19:32,747 - INFO - train -   Epoch 70. Top1: 88.5659. Top5: 99.4186. best_acc: 88.7657 in epoch 65\n",
      "2022-04-14 00:20:37,119 - INFO - train -   epoch:71, iter: 64. loss: 0.2588. loss_u: 0.2395. loss_x: 0.0193. Mask:0.8020 . LR: 0.0216. Time: 64.37\n",
      "2022-04-14 00:21:40,120 - INFO - train -   epoch:71, iter: 128. loss: 0.2648. loss_u: 0.2449. loss_x: 0.0199. Mask:0.8047 . LR: 0.0216. Time: 63.00\n",
      "2022-04-14 00:22:42,494 - INFO - train -   epoch:71, iter: 192. loss: 0.2634. loss_u: 0.2441. loss_x: 0.0193. Mask:0.8026 . LR: 0.0215. Time: 62.37\n",
      "2022-04-14 00:23:48,190 - INFO - train -   epoch:71, iter: 256. loss: 0.2642. loss_u: 0.2444. loss_x: 0.0198. Mask:0.8011 . LR: 0.0215. Time: 65.69\n",
      "2022-04-14 00:23:52,093 - INFO - train -   Epoch 71. Top1: 88.1480. Top5: 99.6548. best_acc: 88.7657 in epoch 65\n",
      "2022-04-14 00:24:58,877 - INFO - train -   epoch:72, iter: 64. loss: 0.2533. loss_u: 0.2368. loss_x: 0.0165. Mask:0.8000 . LR: 0.0214. Time: 66.78\n",
      "2022-04-14 00:26:00,452 - INFO - train -   epoch:72, iter: 128. loss: 0.2568. loss_u: 0.2401. loss_x: 0.0166. Mask:0.8009 . LR: 0.0214. Time: 61.57\n",
      "2022-04-14 00:27:00,844 - INFO - train -   epoch:72, iter: 192. loss: 0.2526. loss_u: 0.2370. loss_x: 0.0155. Mask:0.8023 . LR: 0.0213. Time: 60.39\n",
      "2022-04-14 00:28:00,882 - INFO - train -   epoch:72, iter: 256. loss: 0.2511. loss_u: 0.2360. loss_x: 0.0151. Mask:0.8057 . LR: 0.0212. Time: 60.04\n",
      "2022-04-14 00:28:04,997 - INFO - train -   Epoch 72. Top1: 86.9913. Top5: 99.2006. best_acc: 88.7657 in epoch 65\n",
      "2022-04-14 00:29:09,972 - INFO - train -   epoch:73, iter: 64. loss: 0.2592. loss_u: 0.2351. loss_x: 0.0240. Mask:0.7981 . LR: 0.0212. Time: 64.97\n",
      "2022-04-14 00:30:14,677 - INFO - train -   epoch:73, iter: 128. loss: 0.2610. loss_u: 0.2407. loss_x: 0.0203. Mask:0.7951 . LR: 0.0211. Time: 64.70\n",
      "2022-04-14 00:31:20,250 - INFO - train -   epoch:73, iter: 192. loss: 0.2568. loss_u: 0.2375. loss_x: 0.0193. Mask:0.7976 . LR: 0.0211. Time: 65.57\n",
      "2022-04-14 00:32:24,062 - INFO - train -   epoch:73, iter: 256. loss: 0.2557. loss_u: 0.2371. loss_x: 0.0187. Mask:0.8017 . LR: 0.0210. Time: 63.81\n",
      "2022-04-14 00:32:28,027 - INFO - train -   Epoch 73. Top1: 88.9111. Top5: 99.5276. best_acc: 88.9111 in epoch 73\n",
      "2022-04-14 00:33:35,733 - INFO - train -   epoch:74, iter: 64. loss: 0.2555. loss_u: 0.2386. loss_x: 0.0168. Mask:0.8068 . LR: 0.0210. Time: 67.70\n",
      "2022-04-14 00:34:38,485 - INFO - train -   epoch:74, iter: 128. loss: 0.2586. loss_u: 0.2432. loss_x: 0.0155. Mask:0.8051 . LR: 0.0209. Time: 62.75\n",
      "2022-04-14 00:35:41,707 - INFO - train -   epoch:74, iter: 192. loss: 0.2563. loss_u: 0.2394. loss_x: 0.0169. Mask:0.8048 . LR: 0.0208. Time: 63.22\n",
      "2022-04-14 00:36:44,108 - INFO - train -   epoch:74, iter: 256. loss: 0.2548. loss_u: 0.2378. loss_x: 0.0170. Mask:0.8028 . LR: 0.0208. Time: 62.40\n",
      "2022-04-14 00:36:48,078 - INFO - train -   Epoch 74. Top1: 88.9172. Top5: 99.6003. best_acc: 88.9172 in epoch 74\n",
      "2022-04-14 00:37:55,418 - INFO - train -   epoch:75, iter: 64. loss: 0.2522. loss_u: 0.2370. loss_x: 0.0152. Mask:0.7980 . LR: 0.0207. Time: 67.34\n",
      "2022-04-14 00:38:59,345 - INFO - train -   epoch:75, iter: 128. loss: 0.2528. loss_u: 0.2354. loss_x: 0.0174. Mask:0.7992 . LR: 0.0207. Time: 63.93\n",
      "2022-04-14 00:40:02,704 - INFO - train -   epoch:75, iter: 192. loss: 0.2514. loss_u: 0.2358. loss_x: 0.0155. Mask:0.8033 . LR: 0.0206. Time: 63.36\n",
      "2022-04-14 00:41:08,323 - INFO - train -   epoch:75, iter: 256. loss: 0.2546. loss_u: 0.2385. loss_x: 0.0162. Mask:0.8037 . LR: 0.0206. Time: 65.62\n",
      "2022-04-14 00:41:12,379 - INFO - train -   Epoch 75. Top1: 89.4440. Top5: 99.6003. best_acc: 89.4440 in epoch 75\n",
      "2022-04-14 00:42:19,483 - INFO - train -   epoch:76, iter: 64. loss: 0.2602. loss_u: 0.2416. loss_x: 0.0186. Mask:0.8053 . LR: 0.0205. Time: 67.10\n",
      "2022-04-14 00:43:24,061 - INFO - train -   epoch:76, iter: 128. loss: 0.2533. loss_u: 0.2362. loss_x: 0.0171. Mask:0.8023 . LR: 0.0204. Time: 64.58\n",
      "2022-04-14 00:44:24,545 - INFO - train -   epoch:76, iter: 192. loss: 0.2531. loss_u: 0.2351. loss_x: 0.0180. Mask:0.8053 . LR: 0.0204. Time: 60.48\n",
      "2022-04-14 00:45:23,891 - INFO - train -   epoch:76, iter: 256. loss: 0.2549. loss_u: 0.2376. loss_x: 0.0174. Mask:0.8058 . LR: 0.0203. Time: 59.34\n",
      "2022-04-14 00:45:27,980 - INFO - train -   Epoch 76. Top1: 86.9913. Top5: 99.2188. best_acc: 89.4440 in epoch 75\n",
      "2022-04-14 00:46:34,090 - INFO - train -   epoch:77, iter: 64. loss: 0.2512. loss_u: 0.2375. loss_x: 0.0136. Mask:0.8147 . LR: 0.0203. Time: 66.11\n",
      "2022-04-14 00:47:33,896 - INFO - train -   epoch:77, iter: 128. loss: 0.2496. loss_u: 0.2358. loss_x: 0.0137. Mask:0.8170 . LR: 0.0202. Time: 59.80\n",
      "2022-04-14 00:48:33,973 - INFO - train -   epoch:77, iter: 192. loss: 0.2468. loss_u: 0.2340. loss_x: 0.0128. Mask:0.8191 . LR: 0.0201. Time: 60.08\n",
      "2022-04-14 00:49:33,632 - INFO - train -   epoch:77, iter: 256. loss: 0.2501. loss_u: 0.2360. loss_x: 0.0141. Mask:0.8176 . LR: 0.0201. Time: 59.66\n",
      "2022-04-14 00:49:37,625 - INFO - train -   Epoch 77. Top1: 87.8815. Top5: 99.5094. best_acc: 89.4440 in epoch 75\n",
      "2022-04-14 00:50:42,264 - INFO - train -   epoch:78, iter: 64. loss: 0.2508. loss_u: 0.2363. loss_x: 0.0145. Mask:0.8160 . LR: 0.0200. Time: 64.63\n",
      "2022-04-14 00:51:43,167 - INFO - train -   epoch:78, iter: 128. loss: 0.2517. loss_u: 0.2370. loss_x: 0.0147. Mask:0.8147 . LR: 0.0200. Time: 60.90\n",
      "2022-04-14 00:52:43,795 - INFO - train -   epoch:78, iter: 192. loss: 0.2533. loss_u: 0.2378. loss_x: 0.0156. Mask:0.8130 . LR: 0.0199. Time: 60.63\n",
      "2022-04-14 00:53:43,390 - INFO - train -   epoch:78, iter: 256. loss: 0.2546. loss_u: 0.2390. loss_x: 0.0156. Mask:0.8100 . LR: 0.0198. Time: 59.59\n",
      "2022-04-14 00:53:47,343 - INFO - train -   Epoch 78. Top1: 87.4394. Top5: 99.1642. best_acc: 89.4440 in epoch 75\n",
      "2022-04-14 00:54:48,726 - INFO - train -   epoch:79, iter: 64. loss: 0.2427. loss_u: 0.2289. loss_x: 0.0138. Mask:0.8142 . LR: 0.0198. Time: 61.38\n",
      "2022-04-14 00:55:47,080 - INFO - train -   epoch:79, iter: 128. loss: 0.2511. loss_u: 0.2342. loss_x: 0.0168. Mask:0.8120 . LR: 0.0197. Time: 58.35\n",
      "2022-04-14 00:56:46,838 - INFO - train -   epoch:79, iter: 192. loss: 0.2495. loss_u: 0.2340. loss_x: 0.0155. Mask:0.8122 . LR: 0.0197. Time: 59.76\n",
      "2022-04-14 00:57:45,238 - INFO - train -   epoch:79, iter: 256. loss: 0.2496. loss_u: 0.2340. loss_x: 0.0156. Mask:0.8123 . LR: 0.0196. Time: 58.40\n",
      "2022-04-14 00:57:49,168 - INFO - train -   Epoch 79. Top1: 88.0027. Top5: 99.0189. best_acc: 89.4440 in epoch 75\n",
      "2022-04-14 00:58:50,015 - INFO - train -   epoch:80, iter: 64. loss: 0.2617. loss_u: 0.2394. loss_x: 0.0223. Mask:0.8073 . LR: 0.0195. Time: 60.84\n",
      "2022-04-14 00:59:49,349 - INFO - train -   epoch:80, iter: 128. loss: 0.2571. loss_u: 0.2390. loss_x: 0.0181. Mask:0.8146 . LR: 0.0195. Time: 59.33\n",
      "2022-04-14 01:00:49,908 - INFO - train -   epoch:80, iter: 192. loss: 0.2552. loss_u: 0.2387. loss_x: 0.0165. Mask:0.8112 . LR: 0.0194. Time: 60.56\n",
      "2022-04-14 01:01:50,409 - INFO - train -   epoch:80, iter: 256. loss: 0.2522. loss_u: 0.2355. loss_x: 0.0168. Mask:0.8098 . LR: 0.0194. Time: 60.50\n",
      "2022-04-14 01:01:54,578 - INFO - train -   Epoch 80. Top1: 90.2071. Top5: 99.5094. best_acc: 90.2071 in epoch 80\n",
      "2022-04-14 01:02:56,651 - INFO - train -   epoch:81, iter: 64. loss: 0.2542. loss_u: 0.2331. loss_x: 0.0211. Mask:0.8089 . LR: 0.0193. Time: 62.07\n",
      "2022-04-14 01:03:56,062 - INFO - train -   epoch:81, iter: 128. loss: 0.2513. loss_u: 0.2302. loss_x: 0.0211. Mask:0.7987 . LR: 0.0192. Time: 59.41\n",
      "2022-04-14 01:04:55,897 - INFO - train -   epoch:81, iter: 192. loss: 0.2498. loss_u: 0.2317. loss_x: 0.0182. Mask:0.8017 . LR: 0.0192. Time: 59.83\n",
      "2022-04-14 01:05:57,168 - INFO - train -   epoch:81, iter: 256. loss: 0.2516. loss_u: 0.2336. loss_x: 0.0180. Mask:0.8046 . LR: 0.0191. Time: 61.27\n",
      "2022-04-14 01:06:01,154 - INFO - train -   Epoch 81. Top1: 87.5182. Top5: 99.2369. best_acc: 90.2071 in epoch 80\n",
      "2022-04-14 01:07:04,912 - INFO - train -   epoch:82, iter: 64. loss: 0.2488. loss_u: 0.2266. loss_x: 0.0222. Mask:0.8015 . LR: 0.0190. Time: 63.75\n",
      "2022-04-14 01:08:08,318 - INFO - train -   epoch:82, iter: 128. loss: 0.2500. loss_u: 0.2301. loss_x: 0.0199. Mask:0.8021 . LR: 0.0190. Time: 63.40\n",
      "2022-04-14 01:09:09,935 - INFO - train -   epoch:82, iter: 192. loss: 0.2481. loss_u: 0.2305. loss_x: 0.0176. Mask:0.8076 . LR: 0.0189. Time: 61.61\n",
      "2022-04-14 01:10:11,814 - INFO - train -   epoch:82, iter: 256. loss: 0.2482. loss_u: 0.2324. loss_x: 0.0158. Mask:0.8108 . LR: 0.0189. Time: 61.88\n",
      "2022-04-14 01:10:15,970 - INFO - train -   Epoch 82. Top1: 89.6923. Top5: 99.5094. best_acc: 90.2071 in epoch 80\n",
      "2022-04-14 01:11:18,673 - INFO - train -   epoch:83, iter: 64. loss: 0.2484. loss_u: 0.2311. loss_x: 0.0173. Mask:0.8178 . LR: 0.0188. Time: 62.70\n",
      "2022-04-14 01:12:17,865 - INFO - train -   epoch:83, iter: 128. loss: 0.2515. loss_u: 0.2350. loss_x: 0.0165. Mask:0.8142 . LR: 0.0187. Time: 59.19\n",
      "2022-04-14 01:13:16,932 - INFO - train -   epoch:83, iter: 192. loss: 0.2472. loss_u: 0.2319. loss_x: 0.0153. Mask:0.8153 . LR: 0.0187. Time: 59.07\n",
      "2022-04-14 01:14:15,521 - INFO - train -   epoch:83, iter: 256. loss: 0.2450. loss_u: 0.2316. loss_x: 0.0134. Mask:0.8179 . LR: 0.0186. Time: 58.59\n",
      "2022-04-14 01:14:19,647 - INFO - train -   Epoch 83. Top1: 89.4562. Top5: 99.6185. best_acc: 90.2071 in epoch 80\n",
      "2022-04-14 01:15:24,677 - INFO - train -   epoch:84, iter: 64. loss: 0.2485. loss_u: 0.2335. loss_x: 0.0150. Mask:0.8163 . LR: 0.0185. Time: 65.03\n",
      "2022-04-14 01:16:24,701 - INFO - train -   epoch:84, iter: 128. loss: 0.2457. loss_u: 0.2316. loss_x: 0.0141. Mask:0.8141 . LR: 0.0185. Time: 60.02\n",
      "2022-04-14 01:17:24,943 - INFO - train -   epoch:84, iter: 192. loss: 0.2447. loss_u: 0.2318. loss_x: 0.0129. Mask:0.8156 . LR: 0.0184. Time: 60.24\n",
      "2022-04-14 01:18:25,110 - INFO - train -   epoch:84, iter: 256. loss: 0.2427. loss_u: 0.2301. loss_x: 0.0126. Mask:0.8146 . LR: 0.0183. Time: 60.17\n",
      "2022-04-14 01:18:29,165 - INFO - train -   Epoch 84. Top1: 90.7825. Top5: 99.5276. best_acc: 90.7825 in epoch 84\n",
      "2022-04-14 01:19:30,354 - INFO - train -   epoch:85, iter: 64. loss: 0.2511. loss_u: 0.2382. loss_x: 0.0129. Mask:0.8168 . LR: 0.0183. Time: 61.18\n",
      "2022-04-14 01:20:27,831 - INFO - train -   epoch:85, iter: 128. loss: 0.2471. loss_u: 0.2335. loss_x: 0.0136. Mask:0.8169 . LR: 0.0182. Time: 57.47\n",
      "2022-04-14 01:21:25,295 - INFO - train -   epoch:85, iter: 192. loss: 0.2457. loss_u: 0.2320. loss_x: 0.0137. Mask:0.8187 . LR: 0.0182. Time: 57.46\n",
      "2022-04-14 01:22:24,991 - INFO - train -   epoch:85, iter: 256. loss: 0.2445. loss_u: 0.2315. loss_x: 0.0130. Mask:0.8196 . LR: 0.0181. Time: 59.69\n",
      "2022-04-14 01:22:29,008 - INFO - train -   Epoch 85. Top1: 88.0329. Top5: 99.6548. best_acc: 90.7825 in epoch 84\n",
      "2022-04-14 01:23:29,197 - INFO - train -   epoch:86, iter: 64. loss: 0.2493. loss_u: 0.2354. loss_x: 0.0139. Mask:0.8176 . LR: 0.0180. Time: 60.18\n",
      "2022-04-14 01:24:29,019 - INFO - train -   epoch:86, iter: 128. loss: 0.2475. loss_u: 0.2324. loss_x: 0.0151. Mask:0.8164 . LR: 0.0180. Time: 59.82\n",
      "2022-04-14 01:25:28,985 - INFO - train -   epoch:86, iter: 192. loss: 0.2450. loss_u: 0.2307. loss_x: 0.0144. Mask:0.8153 . LR: 0.0179. Time: 59.96\n",
      "2022-04-14 01:26:29,506 - INFO - train -   epoch:86, iter: 256. loss: 0.2444. loss_u: 0.2303. loss_x: 0.0140. Mask:0.8180 . LR: 0.0178. Time: 60.52\n",
      "2022-04-14 01:26:33,477 - INFO - train -   Epoch 86. Top1: 91.4971. Top5: 99.7275. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 01:27:39,039 - INFO - train -   epoch:87, iter: 64. loss: 0.2365. loss_u: 0.2285. loss_x: 0.0079. Mask:0.8297 . LR: 0.0178. Time: 65.56\n",
      "2022-04-14 01:28:39,613 - INFO - train -   epoch:87, iter: 128. loss: 0.2376. loss_u: 0.2302. loss_x: 0.0075. Mask:0.8337 . LR: 0.0177. Time: 60.57\n",
      "2022-04-14 01:29:40,598 - INFO - train -   epoch:87, iter: 192. loss: 0.2369. loss_u: 0.2289. loss_x: 0.0080. Mask:0.8338 . LR: 0.0176. Time: 60.98\n",
      "2022-04-14 01:30:41,173 - INFO - train -   epoch:87, iter: 256. loss: 0.2397. loss_u: 0.2319. loss_x: 0.0077. Mask:0.8345 . LR: 0.0176. Time: 60.57\n",
      "2022-04-14 01:30:45,281 - INFO - train -   Epoch 87. Top1: 91.3275. Top5: 99.6366. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 01:31:49,014 - INFO - train -   epoch:88, iter: 64. loss: 0.2606. loss_u: 0.2365. loss_x: 0.0241. Mask:0.8170 . LR: 0.0175. Time: 63.73\n",
      "2022-04-14 01:32:50,783 - INFO - train -   epoch:88, iter: 128. loss: 0.2626. loss_u: 0.2390. loss_x: 0.0237. Mask:0.8128 . LR: 0.0174. Time: 61.77\n",
      "2022-04-14 01:33:53,021 - INFO - train -   epoch:88, iter: 192. loss: 0.2561. loss_u: 0.2370. loss_x: 0.0191. Mask:0.8153 . LR: 0.0174. Time: 62.24\n",
      "2022-04-14 01:34:54,396 - INFO - train -   epoch:88, iter: 256. loss: 0.2514. loss_u: 0.2351. loss_x: 0.0163. Mask:0.8186 . LR: 0.0173. Time: 61.37\n",
      "2022-04-14 01:34:58,392 - INFO - train -   Epoch 88. Top1: 89.2805. Top5: 99.5094. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 01:36:05,134 - INFO - train -   epoch:89, iter: 64. loss: 0.2483. loss_u: 0.2363. loss_x: 0.0121. Mask:0.8281 . LR: 0.0172. Time: 66.74\n",
      "2022-04-14 01:37:06,956 - INFO - train -   epoch:89, iter: 128. loss: 0.2486. loss_u: 0.2361. loss_x: 0.0125. Mask:0.8234 . LR: 0.0172. Time: 61.82\n",
      "2022-04-14 01:38:11,781 - INFO - train -   epoch:89, iter: 192. loss: 0.2511. loss_u: 0.2357. loss_x: 0.0153. Mask:0.8191 . LR: 0.0171. Time: 64.82\n",
      "2022-04-14 01:39:11,683 - INFO - train -   epoch:89, iter: 256. loss: 0.2511. loss_u: 0.2355. loss_x: 0.0156. Mask:0.8174 . LR: 0.0170. Time: 59.90\n",
      "2022-04-14 01:39:15,762 - INFO - train -   Epoch 89. Top1: 88.1117. Top5: 99.4186. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 01:40:17,481 - INFO - train -   epoch:90, iter: 64. loss: 0.2435. loss_u: 0.2287. loss_x: 0.0148. Mask:0.8288 . LR: 0.0170. Time: 61.71\n",
      "2022-04-14 01:41:16,300 - INFO - train -   epoch:90, iter: 128. loss: 0.2452. loss_u: 0.2315. loss_x: 0.0137. Mask:0.8281 . LR: 0.0169. Time: 58.82\n",
      "2022-04-14 01:42:16,561 - INFO - train -   epoch:90, iter: 192. loss: 0.2428. loss_u: 0.2297. loss_x: 0.0131. Mask:0.8281 . LR: 0.0168. Time: 60.26\n",
      "2022-04-14 01:43:18,707 - INFO - train -   epoch:90, iter: 256. loss: 0.2461. loss_u: 0.2324. loss_x: 0.0137. Mask:0.8277 . LR: 0.0168. Time: 62.14\n",
      "2022-04-14 01:43:22,766 - INFO - train -   Epoch 90. Top1: 90.1526. Top5: 99.7093. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 01:44:24,082 - INFO - train -   epoch:91, iter: 64. loss: 0.2427. loss_u: 0.2290. loss_x: 0.0138. Mask:0.8161 . LR: 0.0167. Time: 61.31\n",
      "2022-04-14 01:45:23,599 - INFO - train -   epoch:91, iter: 128. loss: 0.2424. loss_u: 0.2298. loss_x: 0.0126. Mask:0.8211 . LR: 0.0166. Time: 59.51\n",
      "2022-04-14 01:46:22,894 - INFO - train -   epoch:91, iter: 192. loss: 0.2448. loss_u: 0.2314. loss_x: 0.0134. Mask:0.8230 . LR: 0.0166. Time: 59.29\n",
      "2022-04-14 01:47:21,284 - INFO - train -   epoch:91, iter: 256. loss: 0.2434. loss_u: 0.2304. loss_x: 0.0129. Mask:0.8222 . LR: 0.0165. Time: 58.39\n",
      "2022-04-14 01:47:25,429 - INFO - train -   Epoch 91. Top1: 90.4797. Top5: 99.6003. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 01:48:31,100 - INFO - train -   epoch:92, iter: 64. loss: 0.2426. loss_u: 0.2323. loss_x: 0.0102. Mask:0.8293 . LR: 0.0164. Time: 65.67\n",
      "2022-04-14 01:49:31,571 - INFO - train -   epoch:92, iter: 128. loss: 0.2468. loss_u: 0.2346. loss_x: 0.0122. Mask:0.8289 . LR: 0.0164. Time: 60.47\n",
      "2022-04-14 01:50:31,029 - INFO - train -   epoch:92, iter: 192. loss: 0.2437. loss_u: 0.2330. loss_x: 0.0108. Mask:0.8334 . LR: 0.0163. Time: 59.46\n",
      "2022-04-14 01:51:30,270 - INFO - train -   epoch:92, iter: 256. loss: 0.2450. loss_u: 0.2334. loss_x: 0.0116. Mask:0.8334 . LR: 0.0162. Time: 59.24\n",
      "2022-04-14 01:51:34,246 - INFO - train -   Epoch 92. Top1: 90.2616. Top5: 99.5276. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 01:52:35,570 - INFO - train -   epoch:93, iter: 64. loss: 0.2479. loss_u: 0.2312. loss_x: 0.0167. Mask:0.8277 . LR: 0.0162. Time: 61.32\n",
      "2022-04-14 01:53:35,238 - INFO - train -   epoch:93, iter: 128. loss: 0.2447. loss_u: 0.2319. loss_x: 0.0127. Mask:0.8306 . LR: 0.0161. Time: 59.67\n",
      "2022-04-14 01:54:33,594 - INFO - train -   epoch:93, iter: 192. loss: 0.2430. loss_u: 0.2304. loss_x: 0.0126. Mask:0.8288 . LR: 0.0160. Time: 58.35\n",
      "2022-04-14 01:55:34,535 - INFO - train -   epoch:93, iter: 256. loss: 0.2410. loss_u: 0.2294. loss_x: 0.0116. Mask:0.8296 . LR: 0.0160. Time: 60.94\n",
      "2022-04-14 01:55:38,581 - INFO - train -   Epoch 93. Top1: 90.5887. Top5: 99.6730. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 01:56:42,453 - INFO - train -   epoch:94, iter: 64. loss: 0.2342. loss_u: 0.2242. loss_x: 0.0101. Mask:0.8334 . LR: 0.0159. Time: 63.87\n",
      "2022-04-14 01:57:43,913 - INFO - train -   epoch:94, iter: 128. loss: 0.2360. loss_u: 0.2254. loss_x: 0.0106. Mask:0.8328 . LR: 0.0158. Time: 61.46\n",
      "2022-04-14 01:58:44,762 - INFO - train -   epoch:94, iter: 192. loss: 0.2434. loss_u: 0.2299. loss_x: 0.0135. Mask:0.8292 . LR: 0.0158. Time: 60.85\n",
      "2022-04-14 01:59:46,439 - INFO - train -   epoch:94, iter: 256. loss: 0.2448. loss_u: 0.2307. loss_x: 0.0141. Mask:0.8280 . LR: 0.0157. Time: 61.67\n",
      "2022-04-14 01:59:50,489 - INFO - train -   Epoch 94. Top1: 90.3040. Top5: 99.5276. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:00:54,837 - INFO - train -   epoch:95, iter: 64. loss: 0.2476. loss_u: 0.2344. loss_x: 0.0132. Mask:0.8293 . LR: 0.0156. Time: 64.34\n",
      "2022-04-14 02:01:56,538 - INFO - train -   epoch:95, iter: 128. loss: 0.2519. loss_u: 0.2334. loss_x: 0.0185. Mask:0.8258 . LR: 0.0156. Time: 61.70\n",
      "2022-04-14 02:02:56,614 - INFO - train -   epoch:95, iter: 192. loss: 0.2512. loss_u: 0.2330. loss_x: 0.0182. Mask:0.8220 . LR: 0.0155. Time: 60.07\n",
      "2022-04-14 02:03:58,471 - INFO - train -   epoch:95, iter: 256. loss: 0.2503. loss_u: 0.2325. loss_x: 0.0179. Mask:0.8224 . LR: 0.0154. Time: 61.85\n",
      "2022-04-14 02:04:02,506 - INFO - train -   Epoch 95. Top1: 89.1897. Top5: 99.6185. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:05:06,388 - INFO - train -   epoch:96, iter: 64. loss: 0.2474. loss_u: 0.2318. loss_x: 0.0155. Mask:0.8217 . LR: 0.0154. Time: 63.88\n",
      "2022-04-14 02:06:07,422 - INFO - train -   epoch:96, iter: 128. loss: 0.2454. loss_u: 0.2315. loss_x: 0.0139. Mask:0.8280 . LR: 0.0153. Time: 61.03\n",
      "2022-04-14 02:07:07,690 - INFO - train -   epoch:96, iter: 192. loss: 0.2430. loss_u: 0.2294. loss_x: 0.0136. Mask:0.8249 . LR: 0.0152. Time: 60.27\n",
      "2022-04-14 02:08:07,572 - INFO - train -   epoch:96, iter: 256. loss: 0.2430. loss_u: 0.2295. loss_x: 0.0134. Mask:0.8279 . LR: 0.0151. Time: 59.88\n",
      "2022-04-14 02:08:11,652 - INFO - train -   Epoch 96. Top1: 88.7112. Top5: 99.4913. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:09:13,467 - INFO - train -   epoch:97, iter: 64. loss: 0.2488. loss_u: 0.2342. loss_x: 0.0146. Mask:0.8284 . LR: 0.0151. Time: 61.81\n",
      "2022-04-14 02:10:15,191 - INFO - train -   epoch:97, iter: 128. loss: 0.2509. loss_u: 0.2365. loss_x: 0.0144. Mask:0.8269 . LR: 0.0150. Time: 61.72\n",
      "2022-04-14 02:11:15,124 - INFO - train -   epoch:97, iter: 192. loss: 0.2452. loss_u: 0.2316. loss_x: 0.0135. Mask:0.8279 . LR: 0.0149. Time: 59.93\n",
      "2022-04-14 02:12:16,199 - INFO - train -   epoch:97, iter: 256. loss: 0.2427. loss_u: 0.2309. loss_x: 0.0117. Mask:0.8302 . LR: 0.0149. Time: 61.07\n",
      "2022-04-14 02:12:20,450 - INFO - train -   Epoch 97. Top1: 90.6371. Top5: 99.4549. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:13:24,663 - INFO - train -   epoch:98, iter: 64. loss: 0.2414. loss_u: 0.2311. loss_x: 0.0103. Mask:0.8367 . LR: 0.0148. Time: 64.21\n",
      "2022-04-14 02:14:25,218 - INFO - train -   epoch:98, iter: 128. loss: 0.2386. loss_u: 0.2272. loss_x: 0.0114. Mask:0.8309 . LR: 0.0147. Time: 60.55\n",
      "2022-04-14 02:15:23,878 - INFO - train -   epoch:98, iter: 192. loss: 0.2407. loss_u: 0.2294. loss_x: 0.0113. Mask:0.8320 . LR: 0.0147. Time: 58.66\n",
      "2022-04-14 02:16:23,625 - INFO - train -   epoch:98, iter: 256. loss: 0.2431. loss_u: 0.2313. loss_x: 0.0118. Mask:0.8290 . LR: 0.0146. Time: 59.74\n",
      "2022-04-14 02:16:27,863 - INFO - train -   Epoch 98. Top1: 88.3660. Top5: 99.5821. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:17:31,618 - INFO - train -   epoch:99, iter: 64. loss: 0.2361. loss_u: 0.2263. loss_x: 0.0098. Mask:0.8260 . LR: 0.0145. Time: 63.75\n",
      "2022-04-14 02:18:31,841 - INFO - train -   epoch:99, iter: 128. loss: 0.2371. loss_u: 0.2266. loss_x: 0.0105. Mask:0.8330 . LR: 0.0144. Time: 60.22\n",
      "2022-04-14 02:19:35,292 - INFO - train -   epoch:99, iter: 192. loss: 0.2416. loss_u: 0.2314. loss_x: 0.0102. Mask:0.8362 . LR: 0.0144. Time: 63.45\n",
      "2022-04-14 02:20:34,089 - INFO - train -   epoch:99, iter: 256. loss: 0.2418. loss_u: 0.2319. loss_x: 0.0099. Mask:0.8388 . LR: 0.0143. Time: 58.80\n",
      "2022-04-14 02:20:38,042 - INFO - train -   Epoch 99. Top1: 89.9043. Top5: 99.4549. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:21:41,205 - INFO - train -   epoch:100, iter: 64. loss: 0.2508. loss_u: 0.2381. loss_x: 0.0127. Mask:0.8291 . LR: 0.0142. Time: 63.16\n",
      "2022-04-14 02:22:40,802 - INFO - train -   epoch:100, iter: 128. loss: 0.2459. loss_u: 0.2353. loss_x: 0.0106. Mask:0.8345 . LR: 0.0142. Time: 59.60\n",
      "2022-04-14 02:23:40,557 - INFO - train -   epoch:100, iter: 192. loss: 0.2455. loss_u: 0.2347. loss_x: 0.0108. Mask:0.8345 . LR: 0.0141. Time: 59.75\n",
      "2022-04-14 02:24:40,328 - INFO - train -   epoch:100, iter: 256. loss: 0.2442. loss_u: 0.2337. loss_x: 0.0105. Mask:0.8358 . LR: 0.0140. Time: 59.77\n",
      "2022-04-14 02:24:44,404 - INFO - train -   Epoch 100. Top1: 91.1701. Top5: 99.4731. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:25:46,582 - INFO - train -   epoch:101, iter: 64. loss: 0.2458. loss_u: 0.2341. loss_x: 0.0118. Mask:0.8415 . LR: 0.0139. Time: 62.17\n",
      "2022-04-14 02:26:46,194 - INFO - train -   epoch:101, iter: 128. loss: 0.2409. loss_u: 0.2301. loss_x: 0.0108. Mask:0.8405 . LR: 0.0139. Time: 59.61\n",
      "2022-04-14 02:27:46,020 - INFO - train -   epoch:101, iter: 192. loss: 0.2388. loss_u: 0.2285. loss_x: 0.0103. Mask:0.8436 . LR: 0.0138. Time: 59.82\n",
      "2022-04-14 02:28:45,103 - INFO - train -   epoch:101, iter: 256. loss: 0.2399. loss_u: 0.2292. loss_x: 0.0107. Mask:0.8434 . LR: 0.0137. Time: 59.08\n",
      "2022-04-14 02:28:49,128 - INFO - train -   Epoch 101. Top1: 91.3517. Top5: 99.5821. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:29:53,664 - INFO - train -   epoch:102, iter: 64. loss: 0.2489. loss_u: 0.2332. loss_x: 0.0157. Mask:0.8298 . LR: 0.0137. Time: 64.53\n",
      "2022-04-14 02:30:54,056 - INFO - train -   epoch:102, iter: 128. loss: 0.2418. loss_u: 0.2281. loss_x: 0.0137. Mask:0.8312 . LR: 0.0136. Time: 60.39\n",
      "2022-04-14 02:31:52,231 - INFO - train -   epoch:102, iter: 192. loss: 0.2402. loss_u: 0.2278. loss_x: 0.0123. Mask:0.8341 . LR: 0.0135. Time: 58.17\n",
      "2022-04-14 02:32:49,988 - INFO - train -   epoch:102, iter: 256. loss: 0.2409. loss_u: 0.2282. loss_x: 0.0126. Mask:0.8315 . LR: 0.0134. Time: 57.76\n",
      "2022-04-14 02:32:54,009 - INFO - train -   Epoch 102. Top1: 89.6742. Top5: 99.6003. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:33:58,567 - INFO - train -   epoch:103, iter: 64. loss: 0.2364. loss_u: 0.2273. loss_x: 0.0091. Mask:0.8397 . LR: 0.0134. Time: 64.55\n",
      "2022-04-14 02:35:01,149 - INFO - train -   epoch:103, iter: 128. loss: 0.2375. loss_u: 0.2302. loss_x: 0.0073. Mask:0.8443 . LR: 0.0133. Time: 62.58\n",
      "2022-04-14 02:36:03,673 - INFO - train -   epoch:103, iter: 192. loss: 0.2433. loss_u: 0.2310. loss_x: 0.0123. Mask:0.8410 . LR: 0.0132. Time: 62.52\n",
      "2022-04-14 02:37:04,842 - INFO - train -   epoch:103, iter: 256. loss: 0.2440. loss_u: 0.2303. loss_x: 0.0137. Mask:0.8361 . LR: 0.0132. Time: 61.17\n",
      "2022-04-14 02:37:08,995 - INFO - train -   Epoch 103. Top1: 90.2798. Top5: 99.6548. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:38:10,280 - INFO - train -   epoch:104, iter: 64. loss: 0.2345. loss_u: 0.2213. loss_x: 0.0132. Mask:0.8327 . LR: 0.0131. Time: 61.28\n",
      "2022-04-14 02:39:09,530 - INFO - train -   epoch:104, iter: 128. loss: 0.2340. loss_u: 0.2231. loss_x: 0.0108. Mask:0.8329 . LR: 0.0130. Time: 59.25\n",
      "2022-04-14 02:40:09,091 - INFO - train -   epoch:104, iter: 192. loss: 0.2321. loss_u: 0.2220. loss_x: 0.0101. Mask:0.8320 . LR: 0.0129. Time: 59.56\n",
      "2022-04-14 02:41:10,069 - INFO - train -   epoch:104, iter: 256. loss: 0.2337. loss_u: 0.2231. loss_x: 0.0106. Mask:0.8341 . LR: 0.0129. Time: 60.98\n",
      "2022-04-14 02:41:14,166 - INFO - train -   Epoch 104. Top1: 90.4918. Top5: 99.6730. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:42:16,030 - INFO - train -   epoch:105, iter: 64. loss: 0.2319. loss_u: 0.2243. loss_x: 0.0076. Mask:0.8473 . LR: 0.0128. Time: 61.86\n",
      "2022-04-14 02:43:19,584 - INFO - train -   epoch:105, iter: 128. loss: 0.2352. loss_u: 0.2273. loss_x: 0.0079. Mask:0.8474 . LR: 0.0127. Time: 63.55\n",
      "2022-04-14 02:44:20,266 - INFO - train -   epoch:105, iter: 192. loss: 0.2337. loss_u: 0.2267. loss_x: 0.0070. Mask:0.8491 . LR: 0.0126. Time: 60.68\n",
      "2022-04-14 02:45:19,435 - INFO - train -   epoch:105, iter: 256. loss: 0.2330. loss_u: 0.2258. loss_x: 0.0071. Mask:0.8483 . LR: 0.0126. Time: 59.17\n",
      "2022-04-14 02:45:23,560 - INFO - train -   Epoch 105. Top1: 90.5039. Top5: 99.5821. best_acc: 91.4971 in epoch 86\n",
      "2022-04-14 02:46:26,804 - INFO - train -   epoch:106, iter: 64. loss: 0.2349. loss_u: 0.2288. loss_x: 0.0062. Mask:0.8483 . LR: 0.0125. Time: 63.24\n",
      "2022-04-14 02:47:28,944 - INFO - train -   epoch:106, iter: 128. loss: 0.2370. loss_u: 0.2301. loss_x: 0.0068. Mask:0.8494 . LR: 0.0124. Time: 62.14\n",
      "2022-04-14 02:48:27,267 - INFO - train -   epoch:106, iter: 192. loss: 0.2342. loss_u: 0.2286. loss_x: 0.0057. Mask:0.8512 . LR: 0.0124. Time: 58.32\n",
      "2022-04-14 02:49:29,494 - INFO - train -   epoch:106, iter: 256. loss: 0.2336. loss_u: 0.2275. loss_x: 0.0060. Mask:0.8520 . LR: 0.0123. Time: 62.23\n",
      "2022-04-14 02:49:33,676 - INFO - train -   Epoch 106. Top1: 92.0724. Top5: 99.5640. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 02:50:36,010 - INFO - train -   epoch:107, iter: 64. loss: 0.2247. loss_u: 0.2165. loss_x: 0.0082. Mask:0.8514 . LR: 0.0122. Time: 62.33\n",
      "2022-04-14 02:51:36,498 - INFO - train -   epoch:107, iter: 128. loss: 0.2325. loss_u: 0.2252. loss_x: 0.0073. Mask:0.8542 . LR: 0.0121. Time: 60.48\n",
      "2022-04-14 02:52:35,591 - INFO - train -   epoch:107, iter: 192. loss: 0.2334. loss_u: 0.2251. loss_x: 0.0083. Mask:0.8512 . LR: 0.0121. Time: 59.09\n",
      "2022-04-14 02:53:35,572 - INFO - train -   epoch:107, iter: 256. loss: 0.2335. loss_u: 0.2254. loss_x: 0.0081. Mask:0.8501 . LR: 0.0120. Time: 59.98\n",
      "2022-04-14 02:53:39,494 - INFO - train -   Epoch 107. Top1: 91.6848. Top5: 99.4004. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 02:54:39,365 - INFO - train -   epoch:108, iter: 64. loss: 0.2319. loss_u: 0.2256. loss_x: 0.0062. Mask:0.8557 . LR: 0.0119. Time: 59.87\n",
      "2022-04-14 02:55:36,848 - INFO - train -   epoch:108, iter: 128. loss: 0.2356. loss_u: 0.2273. loss_x: 0.0082. Mask:0.8555 . LR: 0.0118. Time: 57.48\n",
      "2022-04-14 02:56:36,046 - INFO - train -   epoch:108, iter: 192. loss: 0.2377. loss_u: 0.2280. loss_x: 0.0097. Mask:0.8502 . LR: 0.0118. Time: 59.20\n",
      "2022-04-14 02:57:35,709 - INFO - train -   epoch:108, iter: 256. loss: 0.2357. loss_u: 0.2258. loss_x: 0.0099. Mask:0.8502 . LR: 0.0117. Time: 59.66\n",
      "2022-04-14 02:57:39,711 - INFO - train -   Epoch 108. Top1: 91.7878. Top5: 99.5821. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 02:58:40,995 - INFO - train -   epoch:109, iter: 64. loss: 0.2347. loss_u: 0.2260. loss_x: 0.0088. Mask:0.8532 . LR: 0.0116. Time: 61.28\n",
      "2022-04-14 02:59:40,374 - INFO - train -   epoch:109, iter: 128. loss: 0.2338. loss_u: 0.2236. loss_x: 0.0101. Mask:0.8474 . LR: 0.0115. Time: 59.38\n",
      "2022-04-14 03:00:40,019 - INFO - train -   epoch:109, iter: 192. loss: 0.2332. loss_u: 0.2220. loss_x: 0.0112. Mask:0.8462 . LR: 0.0115. Time: 59.64\n",
      "2022-04-14 03:01:39,009 - INFO - train -   epoch:109, iter: 256. loss: 0.2346. loss_u: 0.2227. loss_x: 0.0119. Mask:0.8464 . LR: 0.0114. Time: 58.99\n",
      "2022-04-14 03:01:43,146 - INFO - train -   Epoch 109. Top1: 90.6311. Top5: 99.5094. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 03:02:48,633 - INFO - train -   epoch:110, iter: 64. loss: 0.2364. loss_u: 0.2247. loss_x: 0.0117. Mask:0.8504 . LR: 0.0113. Time: 65.48\n",
      "2022-04-14 03:03:49,942 - INFO - train -   epoch:110, iter: 128. loss: 0.2330. loss_u: 0.2240. loss_x: 0.0089. Mask:0.8545 . LR: 0.0112. Time: 61.31\n",
      "2022-04-14 03:04:49,104 - INFO - train -   epoch:110, iter: 192. loss: 0.2340. loss_u: 0.2250. loss_x: 0.0090. Mask:0.8532 . LR: 0.0112. Time: 59.16\n",
      "2022-04-14 03:05:51,228 - INFO - train -   epoch:110, iter: 256. loss: 0.2344. loss_u: 0.2256. loss_x: 0.0088. Mask:0.8528 . LR: 0.0111. Time: 62.12\n",
      "2022-04-14 03:05:55,415 - INFO - train -   Epoch 110. Top1: 90.6553. Top5: 99.3459. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 03:06:57,890 - INFO - train -   epoch:111, iter: 64. loss: 0.2314. loss_u: 0.2238. loss_x: 0.0076. Mask:0.8569 . LR: 0.0110. Time: 62.47\n",
      "2022-04-14 03:07:59,771 - INFO - train -   epoch:111, iter: 128. loss: 0.2325. loss_u: 0.2253. loss_x: 0.0073. Mask:0.8562 . LR: 0.0109. Time: 61.88\n",
      "2022-04-14 03:08:59,736 - INFO - train -   epoch:111, iter: 192. loss: 0.2332. loss_u: 0.2264. loss_x: 0.0068. Mask:0.8542 . LR: 0.0109. Time: 59.96\n",
      "2022-04-14 03:09:59,644 - INFO - train -   epoch:111, iter: 256. loss: 0.2311. loss_u: 0.2248. loss_x: 0.0064. Mask:0.8526 . LR: 0.0108. Time: 59.91\n",
      "2022-04-14 03:10:03,895 - INFO - train -   Epoch 111. Top1: 91.4184. Top5: 99.3641. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 03:11:04,343 - INFO - train -   epoch:112, iter: 64. loss: 0.2248. loss_u: 0.2178. loss_x: 0.0070. Mask:0.8552 . LR: 0.0107. Time: 60.44\n",
      "2022-04-14 03:12:03,516 - INFO - train -   epoch:112, iter: 128. loss: 0.2232. loss_u: 0.2161. loss_x: 0.0070. Mask:0.8558 . LR: 0.0106. Time: 59.17\n",
      "2022-04-14 03:13:01,619 - INFO - train -   epoch:112, iter: 192. loss: 0.2257. loss_u: 0.2197. loss_x: 0.0060. Mask:0.8577 . LR: 0.0106. Time: 58.10\n",
      "2022-04-14 03:13:59,627 - INFO - train -   epoch:112, iter: 256. loss: 0.2282. loss_u: 0.2214. loss_x: 0.0068. Mask:0.8578 . LR: 0.0105. Time: 58.01\n",
      "2022-04-14 03:14:03,699 - INFO - train -   Epoch 112. Top1: 89.9830. Top5: 99.6185. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 03:15:07,396 - INFO - train -   epoch:113, iter: 64. loss: 0.2299. loss_u: 0.2193. loss_x: 0.0105. Mask:0.8406 . LR: 0.0104. Time: 63.69\n",
      "2022-04-14 03:16:08,859 - INFO - train -   epoch:113, iter: 128. loss: 0.2293. loss_u: 0.2201. loss_x: 0.0092. Mask:0.8433 . LR: 0.0103. Time: 61.46\n",
      "2022-04-14 03:17:12,464 - INFO - train -   epoch:113, iter: 192. loss: 0.2298. loss_u: 0.2218. loss_x: 0.0080. Mask:0.8479 . LR: 0.0103. Time: 63.60\n",
      "2022-04-14 03:18:17,213 - INFO - train -   epoch:113, iter: 256. loss: 0.2316. loss_u: 0.2233. loss_x: 0.0083. Mask:0.8510 . LR: 0.0102. Time: 64.75\n",
      "2022-04-14 03:18:21,404 - INFO - train -   Epoch 113. Top1: 91.4547. Top5: 99.5094. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 03:19:28,041 - INFO - train -   epoch:114, iter: 64. loss: 0.2211. loss_u: 0.2147. loss_x: 0.0064. Mask:0.8593 . LR: 0.0101. Time: 66.63\n",
      "2022-04-14 03:20:27,929 - INFO - train -   epoch:114, iter: 128. loss: 0.2237. loss_u: 0.2170. loss_x: 0.0068. Mask:0.8568 . LR: 0.0100. Time: 59.88\n",
      "2022-04-14 03:21:27,067 - INFO - train -   epoch:114, iter: 192. loss: 0.2268. loss_u: 0.2206. loss_x: 0.0063. Mask:0.8589 . LR: 0.0100. Time: 59.13\n",
      "2022-04-14 03:22:29,012 - INFO - train -   epoch:114, iter: 256. loss: 0.2283. loss_u: 0.2213. loss_x: 0.0070. Mask:0.8587 . LR: 0.0099. Time: 61.94\n",
      "2022-04-14 03:22:32,969 - INFO - train -   Epoch 114. Top1: 91.6606. Top5: 99.7638. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 03:23:37,417 - INFO - train -   epoch:115, iter: 64. loss: 0.2346. loss_u: 0.2266. loss_x: 0.0080. Mask:0.8562 . LR: 0.0098. Time: 64.44\n",
      "2022-04-14 03:24:41,410 - INFO - train -   epoch:115, iter: 128. loss: 0.2337. loss_u: 0.2259. loss_x: 0.0078. Mask:0.8538 . LR: 0.0097. Time: 63.99\n",
      "2022-04-14 03:25:44,002 - INFO - train -   epoch:115, iter: 192. loss: 0.2326. loss_u: 0.2261. loss_x: 0.0066. Mask:0.8557 . LR: 0.0097. Time: 62.59\n",
      "2022-04-14 03:26:44,410 - INFO - train -   epoch:115, iter: 256. loss: 0.2337. loss_u: 0.2267. loss_x: 0.0070. Mask:0.8551 . LR: 0.0096. Time: 60.40\n",
      "2022-04-14 03:26:48,463 - INFO - train -   Epoch 115. Top1: 91.5455. Top5: 99.6548. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 03:27:54,071 - INFO - train -   epoch:116, iter: 64. loss: 0.2288. loss_u: 0.2241. loss_x: 0.0047. Mask:0.8557 . LR: 0.0095. Time: 65.60\n",
      "2022-04-14 03:28:54,796 - INFO - train -   epoch:116, iter: 128. loss: 0.2299. loss_u: 0.2226. loss_x: 0.0073. Mask:0.8527 . LR: 0.0094. Time: 60.72\n",
      "2022-04-14 03:29:56,643 - INFO - train -   epoch:116, iter: 192. loss: 0.2277. loss_u: 0.2215. loss_x: 0.0063. Mask:0.8544 . LR: 0.0094. Time: 61.85\n",
      "2022-04-14 03:30:54,869 - INFO - train -   epoch:116, iter: 256. loss: 0.2260. loss_u: 0.2198. loss_x: 0.0062. Mask:0.8585 . LR: 0.0093. Time: 58.22\n",
      "2022-04-14 03:30:58,828 - INFO - train -   Epoch 116. Top1: 91.6546. Top5: 99.5821. best_acc: 92.0724 in epoch 106\n",
      "2022-04-14 03:32:02,960 - INFO - train -   epoch:117, iter: 64. loss: 0.2325. loss_u: 0.2265. loss_x: 0.0059. Mask:0.8651 . LR: 0.0092. Time: 64.13\n",
      "2022-04-14 03:33:07,814 - INFO - train -   epoch:117, iter: 128. loss: 0.2323. loss_u: 0.2257. loss_x: 0.0067. Mask:0.8644 . LR: 0.0091. Time: 64.85\n",
      "2022-04-14 03:34:08,986 - INFO - train -   epoch:117, iter: 192. loss: 0.2322. loss_u: 0.2262. loss_x: 0.0060. Mask:0.8649 . LR: 0.0090. Time: 61.17\n",
      "2022-04-14 03:35:10,011 - INFO - train -   epoch:117, iter: 256. loss: 0.2304. loss_u: 0.2244. loss_x: 0.0060. Mask:0.8633 . LR: 0.0090. Time: 61.02\n",
      "2022-04-14 03:35:14,184 - INFO - train -   Epoch 117. Top1: 92.3752. Top5: 99.5821. best_acc: 92.3752 in epoch 117\n",
      "2022-04-14 03:36:20,290 - INFO - train -   epoch:118, iter: 64. loss: 0.2180. loss_u: 0.2129. loss_x: 0.0051. Mask:0.8614 . LR: 0.0089. Time: 66.10\n",
      "2022-04-14 03:37:18,818 - INFO - train -   epoch:118, iter: 128. loss: 0.2281. loss_u: 0.2210. loss_x: 0.0071. Mask:0.8641 . LR: 0.0088. Time: 58.53\n",
      "2022-04-14 03:38:19,537 - INFO - train -   epoch:118, iter: 192. loss: 0.2306. loss_u: 0.2235. loss_x: 0.0071. Mask:0.8625 . LR: 0.0087. Time: 60.72\n",
      "2022-04-14 03:39:17,997 - INFO - train -   epoch:118, iter: 256. loss: 0.2302. loss_u: 0.2232. loss_x: 0.0070. Mask:0.8643 . LR: 0.0087. Time: 58.46\n",
      "2022-04-14 03:39:22,119 - INFO - train -   Epoch 118. Top1: 91.5940. Top5: 99.5821. best_acc: 92.3752 in epoch 117\n",
      "2022-04-14 03:40:23,865 - INFO - train -   epoch:119, iter: 64. loss: 0.2311. loss_u: 0.2206. loss_x: 0.0105. Mask:0.8569 . LR: 0.0086. Time: 61.74\n",
      "2022-04-14 03:41:24,706 - INFO - train -   epoch:119, iter: 128. loss: 0.2288. loss_u: 0.2194. loss_x: 0.0093. Mask:0.8575 . LR: 0.0085. Time: 60.84\n",
      "2022-04-14 03:42:23,702 - INFO - train -   epoch:119, iter: 192. loss: 0.2271. loss_u: 0.2186. loss_x: 0.0085. Mask:0.8571 . LR: 0.0084. Time: 58.99\n",
      "2022-04-14 03:43:23,982 - INFO - train -   epoch:119, iter: 256. loss: 0.2297. loss_u: 0.2221. loss_x: 0.0076. Mask:0.8598 . LR: 0.0084. Time: 60.28\n",
      "2022-04-14 03:43:28,222 - INFO - train -   Epoch 119. Top1: 91.8362. Top5: 99.4549. best_acc: 92.3752 in epoch 117\n",
      "2022-04-14 03:44:35,641 - INFO - train -   epoch:120, iter: 64. loss: 0.2237. loss_u: 0.2189. loss_x: 0.0048. Mask:0.8688 . LR: 0.0083. Time: 67.42\n",
      "2022-04-14 03:45:36,607 - INFO - train -   epoch:120, iter: 128. loss: 0.2328. loss_u: 0.2276. loss_x: 0.0052. Mask:0.8682 . LR: 0.0082. Time: 60.96\n",
      "2022-04-14 03:46:38,892 - INFO - train -   epoch:120, iter: 192. loss: 0.2319. loss_u: 0.2260. loss_x: 0.0059. Mask:0.8673 . LR: 0.0081. Time: 62.28\n",
      "2022-04-14 03:47:40,122 - INFO - train -   epoch:120, iter: 256. loss: 0.2309. loss_u: 0.2249. loss_x: 0.0061. Mask:0.8676 . LR: 0.0080. Time: 61.23\n",
      "2022-04-14 03:47:44,435 - INFO - train -   Epoch 120. Top1: 91.3881. Top5: 99.6911. best_acc: 92.3752 in epoch 117\n",
      "2022-04-14 03:48:48,748 - INFO - train -   epoch:121, iter: 64. loss: 0.2311. loss_u: 0.2267. loss_x: 0.0044. Mask:0.8687 . LR: 0.0080. Time: 64.31\n",
      "2022-04-14 03:49:47,547 - INFO - train -   epoch:121, iter: 128. loss: 0.2301. loss_u: 0.2244. loss_x: 0.0057. Mask:0.8668 . LR: 0.0079. Time: 58.80\n",
      "2022-04-14 03:50:49,663 - INFO - train -   epoch:121, iter: 192. loss: 0.2289. loss_u: 0.2226. loss_x: 0.0064. Mask:0.8664 . LR: 0.0078. Time: 62.11\n",
      "2022-04-14 03:51:48,221 - INFO - train -   epoch:121, iter: 256. loss: 0.2284. loss_u: 0.2227. loss_x: 0.0057. Mask:0.8682 . LR: 0.0077. Time: 58.56\n",
      "2022-04-14 03:51:52,376 - INFO - train -   Epoch 121. Top1: 91.5213. Top5: 99.5458. best_acc: 92.3752 in epoch 117\n",
      "2022-04-14 03:52:54,308 - INFO - train -   epoch:122, iter: 64. loss: 0.2314. loss_u: 0.2248. loss_x: 0.0066. Mask:0.8743 . LR: 0.0077. Time: 61.93\n",
      "2022-04-14 03:53:56,459 - INFO - train -   epoch:122, iter: 128. loss: 0.2331. loss_u: 0.2278. loss_x: 0.0053. Mask:0.8738 . LR: 0.0076. Time: 62.15\n",
      "2022-04-14 03:54:57,723 - INFO - train -   epoch:122, iter: 192. loss: 0.2317. loss_u: 0.2258. loss_x: 0.0059. Mask:0.8725 . LR: 0.0075. Time: 61.26\n",
      "2022-04-14 03:56:00,822 - INFO - train -   epoch:122, iter: 256. loss: 0.2310. loss_u: 0.2257. loss_x: 0.0053. Mask:0.8734 . LR: 0.0074. Time: 63.10\n",
      "2022-04-14 03:56:04,654 - INFO - train -   Epoch 122. Top1: 91.0368. Top5: 99.6003. best_acc: 92.3752 in epoch 117\n",
      "2022-04-14 03:57:06,421 - INFO - train -   epoch:123, iter: 64. loss: 0.2254. loss_u: 0.2167. loss_x: 0.0087. Mask:0.8652 . LR: 0.0073. Time: 61.76\n",
      "2022-04-14 03:58:07,371 - INFO - train -   epoch:123, iter: 128. loss: 0.2267. loss_u: 0.2202. loss_x: 0.0065. Mask:0.8649 . LR: 0.0073. Time: 60.95\n",
      "2022-04-14 03:59:07,332 - INFO - train -   epoch:123, iter: 192. loss: 0.2258. loss_u: 0.2199. loss_x: 0.0059. Mask:0.8686 . LR: 0.0072. Time: 59.96\n",
      "2022-04-14 04:00:10,223 - INFO - train -   epoch:123, iter: 256. loss: 0.2235. loss_u: 0.2180. loss_x: 0.0055. Mask:0.8694 . LR: 0.0071. Time: 62.89\n",
      "2022-04-14 04:00:14,132 - INFO - train -   Epoch 123. Top1: 91.5516. Top5: 99.6730. best_acc: 92.3752 in epoch 117\n",
      "2022-04-14 04:01:15,782 - INFO - train -   epoch:124, iter: 64. loss: 0.2219. loss_u: 0.2165. loss_x: 0.0054. Mask:0.8711 . LR: 0.0070. Time: 61.65\n",
      "2022-04-14 04:02:16,426 - INFO - train -   epoch:124, iter: 128. loss: 0.2253. loss_u: 0.2196. loss_x: 0.0057. Mask:0.8719 . LR: 0.0070. Time: 60.64\n",
      "2022-04-14 04:03:18,348 - INFO - train -   epoch:124, iter: 192. loss: 0.2239. loss_u: 0.2187. loss_x: 0.0052. Mask:0.8722 . LR: 0.0069. Time: 61.92\n",
      "2022-04-14 04:04:17,164 - INFO - train -   epoch:124, iter: 256. loss: 0.2225. loss_u: 0.2176. loss_x: 0.0049. Mask:0.8721 . LR: 0.0068. Time: 58.82\n",
      "2022-04-14 04:04:21,262 - INFO - train -   Epoch 124. Top1: 92.4055. Top5: 99.5821. best_acc: 92.4055 in epoch 124\n",
      "2022-04-14 04:05:24,218 - INFO - train -   epoch:125, iter: 64. loss: 0.2214. loss_u: 0.2178. loss_x: 0.0035. Mask:0.8737 . LR: 0.0067. Time: 62.95\n",
      "2022-04-14 04:06:25,400 - INFO - train -   epoch:125, iter: 128. loss: 0.2215. loss_u: 0.2179. loss_x: 0.0035. Mask:0.8760 . LR: 0.0066. Time: 61.18\n",
      "2022-04-14 04:07:25,465 - INFO - train -   epoch:125, iter: 192. loss: 0.2209. loss_u: 0.2169. loss_x: 0.0040. Mask:0.8776 . LR: 0.0066. Time: 60.06\n",
      "2022-04-14 04:08:26,789 - INFO - train -   epoch:125, iter: 256. loss: 0.2219. loss_u: 0.2180. loss_x: 0.0039. Mask:0.8791 . LR: 0.0065. Time: 61.32\n",
      "2022-04-14 04:08:30,752 - INFO - train -   Epoch 125. Top1: 92.6114. Top5: 99.6730. best_acc: 92.6114 in epoch 125\n",
      "2022-04-14 04:09:33,411 - INFO - train -   epoch:126, iter: 64. loss: 0.2197. loss_u: 0.2172. loss_x: 0.0025. Mask:0.8817 . LR: 0.0064. Time: 62.65\n",
      "2022-04-14 04:10:32,775 - INFO - train -   epoch:126, iter: 128. loss: 0.2213. loss_u: 0.2185. loss_x: 0.0027. Mask:0.8794 . LR: 0.0063. Time: 59.36\n",
      "2022-04-14 04:11:30,982 - INFO - train -   epoch:126, iter: 192. loss: 0.2224. loss_u: 0.2187. loss_x: 0.0037. Mask:0.8790 . LR: 0.0062. Time: 58.21\n",
      "2022-04-14 04:12:30,412 - INFO - train -   epoch:126, iter: 256. loss: 0.2227. loss_u: 0.2192. loss_x: 0.0035. Mask:0.8779 . LR: 0.0062. Time: 59.43\n",
      "2022-04-14 04:12:34,600 - INFO - train -   Epoch 126. Top1: 91.7212. Top5: 99.5640. best_acc: 92.6114 in epoch 125\n",
      "2022-04-14 04:13:37,050 - INFO - train -   epoch:127, iter: 64. loss: 0.2250. loss_u: 0.2208. loss_x: 0.0042. Mask:0.8749 . LR: 0.0061. Time: 62.45\n",
      "2022-04-14 04:14:37,973 - INFO - train -   epoch:127, iter: 128. loss: 0.2230. loss_u: 0.2193. loss_x: 0.0037. Mask:0.8753 . LR: 0.0060. Time: 60.92\n",
      "2022-04-14 04:15:37,295 - INFO - train -   epoch:127, iter: 192. loss: 0.2218. loss_u: 0.2185. loss_x: 0.0033. Mask:0.8764 . LR: 0.0059. Time: 59.32\n",
      "2022-04-14 04:16:40,747 - INFO - train -   epoch:127, iter: 256. loss: 0.2226. loss_u: 0.2185. loss_x: 0.0041. Mask:0.8768 . LR: 0.0059. Time: 63.45\n",
      "2022-04-14 04:16:44,908 - INFO - train -   Epoch 127. Top1: 91.7757. Top5: 99.4368. best_acc: 92.6114 in epoch 125\n"
     ]
    }
   ],
   "source": [
    "args.use_ema = False\n",
    "model,criteria_x,criteria_u = create_model(args)\n",
    "num_iters_per_epoch = args.num_images_per_epoch // args.batch_size\n",
    "num_iters_all = num_iters_per_epoch * args.num_epoches\n",
    "ema = EMA(model,args.ema_decay)\n",
    "# wd_params,non_wd_params = [],[]\n",
    "# for name,param in model.named_parameters():\n",
    "#     if 'bn' in name:\n",
    "#         non_wd_params.append(param)\n",
    "#     else:\n",
    "#         wd_params.append(param)\n",
    "# # print(len(wd_params),len(non_wd_params))\n",
    "# param_list = [\n",
    "#     {\n",
    "#         'params':wd_params\n",
    "#     },\n",
    "#     {\n",
    "#         'params':non_wd_params,\n",
    "#         'weight_decay': 0\n",
    "#     }\n",
    "# ]\n",
    "optimizer = torch.optim.SGD(ema.model.parameters(),lr=args.lr,weight_decay=args.wdecay,momentum=args.momentum,nesterov=args.nesterov)\n",
    "lr_schdlr = WarmupCosineLrScheduler(\n",
    "    optimizer,\n",
    "    max_iter=num_iters_all,\n",
    "    warmup_iter=0\n",
    ")\n",
    "\n",
    "\n",
    "best_acc = -1\n",
    "best_epoch = 0\n",
    "logger,writer = setup_default_logging(args)\n",
    "labeledDatasetDataloader,unlabeledDatasetDataloader=get_train_loader(args)\n",
    "validDatasetDataloader = get_valid_loader(args)\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Task = {args.dataset}@{args.num_labeled}\")\n",
    "logger.info(f\"  Num Iters Per Epoch = {num_iters_per_epoch}\")\n",
    "logger.info(f\"  Batch size per GPU = {args.batch_size}\")\n",
    "# logger.info(f\"  Total train batch size = {args.batch_size * args.world_size}\")\n",
    "logger.info(f\"  Total optimization steps = {num_iters_all}\")\n",
    "logger.info(\"Total params: {:.2f}M\".format(\n",
    "    sum(p.numel() for p in model.parameters()) / 1e6))\n",
    "logger.info('-----------start training--------------')\n",
    "for epoch in range(args.num_epoches):\n",
    "    train_loss,loss_x,loss_u,mask_mean=train_one_epoch(\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        criteria_x=criteria_x,\n",
    "        criteria_u=criteria_u,\n",
    "        optimizer=optimizer,\n",
    "        lr_schdlr=lr_schdlr,\n",
    "        ema=ema,\n",
    "        labeledDatasetLoader=labeledDatasetDataloader,\n",
    "        unlabeledDatasetLoader=unlabeledDatasetDataloader,\n",
    "        lambda_u=args.lambda_u,\n",
    "        n_iters=num_iters_per_epoch,\n",
    "        args=args,\n",
    "        logger=logger \n",
    "    )\n",
    "    top1, top5, valid_loss = evaluate(ema, validDatasetDataloader, criteria_x, args=args)\n",
    "\n",
    "    writer.add_scalars('train/1.loss', {'train': train_loss,\n",
    "                                        'test': valid_loss}, epoch)\n",
    "    writer.add_scalar('train/2.train_loss_x', loss_x, epoch)\n",
    "    writer.add_scalar('train/3.train_loss_u', loss_u, epoch)\n",
    "    writer.add_scalar('train/4.mask_mean', mask_mean, epoch)\n",
    "    writer.add_scalars('test/1.test_acc', {'top1': top1, 'top5': top5}, epoch)\n",
    "    # writer.add_scalar('test/2.test_loss', loss, epoch)\n",
    "\n",
    "    # best_acc = top1 if best_acc < top1 else best_acc\n",
    "    if best_acc < top1:\n",
    "        best_acc = top1\n",
    "        best_epoch = epoch\n",
    "\n",
    "    logger.info(\"Epoch {}. Top1: {:.4f}. Top5: {:.4f}. best_acc: {:.4f} in epoch {}\".\n",
    "                format(epoch, top1, top5, best_acc, best_epoch))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-14 04:16:45,255 - INFO - train -   ***** Running training *****\n",
      "2022-04-14 04:16:45,255 - INFO - train -   ***** Running training *****\n",
      "2022-04-14 04:16:45,257 - INFO - train -     Task = dataset@250\n",
      "2022-04-14 04:16:45,257 - INFO - train -     Task = dataset@250\n",
      "2022-04-14 04:16:45,259 - INFO - train -     Num Iters Per Epoch = 256\n",
      "2022-04-14 04:16:45,259 - INFO - train -     Num Iters Per Epoch = 256\n",
      "2022-04-14 04:16:45,260 - INFO - train -     Batch size per GPU = 64\n",
      "2022-04-14 04:16:45,260 - INFO - train -     Batch size per GPU = 64\n",
      "2022-04-14 04:16:45,261 - INFO - train -     Total optimization steps = 32768\n",
      "2022-04-14 04:16:45,261 - INFO - train -     Total optimization steps = 32768\n",
      "2022-04-14 04:16:45,263 - INFO - train -   Total params: 11.18M\n",
      "2022-04-14 04:16:45,263 - INFO - train -   Total params: 11.18M\n",
      "2022-04-14 04:16:45,264 - INFO - train -   -----------start training--------------\n",
      "2022-04-14 04:16:45,264 - INFO - train -   -----------start training--------------\n",
      "2022-04-14 04:17:47,403 - INFO - train -   epoch:0, iter: 64. loss: 1.5234. loss_u: 0.0474. loss_x: 1.4760. Mask:0.0722 . LR: 0.0300. Time: 62.14\n",
      "2022-04-14 04:17:47,403 - INFO - train -   epoch:0, iter: 64. loss: 1.5234. loss_u: 0.0474. loss_x: 1.4760. Mask:0.0722 . LR: 0.0300. Time: 62.14\n",
      "2022-04-14 04:18:47,127 - INFO - train -   epoch:0, iter: 128. loss: 1.2974. loss_u: 0.0630. loss_x: 1.2344. Mask:0.0974 . LR: 0.0300. Time: 59.72\n",
      "2022-04-14 04:18:47,127 - INFO - train -   epoch:0, iter: 128. loss: 1.2974. loss_u: 0.0630. loss_x: 1.2344. Mask:0.0974 . LR: 0.0300. Time: 59.72\n",
      "2022-04-14 04:19:46,319 - INFO - train -   epoch:0, iter: 192. loss: 1.1518. loss_u: 0.0923. loss_x: 1.0596. Mask:0.1419 . LR: 0.0300. Time: 59.19\n",
      "2022-04-14 04:19:46,319 - INFO - train -   epoch:0, iter: 192. loss: 1.1518. loss_u: 0.0923. loss_x: 1.0596. Mask:0.1419 . LR: 0.0300. Time: 59.19\n",
      "2022-04-14 04:20:45,799 - INFO - train -   epoch:0, iter: 256. loss: 1.0649. loss_u: 0.1200. loss_x: 0.9448. Mask:0.1828 . LR: 0.0300. Time: 59.48\n",
      "2022-04-14 04:20:45,799 - INFO - train -   epoch:0, iter: 256. loss: 1.0649. loss_u: 0.1200. loss_x: 0.9448. Mask:0.1828 . LR: 0.0300. Time: 59.48\n",
      "2022-04-14 04:20:49,955 - INFO - train -   Epoch 0. Top1: 57.3583. Top5: 93.8227. best_acc: 57.3583 in epoch 0\n",
      "2022-04-14 04:20:49,955 - INFO - train -   Epoch 0. Top1: 57.3583. Top5: 93.8227. best_acc: 57.3583 in epoch 0\n",
      "2022-04-14 04:21:52,132 - INFO - train -   epoch:1, iter: 64. loss: 0.6740. loss_u: 0.2306. loss_x: 0.4434. Mask:0.3667 . LR: 0.0300. Time: 62.17\n",
      "2022-04-14 04:21:52,132 - INFO - train -   epoch:1, iter: 64. loss: 0.6740. loss_u: 0.2306. loss_x: 0.4434. Mask:0.3667 . LR: 0.0300. Time: 62.17\n",
      "2022-04-14 04:22:51,947 - INFO - train -   epoch:1, iter: 128. loss: 0.6485. loss_u: 0.2394. loss_x: 0.4091. Mask:0.3798 . LR: 0.0300. Time: 59.81\n",
      "2022-04-14 04:22:51,947 - INFO - train -   epoch:1, iter: 128. loss: 0.6485. loss_u: 0.2394. loss_x: 0.4091. Mask:0.3798 . LR: 0.0300. Time: 59.81\n",
      "2022-04-14 04:23:50,908 - INFO - train -   epoch:1, iter: 192. loss: 0.6168. loss_u: 0.2537. loss_x: 0.3631. Mask:0.4080 . LR: 0.0300. Time: 58.96\n",
      "2022-04-14 04:23:50,908 - INFO - train -   epoch:1, iter: 192. loss: 0.6168. loss_u: 0.2537. loss_x: 0.3631. Mask:0.4080 . LR: 0.0300. Time: 58.96\n",
      "2022-04-14 04:24:49,657 - INFO - train -   epoch:1, iter: 256. loss: 0.6035. loss_u: 0.2597. loss_x: 0.3438. Mask:0.4215 . LR: 0.0300. Time: 58.75\n",
      "2022-04-14 04:24:49,657 - INFO - train -   epoch:1, iter: 256. loss: 0.6035. loss_u: 0.2597. loss_x: 0.3438. Mask:0.4215 . LR: 0.0300. Time: 58.75\n",
      "2022-04-14 04:24:53,775 - INFO - train -   Epoch 1. Top1: 60.4591. Top5: 95.4942. best_acc: 60.4591 in epoch 1\n",
      "2022-04-14 04:24:53,775 - INFO - train -   Epoch 1. Top1: 60.4591. Top5: 95.4942. best_acc: 60.4591 in epoch 1\n",
      "2022-04-14 04:25:57,080 - INFO - train -   epoch:2, iter: 64. loss: 0.5439. loss_u: 0.2786. loss_x: 0.2653. Mask:0.4846 . LR: 0.0300. Time: 63.30\n",
      "2022-04-14 04:25:57,080 - INFO - train -   epoch:2, iter: 64. loss: 0.5439. loss_u: 0.2786. loss_x: 0.2653. Mask:0.4846 . LR: 0.0300. Time: 63.30\n",
      "2022-04-14 04:26:56,925 - INFO - train -   epoch:2, iter: 128. loss: 0.5235. loss_u: 0.2790. loss_x: 0.2446. Mask:0.4907 . LR: 0.0300. Time: 59.84\n",
      "2022-04-14 04:26:56,925 - INFO - train -   epoch:2, iter: 128. loss: 0.5235. loss_u: 0.2790. loss_x: 0.2446. Mask:0.4907 . LR: 0.0300. Time: 59.84\n",
      "2022-04-14 04:27:58,240 - INFO - train -   epoch:2, iter: 192. loss: 0.5070. loss_u: 0.2834. loss_x: 0.2235. Mask:0.4988 . LR: 0.0300. Time: 61.31\n",
      "2022-04-14 04:27:58,240 - INFO - train -   epoch:2, iter: 192. loss: 0.5070. loss_u: 0.2834. loss_x: 0.2235. Mask:0.4988 . LR: 0.0300. Time: 61.31\n",
      "2022-04-14 04:28:57,021 - INFO - train -   epoch:2, iter: 256. loss: 0.4914. loss_u: 0.2867. loss_x: 0.2048. Mask:0.5107 . LR: 0.0300. Time: 58.78\n",
      "2022-04-14 04:28:57,021 - INFO - train -   epoch:2, iter: 256. loss: 0.4914. loss_u: 0.2867. loss_x: 0.2048. Mask:0.5107 . LR: 0.0300. Time: 58.78\n",
      "2022-04-14 04:29:01,169 - INFO - train -   Epoch 2. Top1: 67.4843. Top5: 95.6456. best_acc: 67.4843 in epoch 2\n",
      "2022-04-14 04:29:01,169 - INFO - train -   Epoch 2. Top1: 67.4843. Top5: 95.6456. best_acc: 67.4843 in epoch 2\n",
      "2022-04-14 04:30:02,245 - INFO - train -   epoch:3, iter: 64. loss: 0.4463. loss_u: 0.3088. loss_x: 0.1375. Mask:0.5547 . LR: 0.0300. Time: 61.07\n",
      "2022-04-14 04:30:02,245 - INFO - train -   epoch:3, iter: 64. loss: 0.4463. loss_u: 0.3088. loss_x: 0.1375. Mask:0.5547 . LR: 0.0300. Time: 61.07\n",
      "2022-04-14 04:31:00,147 - INFO - train -   epoch:3, iter: 128. loss: 0.4481. loss_u: 0.2972. loss_x: 0.1509. Mask:0.5584 . LR: 0.0300. Time: 57.90\n",
      "2022-04-14 04:31:00,147 - INFO - train -   epoch:3, iter: 128. loss: 0.4481. loss_u: 0.2972. loss_x: 0.1509. Mask:0.5584 . LR: 0.0300. Time: 57.90\n",
      "2022-04-14 04:31:57,975 - INFO - train -   epoch:3, iter: 192. loss: 0.4502. loss_u: 0.2984. loss_x: 0.1518. Mask:0.5537 . LR: 0.0300. Time: 57.83\n",
      "2022-04-14 04:31:57,975 - INFO - train -   epoch:3, iter: 192. loss: 0.4502. loss_u: 0.2984. loss_x: 0.1518. Mask:0.5537 . LR: 0.0300. Time: 57.83\n",
      "2022-04-14 04:32:56,653 - INFO - train -   epoch:3, iter: 256. loss: 0.4478. loss_u: 0.2977. loss_x: 0.1501. Mask:0.5553 . LR: 0.0300. Time: 58.68\n",
      "2022-04-14 04:32:56,653 - INFO - train -   epoch:3, iter: 256. loss: 0.4478. loss_u: 0.2977. loss_x: 0.1501. Mask:0.5553 . LR: 0.0300. Time: 58.68\n",
      "2022-04-14 04:33:00,730 - INFO - train -   Epoch 3. Top1: 63.9898. Top5: 96.5480. best_acc: 67.4843 in epoch 2\n",
      "2022-04-14 04:33:00,730 - INFO - train -   Epoch 3. Top1: 63.9898. Top5: 96.5480. best_acc: 67.4843 in epoch 2\n",
      "2022-04-14 04:34:02,048 - INFO - train -   epoch:4, iter: 64. loss: 0.4286. loss_u: 0.2910. loss_x: 0.1376. Mask:0.5629 . LR: 0.0300. Time: 61.31\n",
      "2022-04-14 04:34:02,048 - INFO - train -   epoch:4, iter: 64. loss: 0.4286. loss_u: 0.2910. loss_x: 0.1376. Mask:0.5629 . LR: 0.0300. Time: 61.31\n",
      "2022-04-14 04:35:02,993 - INFO - train -   epoch:4, iter: 128. loss: 0.4202. loss_u: 0.2873. loss_x: 0.1329. Mask:0.5645 . LR: 0.0300. Time: 60.94\n",
      "2022-04-14 04:35:02,993 - INFO - train -   epoch:4, iter: 128. loss: 0.4202. loss_u: 0.2873. loss_x: 0.1329. Mask:0.5645 . LR: 0.0300. Time: 60.94\n",
      "2022-04-14 04:36:02,445 - INFO - train -   epoch:4, iter: 192. loss: 0.4153. loss_u: 0.2917. loss_x: 0.1236. Mask:0.5705 . LR: 0.0300. Time: 59.45\n",
      "2022-04-14 04:36:02,445 - INFO - train -   epoch:4, iter: 192. loss: 0.4153. loss_u: 0.2917. loss_x: 0.1236. Mask:0.5705 . LR: 0.0300. Time: 59.45\n",
      "2022-04-14 04:37:03,299 - INFO - train -   epoch:4, iter: 256. loss: 0.4112. loss_u: 0.2941. loss_x: 0.1170. Mask:0.5714 . LR: 0.0300. Time: 60.85\n",
      "2022-04-14 04:37:03,299 - INFO - train -   epoch:4, iter: 256. loss: 0.4112. loss_u: 0.2941. loss_x: 0.1170. Mask:0.5714 . LR: 0.0300. Time: 60.85\n",
      "2022-04-14 04:37:07,326 - INFO - train -   Epoch 4. Top1: 67.8537. Top5: 96.8387. best_acc: 67.8537 in epoch 4\n",
      "2022-04-14 04:37:07,326 - INFO - train -   Epoch 4. Top1: 67.8537. Top5: 96.8387. best_acc: 67.8537 in epoch 4\n",
      "2022-04-14 04:38:11,263 - INFO - train -   epoch:5, iter: 64. loss: 0.4042. loss_u: 0.2884. loss_x: 0.1158. Mask:0.5830 . LR: 0.0300. Time: 63.93\n",
      "2022-04-14 04:38:11,263 - INFO - train -   epoch:5, iter: 64. loss: 0.4042. loss_u: 0.2884. loss_x: 0.1158. Mask:0.5830 . LR: 0.0300. Time: 63.93\n",
      "2022-04-14 04:39:12,908 - INFO - train -   epoch:5, iter: 128. loss: 0.4039. loss_u: 0.2908. loss_x: 0.1131. Mask:0.5798 . LR: 0.0299. Time: 61.64\n",
      "2022-04-14 04:39:12,908 - INFO - train -   epoch:5, iter: 128. loss: 0.4039. loss_u: 0.2908. loss_x: 0.1131. Mask:0.5798 . LR: 0.0299. Time: 61.64\n",
      "2022-04-14 04:40:13,716 - INFO - train -   epoch:5, iter: 192. loss: 0.3953. loss_u: 0.2929. loss_x: 0.1025. Mask:0.5855 . LR: 0.0299. Time: 60.80\n",
      "2022-04-14 04:40:13,716 - INFO - train -   epoch:5, iter: 192. loss: 0.3953. loss_u: 0.2929. loss_x: 0.1025. Mask:0.5855 . LR: 0.0299. Time: 60.80\n",
      "2022-04-14 04:41:14,192 - INFO - train -   epoch:5, iter: 256. loss: 0.3944. loss_u: 0.2955. loss_x: 0.0989. Mask:0.5904 . LR: 0.0299. Time: 60.47\n",
      "2022-04-14 04:41:14,192 - INFO - train -   epoch:5, iter: 256. loss: 0.3944. loss_u: 0.2955. loss_x: 0.0989. Mask:0.5904 . LR: 0.0299. Time: 60.47\n",
      "2022-04-14 04:41:18,383 - INFO - train -   Epoch 5. Top1: 69.2587. Top5: 96.8023. best_acc: 69.2587 in epoch 5\n",
      "2022-04-14 04:41:18,383 - INFO - train -   Epoch 5. Top1: 69.2587. Top5: 96.8023. best_acc: 69.2587 in epoch 5\n",
      "2022-04-14 04:42:19,984 - INFO - train -   epoch:6, iter: 64. loss: 0.3916. loss_u: 0.2893. loss_x: 0.1023. Mask:0.5986 . LR: 0.0299. Time: 61.60\n",
      "2022-04-14 04:42:19,984 - INFO - train -   epoch:6, iter: 64. loss: 0.3916. loss_u: 0.2893. loss_x: 0.1023. Mask:0.5986 . LR: 0.0299. Time: 61.60\n",
      "2022-04-14 04:43:19,445 - INFO - train -   epoch:6, iter: 128. loss: 0.4053. loss_u: 0.2891. loss_x: 0.1161. Mask:0.5915 . LR: 0.0299. Time: 59.46\n",
      "2022-04-14 04:43:19,445 - INFO - train -   epoch:6, iter: 128. loss: 0.4053. loss_u: 0.2891. loss_x: 0.1161. Mask:0.5915 . LR: 0.0299. Time: 59.46\n",
      "2022-04-14 04:44:18,135 - INFO - train -   epoch:6, iter: 192. loss: 0.3979. loss_u: 0.2918. loss_x: 0.1061. Mask:0.5958 . LR: 0.0299. Time: 58.69\n",
      "2022-04-14 04:44:18,135 - INFO - train -   epoch:6, iter: 192. loss: 0.3979. loss_u: 0.2918. loss_x: 0.1061. Mask:0.5958 . LR: 0.0299. Time: 58.69\n",
      "2022-04-14 04:45:17,219 - INFO - train -   epoch:6, iter: 256. loss: 0.3901. loss_u: 0.2898. loss_x: 0.1003. Mask:0.5971 . LR: 0.0299. Time: 59.08\n",
      "2022-04-14 04:45:17,219 - INFO - train -   epoch:6, iter: 256. loss: 0.3901. loss_u: 0.2898. loss_x: 0.1003. Mask:0.5971 . LR: 0.0299. Time: 59.08\n",
      "2022-04-14 04:45:21,317 - INFO - train -   Epoch 6. Top1: 67.2117. Top5: 96.3723. best_acc: 69.2587 in epoch 5\n",
      "2022-04-14 04:45:21,317 - INFO - train -   Epoch 6. Top1: 67.2117. Top5: 96.3723. best_acc: 69.2587 in epoch 5\n",
      "2022-04-14 04:46:26,713 - INFO - train -   epoch:7, iter: 64. loss: 0.3804. loss_u: 0.2885. loss_x: 0.0919. Mask:0.5975 . LR: 0.0299. Time: 65.39\n",
      "2022-04-14 04:46:26,713 - INFO - train -   epoch:7, iter: 64. loss: 0.3804. loss_u: 0.2885. loss_x: 0.0919. Mask:0.5975 . LR: 0.0299. Time: 65.39\n",
      "2022-04-14 04:47:29,676 - INFO - train -   epoch:7, iter: 128. loss: 0.3803. loss_u: 0.2897. loss_x: 0.0906. Mask:0.6027 . LR: 0.0299. Time: 62.96\n",
      "2022-04-14 04:47:29,676 - INFO - train -   epoch:7, iter: 128. loss: 0.3803. loss_u: 0.2897. loss_x: 0.0906. Mask:0.6027 . LR: 0.0299. Time: 62.96\n",
      "2022-04-14 04:48:33,281 - INFO - train -   epoch:7, iter: 192. loss: 0.3743. loss_u: 0.2894. loss_x: 0.0849. Mask:0.6070 . LR: 0.0299. Time: 63.60\n",
      "2022-04-14 04:48:33,281 - INFO - train -   epoch:7, iter: 192. loss: 0.3743. loss_u: 0.2894. loss_x: 0.0849. Mask:0.6070 . LR: 0.0299. Time: 63.60\n",
      "2022-04-14 04:49:37,146 - INFO - train -   epoch:7, iter: 256. loss: 0.3708. loss_u: 0.2872. loss_x: 0.0836. Mask:0.6092 . LR: 0.0299. Time: 63.86\n",
      "2022-04-14 04:49:37,146 - INFO - train -   epoch:7, iter: 256. loss: 0.3708. loss_u: 0.2872. loss_x: 0.0836. Mask:0.6092 . LR: 0.0299. Time: 63.86\n",
      "2022-04-14 04:49:41,468 - INFO - train -   Epoch 7. Top1: 69.5494. Top5: 97.3292. best_acc: 69.5494 in epoch 7\n",
      "2022-04-14 04:49:41,468 - INFO - train -   Epoch 7. Top1: 69.5494. Top5: 97.3292. best_acc: 69.5494 in epoch 7\n",
      "2022-04-14 04:50:46,404 - INFO - train -   epoch:8, iter: 64. loss: 0.3701. loss_u: 0.2795. loss_x: 0.0907. Mask:0.6109 . LR: 0.0299. Time: 64.93\n",
      "2022-04-14 04:50:46,404 - INFO - train -   epoch:8, iter: 64. loss: 0.3701. loss_u: 0.2795. loss_x: 0.0907. Mask:0.6109 . LR: 0.0299. Time: 64.93\n",
      "2022-04-14 04:51:45,786 - INFO - train -   epoch:8, iter: 128. loss: 0.3716. loss_u: 0.2825. loss_x: 0.0891. Mask:0.6138 . LR: 0.0299. Time: 59.38\n",
      "2022-04-14 04:51:45,786 - INFO - train -   epoch:8, iter: 128. loss: 0.3716. loss_u: 0.2825. loss_x: 0.0891. Mask:0.6138 . LR: 0.0299. Time: 59.38\n",
      "2022-04-14 04:52:45,282 - INFO - train -   epoch:8, iter: 192. loss: 0.3662. loss_u: 0.2838. loss_x: 0.0824. Mask:0.6221 . LR: 0.0299. Time: 59.49\n",
      "2022-04-14 04:52:45,282 - INFO - train -   epoch:8, iter: 192. loss: 0.3662. loss_u: 0.2838. loss_x: 0.0824. Mask:0.6221 . LR: 0.0299. Time: 59.49\n",
      "2022-04-14 04:53:46,121 - INFO - train -   epoch:8, iter: 256. loss: 0.3716. loss_u: 0.2861. loss_x: 0.0855. Mask:0.6202 . LR: 0.0299. Time: 60.84\n",
      "2022-04-14 04:53:46,121 - INFO - train -   epoch:8, iter: 256. loss: 0.3716. loss_u: 0.2861. loss_x: 0.0855. Mask:0.6202 . LR: 0.0299. Time: 60.84\n",
      "2022-04-14 04:53:50,421 - INFO - train -   Epoch 8. Top1: 75.6238. Top5: 98.2558. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 04:53:50,421 - INFO - train -   Epoch 8. Top1: 75.6238. Top5: 98.2558. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 04:54:53,148 - INFO - train -   epoch:9, iter: 64. loss: 0.3646. loss_u: 0.2894. loss_x: 0.0752. Mask:0.6235 . LR: 0.0299. Time: 62.71\n",
      "2022-04-14 04:54:53,148 - INFO - train -   epoch:9, iter: 64. loss: 0.3646. loss_u: 0.2894. loss_x: 0.0752. Mask:0.6235 . LR: 0.0299. Time: 62.71\n",
      "2022-04-14 04:55:54,357 - INFO - train -   epoch:9, iter: 128. loss: 0.3630. loss_u: 0.2883. loss_x: 0.0747. Mask:0.6192 . LR: 0.0298. Time: 61.21\n",
      "2022-04-14 04:55:54,357 - INFO - train -   epoch:9, iter: 128. loss: 0.3630. loss_u: 0.2883. loss_x: 0.0747. Mask:0.6192 . LR: 0.0298. Time: 61.21\n",
      "2022-04-14 04:56:55,136 - INFO - train -   epoch:9, iter: 192. loss: 0.3610. loss_u: 0.2891. loss_x: 0.0720. Mask:0.6191 . LR: 0.0298. Time: 60.78\n",
      "2022-04-14 04:56:55,136 - INFO - train -   epoch:9, iter: 192. loss: 0.3610. loss_u: 0.2891. loss_x: 0.0720. Mask:0.6191 . LR: 0.0298. Time: 60.78\n",
      "2022-04-14 04:57:56,044 - INFO - train -   epoch:9, iter: 256. loss: 0.3583. loss_u: 0.2849. loss_x: 0.0734. Mask:0.6210 . LR: 0.0298. Time: 60.91\n",
      "2022-04-14 04:57:56,044 - INFO - train -   epoch:9, iter: 256. loss: 0.3583. loss_u: 0.2849. loss_x: 0.0734. Mask:0.6210 . LR: 0.0298. Time: 60.91\n",
      "2022-04-14 04:58:00,146 - INFO - train -   Epoch 9. Top1: 74.5579. Top5: 97.8924. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 04:58:00,146 - INFO - train -   Epoch 9. Top1: 74.5579. Top5: 97.8924. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 04:59:03,396 - INFO - train -   epoch:10, iter: 64. loss: 0.3469. loss_u: 0.2909. loss_x: 0.0559. Mask:0.6410 . LR: 0.0298. Time: 63.25\n",
      "2022-04-14 04:59:03,396 - INFO - train -   epoch:10, iter: 64. loss: 0.3469. loss_u: 0.2909. loss_x: 0.0559. Mask:0.6410 . LR: 0.0298. Time: 63.25\n",
      "2022-04-14 05:00:00,377 - INFO - train -   epoch:10, iter: 128. loss: 0.3480. loss_u: 0.2876. loss_x: 0.0604. Mask:0.6418 . LR: 0.0298. Time: 56.98\n",
      "2022-04-14 05:00:00,377 - INFO - train -   epoch:10, iter: 128. loss: 0.3480. loss_u: 0.2876. loss_x: 0.0604. Mask:0.6418 . LR: 0.0298. Time: 56.98\n",
      "2022-04-14 05:00:57,316 - INFO - train -   epoch:10, iter: 192. loss: 0.3416. loss_u: 0.2823. loss_x: 0.0593. Mask:0.6367 . LR: 0.0298. Time: 56.94\n",
      "2022-04-14 05:00:57,316 - INFO - train -   epoch:10, iter: 192. loss: 0.3416. loss_u: 0.2823. loss_x: 0.0593. Mask:0.6367 . LR: 0.0298. Time: 56.94\n",
      "2022-04-14 05:01:57,869 - INFO - train -   epoch:10, iter: 256. loss: 0.3416. loss_u: 0.2829. loss_x: 0.0588. Mask:0.6390 . LR: 0.0298. Time: 60.55\n",
      "2022-04-14 05:01:57,869 - INFO - train -   epoch:10, iter: 256. loss: 0.3416. loss_u: 0.2829. loss_x: 0.0588. Mask:0.6390 . LR: 0.0298. Time: 60.55\n",
      "2022-04-14 05:02:01,872 - INFO - train -   Epoch 10. Top1: 74.1461. Top5: 98.1105. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 05:02:01,872 - INFO - train -   Epoch 10. Top1: 74.1461. Top5: 98.1105. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 05:03:04,647 - INFO - train -   epoch:11, iter: 64. loss: 0.3410. loss_u: 0.2817. loss_x: 0.0593. Mask:0.6343 . LR: 0.0298. Time: 62.77\n",
      "2022-04-14 05:03:04,647 - INFO - train -   epoch:11, iter: 64. loss: 0.3410. loss_u: 0.2817. loss_x: 0.0593. Mask:0.6343 . LR: 0.0298. Time: 62.77\n",
      "2022-04-14 05:04:03,501 - INFO - train -   epoch:11, iter: 128. loss: 0.3389. loss_u: 0.2772. loss_x: 0.0617. Mask:0.6330 . LR: 0.0298. Time: 58.85\n",
      "2022-04-14 05:04:03,501 - INFO - train -   epoch:11, iter: 128. loss: 0.3389. loss_u: 0.2772. loss_x: 0.0617. Mask:0.6330 . LR: 0.0298. Time: 58.85\n",
      "2022-04-14 05:05:03,316 - INFO - train -   epoch:11, iter: 192. loss: 0.3413. loss_u: 0.2789. loss_x: 0.0623. Mask:0.6376 . LR: 0.0298. Time: 59.81\n",
      "2022-04-14 05:05:03,316 - INFO - train -   epoch:11, iter: 192. loss: 0.3413. loss_u: 0.2789. loss_x: 0.0623. Mask:0.6376 . LR: 0.0298. Time: 59.81\n",
      "2022-04-14 05:06:01,458 - INFO - train -   epoch:11, iter: 256. loss: 0.3390. loss_u: 0.2789. loss_x: 0.0600. Mask:0.6370 . LR: 0.0298. Time: 58.14\n",
      "2022-04-14 05:06:01,458 - INFO - train -   epoch:11, iter: 256. loss: 0.3390. loss_u: 0.2789. loss_x: 0.0600. Mask:0.6370 . LR: 0.0298. Time: 58.14\n",
      "2022-04-14 05:06:05,541 - INFO - train -   Epoch 11. Top1: 72.9409. Top5: 97.8500. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 05:06:05,541 - INFO - train -   Epoch 11. Top1: 72.9409. Top5: 97.8500. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 05:07:07,712 - INFO - train -   epoch:12, iter: 64. loss: 0.3329. loss_u: 0.2829. loss_x: 0.0501. Mask:0.6447 . LR: 0.0297. Time: 62.17\n",
      "2022-04-14 05:07:07,712 - INFO - train -   epoch:12, iter: 64. loss: 0.3329. loss_u: 0.2829. loss_x: 0.0501. Mask:0.6447 . LR: 0.0297. Time: 62.17\n",
      "2022-04-14 05:08:06,035 - INFO - train -   epoch:12, iter: 128. loss: 0.3289. loss_u: 0.2853. loss_x: 0.0435. Mask:0.6568 . LR: 0.0297. Time: 58.32\n",
      "2022-04-14 05:08:06,035 - INFO - train -   epoch:12, iter: 128. loss: 0.3289. loss_u: 0.2853. loss_x: 0.0435. Mask:0.6568 . LR: 0.0297. Time: 58.32\n",
      "2022-04-14 05:09:05,597 - INFO - train -   epoch:12, iter: 192. loss: 0.3347. loss_u: 0.2871. loss_x: 0.0476. Mask:0.6594 . LR: 0.0297. Time: 59.56\n",
      "2022-04-14 05:09:05,597 - INFO - train -   epoch:12, iter: 192. loss: 0.3347. loss_u: 0.2871. loss_x: 0.0476. Mask:0.6594 . LR: 0.0297. Time: 59.56\n",
      "2022-04-14 05:10:04,230 - INFO - train -   epoch:12, iter: 256. loss: 0.3369. loss_u: 0.2840. loss_x: 0.0529. Mask:0.6565 . LR: 0.0297. Time: 58.63\n",
      "2022-04-14 05:10:04,230 - INFO - train -   epoch:12, iter: 256. loss: 0.3369. loss_u: 0.2840. loss_x: 0.0529. Mask:0.6565 . LR: 0.0297. Time: 58.63\n",
      "2022-04-14 05:10:08,476 - INFO - train -   Epoch 12. Top1: 64.8074. Top5: 96.4753. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 05:10:08,476 - INFO - train -   Epoch 12. Top1: 64.8074. Top5: 96.4753. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 05:11:11,678 - INFO - train -   epoch:13, iter: 64. loss: 0.3403. loss_u: 0.2751. loss_x: 0.0652. Mask:0.6455 . LR: 0.0297. Time: 63.20\n",
      "2022-04-14 05:11:11,678 - INFO - train -   epoch:13, iter: 64. loss: 0.3403. loss_u: 0.2751. loss_x: 0.0652. Mask:0.6455 . LR: 0.0297. Time: 63.20\n",
      "2022-04-14 05:12:10,274 - INFO - train -   epoch:13, iter: 128. loss: 0.3353. loss_u: 0.2738. loss_x: 0.0615. Mask:0.6472 . LR: 0.0297. Time: 58.59\n",
      "2022-04-14 05:12:10,274 - INFO - train -   epoch:13, iter: 128. loss: 0.3353. loss_u: 0.2738. loss_x: 0.0615. Mask:0.6472 . LR: 0.0297. Time: 58.59\n",
      "2022-04-14 05:13:10,339 - INFO - train -   epoch:13, iter: 192. loss: 0.3425. loss_u: 0.2773. loss_x: 0.0652. Mask:0.6481 . LR: 0.0297. Time: 60.06\n",
      "2022-04-14 05:13:10,339 - INFO - train -   epoch:13, iter: 192. loss: 0.3425. loss_u: 0.2773. loss_x: 0.0652. Mask:0.6481 . LR: 0.0297. Time: 60.06\n",
      "2022-04-14 05:14:08,270 - INFO - train -   epoch:13, iter: 256. loss: 0.3458. loss_u: 0.2792. loss_x: 0.0666. Mask:0.6471 . LR: 0.0297. Time: 57.93\n",
      "2022-04-14 05:14:08,270 - INFO - train -   epoch:13, iter: 256. loss: 0.3458. loss_u: 0.2792. loss_x: 0.0666. Mask:0.6471 . LR: 0.0297. Time: 57.93\n",
      "2022-04-14 05:14:12,662 - INFO - train -   Epoch 13. Top1: 74.2430. Top5: 97.4746. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 05:14:12,662 - INFO - train -   Epoch 13. Top1: 74.2430. Top5: 97.4746. best_acc: 75.6238 in epoch 8\n",
      "2022-04-14 05:15:16,436 - INFO - train -   epoch:14, iter: 64. loss: 0.3407. loss_u: 0.2878. loss_x: 0.0528. Mask:0.6623 . LR: 0.0296. Time: 63.77\n",
      "2022-04-14 05:15:16,436 - INFO - train -   epoch:14, iter: 64. loss: 0.3407. loss_u: 0.2878. loss_x: 0.0528. Mask:0.6623 . LR: 0.0296. Time: 63.77\n",
      "2022-04-14 05:16:15,672 - INFO - train -   epoch:14, iter: 128. loss: 0.3414. loss_u: 0.2867. loss_x: 0.0546. Mask:0.6563 . LR: 0.0296. Time: 59.23\n",
      "2022-04-14 05:16:15,672 - INFO - train -   epoch:14, iter: 128. loss: 0.3414. loss_u: 0.2867. loss_x: 0.0546. Mask:0.6563 . LR: 0.0296. Time: 59.23\n",
      "2022-04-14 05:17:14,689 - INFO - train -   epoch:14, iter: 192. loss: 0.3371. loss_u: 0.2847. loss_x: 0.0523. Mask:0.6573 . LR: 0.0296. Time: 59.02\n",
      "2022-04-14 05:17:14,689 - INFO - train -   epoch:14, iter: 192. loss: 0.3371. loss_u: 0.2847. loss_x: 0.0523. Mask:0.6573 . LR: 0.0296. Time: 59.02\n",
      "2022-04-14 05:18:14,024 - INFO - train -   epoch:14, iter: 256. loss: 0.3335. loss_u: 0.2837. loss_x: 0.0498. Mask:0.6595 . LR: 0.0296. Time: 59.33\n",
      "2022-04-14 05:18:14,024 - INFO - train -   epoch:14, iter: 256. loss: 0.3335. loss_u: 0.2837. loss_x: 0.0498. Mask:0.6595 . LR: 0.0296. Time: 59.33\n",
      "2022-04-14 05:18:18,343 - INFO - train -   Epoch 14. Top1: 78.4278. Top5: 98.5828. best_acc: 78.4278 in epoch 14\n",
      "2022-04-14 05:18:18,343 - INFO - train -   Epoch 14. Top1: 78.4278. Top5: 98.5828. best_acc: 78.4278 in epoch 14\n",
      "2022-04-14 05:19:19,022 - INFO - train -   epoch:15, iter: 64. loss: 0.3376. loss_u: 0.2808. loss_x: 0.0568. Mask:0.6676 . LR: 0.0296. Time: 60.67\n",
      "2022-04-14 05:19:19,022 - INFO - train -   epoch:15, iter: 64. loss: 0.3376. loss_u: 0.2808. loss_x: 0.0568. Mask:0.6676 . LR: 0.0296. Time: 60.67\n",
      "2022-04-14 05:20:18,169 - INFO - train -   epoch:15, iter: 128. loss: 0.3276. loss_u: 0.2764. loss_x: 0.0512. Mask:0.6646 . LR: 0.0296. Time: 59.14\n",
      "2022-04-14 05:20:18,169 - INFO - train -   epoch:15, iter: 128. loss: 0.3276. loss_u: 0.2764. loss_x: 0.0512. Mask:0.6646 . LR: 0.0296. Time: 59.14\n",
      "2022-04-14 05:21:17,682 - INFO - train -   epoch:15, iter: 192. loss: 0.3279. loss_u: 0.2776. loss_x: 0.0503. Mask:0.6638 . LR: 0.0296. Time: 59.51\n",
      "2022-04-14 05:21:17,682 - INFO - train -   epoch:15, iter: 192. loss: 0.3279. loss_u: 0.2776. loss_x: 0.0503. Mask:0.6638 . LR: 0.0296. Time: 59.51\n",
      "2022-04-14 05:22:16,613 - INFO - train -   epoch:15, iter: 256. loss: 0.3238. loss_u: 0.2749. loss_x: 0.0489. Mask:0.6634 . LR: 0.0296. Time: 58.93\n",
      "2022-04-14 05:22:16,613 - INFO - train -   epoch:15, iter: 256. loss: 0.3238. loss_u: 0.2749. loss_x: 0.0489. Mask:0.6634 . LR: 0.0296. Time: 58.93\n",
      "2022-04-14 05:22:20,733 - INFO - train -   Epoch 15. Top1: 75.7994. Top5: 98.4375. best_acc: 78.4278 in epoch 14\n",
      "2022-04-14 05:22:20,733 - INFO - train -   Epoch 15. Top1: 75.7994. Top5: 98.4375. best_acc: 78.4278 in epoch 14\n",
      "2022-04-14 05:23:21,058 - INFO - train -   epoch:16, iter: 64. loss: 0.3325. loss_u: 0.2840. loss_x: 0.0485. Mask:0.6699 . LR: 0.0295. Time: 60.32\n",
      "2022-04-14 05:23:21,058 - INFO - train -   epoch:16, iter: 64. loss: 0.3325. loss_u: 0.2840. loss_x: 0.0485. Mask:0.6699 . LR: 0.0295. Time: 60.32\n",
      "2022-04-14 05:24:20,769 - INFO - train -   epoch:16, iter: 128. loss: 0.3323. loss_u: 0.2830. loss_x: 0.0493. Mask:0.6647 . LR: 0.0295. Time: 59.71\n",
      "2022-04-14 05:24:20,769 - INFO - train -   epoch:16, iter: 128. loss: 0.3323. loss_u: 0.2830. loss_x: 0.0493. Mask:0.6647 . LR: 0.0295. Time: 59.71\n",
      "2022-04-14 05:25:20,151 - INFO - train -   epoch:16, iter: 192. loss: 0.3335. loss_u: 0.2811. loss_x: 0.0524. Mask:0.6654 . LR: 0.0295. Time: 59.38\n",
      "2022-04-14 05:25:20,151 - INFO - train -   epoch:16, iter: 192. loss: 0.3335. loss_u: 0.2811. loss_x: 0.0524. Mask:0.6654 . LR: 0.0295. Time: 59.38\n",
      "2022-04-14 05:26:18,169 - INFO - train -   epoch:16, iter: 256. loss: 0.3295. loss_u: 0.2798. loss_x: 0.0497. Mask:0.6646 . LR: 0.0295. Time: 58.02\n",
      "2022-04-14 05:26:18,169 - INFO - train -   epoch:16, iter: 256. loss: 0.3295. loss_u: 0.2798. loss_x: 0.0497. Mask:0.6646 . LR: 0.0295. Time: 58.02\n",
      "2022-04-14 05:26:22,365 - INFO - train -   Epoch 16. Top1: 79.9964. Top5: 97.9288. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:26:22,365 - INFO - train -   Epoch 16. Top1: 79.9964. Top5: 97.9288. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:27:24,742 - INFO - train -   epoch:17, iter: 64. loss: 0.3434. loss_u: 0.2692. loss_x: 0.0742. Mask:0.6603 . LR: 0.0295. Time: 62.37\n",
      "2022-04-14 05:27:24,742 - INFO - train -   epoch:17, iter: 64. loss: 0.3434. loss_u: 0.2692. loss_x: 0.0742. Mask:0.6603 . LR: 0.0295. Time: 62.37\n",
      "2022-04-14 05:28:24,551 - INFO - train -   epoch:17, iter: 128. loss: 0.3395. loss_u: 0.2768. loss_x: 0.0627. Mask:0.6655 . LR: 0.0295. Time: 59.81\n",
      "2022-04-14 05:28:24,551 - INFO - train -   epoch:17, iter: 128. loss: 0.3395. loss_u: 0.2768. loss_x: 0.0627. Mask:0.6655 . LR: 0.0295. Time: 59.81\n",
      "2022-04-14 05:29:22,961 - INFO - train -   epoch:17, iter: 192. loss: 0.3340. loss_u: 0.2797. loss_x: 0.0543. Mask:0.6720 . LR: 0.0295. Time: 58.41\n",
      "2022-04-14 05:29:22,961 - INFO - train -   epoch:17, iter: 192. loss: 0.3340. loss_u: 0.2797. loss_x: 0.0543. Mask:0.6720 . LR: 0.0295. Time: 58.41\n",
      "2022-04-14 05:30:23,080 - INFO - train -   epoch:17, iter: 256. loss: 0.3344. loss_u: 0.2808. loss_x: 0.0536. Mask:0.6728 . LR: 0.0294. Time: 60.12\n",
      "2022-04-14 05:30:23,080 - INFO - train -   epoch:17, iter: 256. loss: 0.3344. loss_u: 0.2808. loss_x: 0.0536. Mask:0.6728 . LR: 0.0294. Time: 60.12\n",
      "2022-04-14 05:30:27,313 - INFO - train -   Epoch 17. Top1: 79.1788. Top5: 98.2376. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:30:27,313 - INFO - train -   Epoch 17. Top1: 79.1788. Top5: 98.2376. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:31:30,198 - INFO - train -   epoch:18, iter: 64. loss: 0.3316. loss_u: 0.2757. loss_x: 0.0559. Mask:0.6682 . LR: 0.0294. Time: 62.88\n",
      "2022-04-14 05:31:30,198 - INFO - train -   epoch:18, iter: 64. loss: 0.3316. loss_u: 0.2757. loss_x: 0.0559. Mask:0.6682 . LR: 0.0294. Time: 62.88\n",
      "2022-04-14 05:32:31,394 - INFO - train -   epoch:18, iter: 128. loss: 0.3280. loss_u: 0.2777. loss_x: 0.0503. Mask:0.6701 . LR: 0.0294. Time: 61.19\n",
      "2022-04-14 05:32:31,394 - INFO - train -   epoch:18, iter: 128. loss: 0.3280. loss_u: 0.2777. loss_x: 0.0503. Mask:0.6701 . LR: 0.0294. Time: 61.19\n",
      "2022-04-14 05:33:31,161 - INFO - train -   epoch:18, iter: 192. loss: 0.3228. loss_u: 0.2750. loss_x: 0.0477. Mask:0.6712 . LR: 0.0294. Time: 59.77\n",
      "2022-04-14 05:33:31,161 - INFO - train -   epoch:18, iter: 192. loss: 0.3228. loss_u: 0.2750. loss_x: 0.0477. Mask:0.6712 . LR: 0.0294. Time: 59.77\n",
      "2022-04-14 05:34:30,387 - INFO - train -   epoch:18, iter: 256. loss: 0.3217. loss_u: 0.2774. loss_x: 0.0442. Mask:0.6784 . LR: 0.0294. Time: 59.22\n",
      "2022-04-14 05:34:30,387 - INFO - train -   epoch:18, iter: 256. loss: 0.3217. loss_u: 0.2774. loss_x: 0.0442. Mask:0.6784 . LR: 0.0294. Time: 59.22\n",
      "2022-04-14 05:34:34,526 - INFO - train -   Epoch 18. Top1: 77.7374. Top5: 98.5828. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:34:34,526 - INFO - train -   Epoch 18. Top1: 77.7374. Top5: 98.5828. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:35:37,694 - INFO - train -   epoch:19, iter: 64. loss: 0.3160. loss_u: 0.2660. loss_x: 0.0500. Mask:0.6694 . LR: 0.0294. Time: 63.16\n",
      "2022-04-14 05:35:37,694 - INFO - train -   epoch:19, iter: 64. loss: 0.3160. loss_u: 0.2660. loss_x: 0.0500. Mask:0.6694 . LR: 0.0294. Time: 63.16\n",
      "2022-04-14 05:36:38,934 - INFO - train -   epoch:19, iter: 128. loss: 0.3137. loss_u: 0.2672. loss_x: 0.0465. Mask:0.6740 . LR: 0.0293. Time: 61.24\n",
      "2022-04-14 05:36:38,934 - INFO - train -   epoch:19, iter: 128. loss: 0.3137. loss_u: 0.2672. loss_x: 0.0465. Mask:0.6740 . LR: 0.0293. Time: 61.24\n",
      "2022-04-14 05:37:40,151 - INFO - train -   epoch:19, iter: 192. loss: 0.3154. loss_u: 0.2676. loss_x: 0.0478. Mask:0.6775 . LR: 0.0293. Time: 61.21\n",
      "2022-04-14 05:37:40,151 - INFO - train -   epoch:19, iter: 192. loss: 0.3154. loss_u: 0.2676. loss_x: 0.0478. Mask:0.6775 . LR: 0.0293. Time: 61.21\n",
      "2022-04-14 05:38:41,497 - INFO - train -   epoch:19, iter: 256. loss: 0.3156. loss_u: 0.2678. loss_x: 0.0477. Mask:0.6789 . LR: 0.0293. Time: 61.34\n",
      "2022-04-14 05:38:41,497 - INFO - train -   epoch:19, iter: 256. loss: 0.3156. loss_u: 0.2678. loss_x: 0.0477. Mask:0.6789 . LR: 0.0293. Time: 61.34\n",
      "2022-04-14 05:38:45,506 - INFO - train -   Epoch 19. Top1: 77.2469. Top5: 97.7168. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:38:45,506 - INFO - train -   Epoch 19. Top1: 77.2469. Top5: 97.7168. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:39:50,898 - INFO - train -   epoch:20, iter: 64. loss: 0.3157. loss_u: 0.2613. loss_x: 0.0544. Mask:0.6808 . LR: 0.0293. Time: 65.39\n",
      "2022-04-14 05:39:50,898 - INFO - train -   epoch:20, iter: 64. loss: 0.3157. loss_u: 0.2613. loss_x: 0.0544. Mask:0.6808 . LR: 0.0293. Time: 65.39\n",
      "2022-04-14 05:40:48,914 - INFO - train -   epoch:20, iter: 128. loss: 0.3150. loss_u: 0.2631. loss_x: 0.0519. Mask:0.6769 . LR: 0.0293. Time: 58.01\n",
      "2022-04-14 05:40:48,914 - INFO - train -   epoch:20, iter: 128. loss: 0.3150. loss_u: 0.2631. loss_x: 0.0519. Mask:0.6769 . LR: 0.0293. Time: 58.01\n",
      "2022-04-14 05:41:47,510 - INFO - train -   epoch:20, iter: 192. loss: 0.3101. loss_u: 0.2647. loss_x: 0.0454. Mask:0.6824 . LR: 0.0293. Time: 58.59\n",
      "2022-04-14 05:41:47,510 - INFO - train -   epoch:20, iter: 192. loss: 0.3101. loss_u: 0.2647. loss_x: 0.0454. Mask:0.6824 . LR: 0.0293. Time: 58.59\n",
      "2022-04-14 05:42:47,847 - INFO - train -   epoch:20, iter: 256. loss: 0.3150. loss_u: 0.2653. loss_x: 0.0497. Mask:0.6789 . LR: 0.0292. Time: 60.33\n",
      "2022-04-14 05:42:47,847 - INFO - train -   epoch:20, iter: 256. loss: 0.3150. loss_u: 0.2653. loss_x: 0.0497. Mask:0.6789 . LR: 0.0292. Time: 60.33\n",
      "2022-04-14 05:42:52,009 - INFO - train -   Epoch 20. Top1: 77.1076. Top5: 98.0015. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:42:52,009 - INFO - train -   Epoch 20. Top1: 77.1076. Top5: 98.0015. best_acc: 79.9964 in epoch 16\n",
      "2022-04-14 05:43:55,601 - INFO - train -   epoch:21, iter: 64. loss: 0.3065. loss_u: 0.2721. loss_x: 0.0344. Mask:0.6928 . LR: 0.0292. Time: 63.59\n",
      "2022-04-14 05:43:55,601 - INFO - train -   epoch:21, iter: 64. loss: 0.3065. loss_u: 0.2721. loss_x: 0.0344. Mask:0.6928 . LR: 0.0292. Time: 63.59\n",
      "2022-04-14 05:44:57,145 - INFO - train -   epoch:21, iter: 128. loss: 0.3160. loss_u: 0.2813. loss_x: 0.0347. Mask:0.6975 . LR: 0.0292. Time: 61.54\n",
      "2022-04-14 05:44:57,145 - INFO - train -   epoch:21, iter: 128. loss: 0.3160. loss_u: 0.2813. loss_x: 0.0347. Mask:0.6975 . LR: 0.0292. Time: 61.54\n",
      "2022-04-14 05:45:57,162 - INFO - train -   epoch:21, iter: 192. loss: 0.3142. loss_u: 0.2784. loss_x: 0.0358. Mask:0.6940 . LR: 0.0292. Time: 60.01\n",
      "2022-04-14 05:45:57,162 - INFO - train -   epoch:21, iter: 192. loss: 0.3142. loss_u: 0.2784. loss_x: 0.0358. Mask:0.6940 . LR: 0.0292. Time: 60.01\n",
      "2022-04-14 05:46:58,171 - INFO - train -   epoch:21, iter: 256. loss: 0.3111. loss_u: 0.2757. loss_x: 0.0353. Mask:0.6960 . LR: 0.0292. Time: 61.01\n",
      "2022-04-14 05:46:58,171 - INFO - train -   epoch:21, iter: 256. loss: 0.3111. loss_u: 0.2757. loss_x: 0.0353. Mask:0.6960 . LR: 0.0292. Time: 61.01\n",
      "2022-04-14 05:47:02,165 - INFO - train -   Epoch 21. Top1: 80.0630. Top5: 98.3830. best_acc: 80.0630 in epoch 21\n",
      "2022-04-14 05:47:02,165 - INFO - train -   Epoch 21. Top1: 80.0630. Top5: 98.3830. best_acc: 80.0630 in epoch 21\n",
      "2022-04-14 05:48:05,209 - INFO - train -   epoch:22, iter: 64. loss: 0.3172. loss_u: 0.2676. loss_x: 0.0495. Mask:0.6882 . LR: 0.0291. Time: 63.04\n",
      "2022-04-14 05:48:05,209 - INFO - train -   epoch:22, iter: 64. loss: 0.3172. loss_u: 0.2676. loss_x: 0.0495. Mask:0.6882 . LR: 0.0291. Time: 63.04\n",
      "2022-04-14 05:49:04,816 - INFO - train -   epoch:22, iter: 128. loss: 0.3123. loss_u: 0.2692. loss_x: 0.0431. Mask:0.6956 . LR: 0.0291. Time: 59.61\n",
      "2022-04-14 05:49:04,816 - INFO - train -   epoch:22, iter: 128. loss: 0.3123. loss_u: 0.2692. loss_x: 0.0431. Mask:0.6956 . LR: 0.0291. Time: 59.61\n",
      "2022-04-14 05:50:04,707 - INFO - train -   epoch:22, iter: 192. loss: 0.3130. loss_u: 0.2718. loss_x: 0.0412. Mask:0.6997 . LR: 0.0291. Time: 59.89\n",
      "2022-04-14 05:50:04,707 - INFO - train -   epoch:22, iter: 192. loss: 0.3130. loss_u: 0.2718. loss_x: 0.0412. Mask:0.6997 . LR: 0.0291. Time: 59.89\n",
      "2022-04-14 05:51:04,130 - INFO - train -   epoch:22, iter: 256. loss: 0.3149. loss_u: 0.2728. loss_x: 0.0421. Mask:0.6971 . LR: 0.0291. Time: 59.42\n",
      "2022-04-14 05:51:04,130 - INFO - train -   epoch:22, iter: 256. loss: 0.3149. loss_u: 0.2728. loss_x: 0.0421. Mask:0.6971 . LR: 0.0291. Time: 59.42\n",
      "2022-04-14 05:51:08,296 - INFO - train -   Epoch 22. Top1: 79.9297. Top5: 98.4557. best_acc: 80.0630 in epoch 21\n",
      "2022-04-14 05:51:08,296 - INFO - train -   Epoch 22. Top1: 79.9297. Top5: 98.4557. best_acc: 80.0630 in epoch 21\n",
      "2022-04-14 05:52:10,438 - INFO - train -   epoch:23, iter: 64. loss: 0.3171. loss_u: 0.2771. loss_x: 0.0400. Mask:0.7027 . LR: 0.0291. Time: 62.14\n",
      "2022-04-14 05:52:10,438 - INFO - train -   epoch:23, iter: 64. loss: 0.3171. loss_u: 0.2771. loss_x: 0.0400. Mask:0.7027 . LR: 0.0291. Time: 62.14\n",
      "2022-04-14 05:53:07,843 - INFO - train -   epoch:23, iter: 128. loss: 0.3154. loss_u: 0.2752. loss_x: 0.0401. Mask:0.7013 . LR: 0.0290. Time: 57.40\n",
      "2022-04-14 05:53:07,843 - INFO - train -   epoch:23, iter: 128. loss: 0.3154. loss_u: 0.2752. loss_x: 0.0401. Mask:0.7013 . LR: 0.0290. Time: 57.40\n",
      "2022-04-14 05:54:06,771 - INFO - train -   epoch:23, iter: 192. loss: 0.3115. loss_u: 0.2736. loss_x: 0.0380. Mask:0.7014 . LR: 0.0290. Time: 58.93\n",
      "2022-04-14 05:54:06,771 - INFO - train -   epoch:23, iter: 192. loss: 0.3115. loss_u: 0.2736. loss_x: 0.0380. Mask:0.7014 . LR: 0.0290. Time: 58.93\n",
      "2022-04-14 05:55:03,351 - INFO - train -   epoch:23, iter: 256. loss: 0.3091. loss_u: 0.2729. loss_x: 0.0362. Mask:0.7024 . LR: 0.0290. Time: 56.58\n",
      "2022-04-14 05:55:03,351 - INFO - train -   epoch:23, iter: 256. loss: 0.3091. loss_u: 0.2729. loss_x: 0.0362. Mask:0.7024 . LR: 0.0290. Time: 56.58\n",
      "2022-04-14 05:55:07,623 - INFO - train -   Epoch 23. Top1: 82.4491. Top5: 98.8372. best_acc: 82.4491 in epoch 23\n",
      "2022-04-14 05:55:07,623 - INFO - train -   Epoch 23. Top1: 82.4491. Top5: 98.8372. best_acc: 82.4491 in epoch 23\n",
      "2022-04-14 05:56:11,871 - INFO - train -   epoch:24, iter: 64. loss: 0.3051. loss_u: 0.2731. loss_x: 0.0320. Mask:0.7090 . LR: 0.0290. Time: 64.24\n",
      "2022-04-14 05:56:11,871 - INFO - train -   epoch:24, iter: 64. loss: 0.3051. loss_u: 0.2731. loss_x: 0.0320. Mask:0.7090 . LR: 0.0290. Time: 64.24\n",
      "2022-04-14 05:57:10,265 - INFO - train -   epoch:24, iter: 128. loss: 0.3051. loss_u: 0.2729. loss_x: 0.0321. Mask:0.7072 . LR: 0.0290. Time: 58.39\n",
      "2022-04-14 05:57:10,265 - INFO - train -   epoch:24, iter: 128. loss: 0.3051. loss_u: 0.2729. loss_x: 0.0321. Mask:0.7072 . LR: 0.0290. Time: 58.39\n",
      "2022-04-14 05:58:08,234 - INFO - train -   epoch:24, iter: 192. loss: 0.3081. loss_u: 0.2747. loss_x: 0.0333. Mask:0.7075 . LR: 0.0289. Time: 57.97\n",
      "2022-04-14 05:58:08,234 - INFO - train -   epoch:24, iter: 192. loss: 0.3081. loss_u: 0.2747. loss_x: 0.0333. Mask:0.7075 . LR: 0.0289. Time: 57.97\n",
      "2022-04-14 05:59:07,993 - INFO - train -   epoch:24, iter: 256. loss: 0.3077. loss_u: 0.2732. loss_x: 0.0345. Mask:0.7069 . LR: 0.0289. Time: 59.76\n",
      "2022-04-14 05:59:07,993 - INFO - train -   epoch:24, iter: 256. loss: 0.3077. loss_u: 0.2732. loss_x: 0.0345. Mask:0.7069 . LR: 0.0289. Time: 59.76\n",
      "2022-04-14 05:59:12,165 - INFO - train -   Epoch 24. Top1: 81.1713. Top5: 98.8917. best_acc: 82.4491 in epoch 23\n",
      "2022-04-14 05:59:12,165 - INFO - train -   Epoch 24. Top1: 81.1713. Top5: 98.8917. best_acc: 82.4491 in epoch 23\n",
      "2022-04-14 06:00:16,572 - INFO - train -   epoch:25, iter: 64. loss: 0.2907. loss_u: 0.2565. loss_x: 0.0342. Mask:0.7031 . LR: 0.0289. Time: 64.40\n",
      "2022-04-14 06:00:16,572 - INFO - train -   epoch:25, iter: 64. loss: 0.2907. loss_u: 0.2565. loss_x: 0.0342. Mask:0.7031 . LR: 0.0289. Time: 64.40\n",
      "2022-04-14 06:01:15,477 - INFO - train -   epoch:25, iter: 128. loss: 0.2995. loss_u: 0.2620. loss_x: 0.0375. Mask:0.6981 . LR: 0.0289. Time: 58.90\n",
      "2022-04-14 06:01:15,477 - INFO - train -   epoch:25, iter: 128. loss: 0.2995. loss_u: 0.2620. loss_x: 0.0375. Mask:0.6981 . LR: 0.0289. Time: 58.90\n",
      "2022-04-14 06:02:15,374 - INFO - train -   epoch:25, iter: 192. loss: 0.3133. loss_u: 0.2686. loss_x: 0.0447. Mask:0.6968 . LR: 0.0289. Time: 59.90\n",
      "2022-04-14 06:02:15,374 - INFO - train -   epoch:25, iter: 192. loss: 0.3133. loss_u: 0.2686. loss_x: 0.0447. Mask:0.6968 . LR: 0.0289. Time: 59.90\n",
      "2022-04-14 06:03:13,929 - INFO - train -   epoch:25, iter: 256. loss: 0.3125. loss_u: 0.2695. loss_x: 0.0430. Mask:0.6949 . LR: 0.0288. Time: 58.55\n",
      "2022-04-14 06:03:13,929 - INFO - train -   epoch:25, iter: 256. loss: 0.3125. loss_u: 0.2695. loss_x: 0.0430. Mask:0.6949 . LR: 0.0288. Time: 58.55\n",
      "2022-04-14 06:03:18,056 - INFO - train -   Epoch 25. Top1: 76.3626. Top5: 98.6192. best_acc: 82.4491 in epoch 23\n",
      "2022-04-14 06:03:18,056 - INFO - train -   Epoch 25. Top1: 76.3626. Top5: 98.6192. best_acc: 82.4491 in epoch 23\n",
      "2022-04-14 06:04:23,143 - INFO - train -   epoch:26, iter: 64. loss: 0.3112. loss_u: 0.2769. loss_x: 0.0343. Mask:0.7139 . LR: 0.0288. Time: 65.08\n",
      "2022-04-14 06:04:23,143 - INFO - train -   epoch:26, iter: 64. loss: 0.3112. loss_u: 0.2769. loss_x: 0.0343. Mask:0.7139 . LR: 0.0288. Time: 65.08\n",
      "2022-04-14 06:05:25,417 - INFO - train -   epoch:26, iter: 128. loss: 0.3060. loss_u: 0.2740. loss_x: 0.0320. Mask:0.7125 . LR: 0.0288. Time: 62.27\n",
      "2022-04-14 06:05:25,417 - INFO - train -   epoch:26, iter: 128. loss: 0.3060. loss_u: 0.2740. loss_x: 0.0320. Mask:0.7125 . LR: 0.0288. Time: 62.27\n",
      "2022-04-14 06:06:25,557 - INFO - train -   epoch:26, iter: 192. loss: 0.3079. loss_u: 0.2753. loss_x: 0.0326. Mask:0.7096 . LR: 0.0288. Time: 60.14\n",
      "2022-04-14 06:06:25,557 - INFO - train -   epoch:26, iter: 192. loss: 0.3079. loss_u: 0.2753. loss_x: 0.0326. Mask:0.7096 . LR: 0.0288. Time: 60.14\n",
      "2022-04-14 06:07:25,084 - INFO - train -   epoch:26, iter: 256. loss: 0.3074. loss_u: 0.2742. loss_x: 0.0333. Mask:0.7114 . LR: 0.0287. Time: 59.53\n",
      "2022-04-14 06:07:25,084 - INFO - train -   epoch:26, iter: 256. loss: 0.3074. loss_u: 0.2742. loss_x: 0.0333. Mask:0.7114 . LR: 0.0287. Time: 59.53\n",
      "2022-04-14 06:07:29,276 - INFO - train -   Epoch 26. Top1: 79.9903. Top5: 98.5828. best_acc: 82.4491 in epoch 23\n",
      "2022-04-14 06:07:29,276 - INFO - train -   Epoch 26. Top1: 79.9903. Top5: 98.5828. best_acc: 82.4491 in epoch 23\n",
      "2022-04-14 06:08:32,550 - INFO - train -   epoch:27, iter: 64. loss: 0.3042. loss_u: 0.2709. loss_x: 0.0333. Mask:0.7151 . LR: 0.0287. Time: 63.27\n",
      "2022-04-14 06:08:32,550 - INFO - train -   epoch:27, iter: 64. loss: 0.3042. loss_u: 0.2709. loss_x: 0.0333. Mask:0.7151 . LR: 0.0287. Time: 63.27\n",
      "2022-04-14 06:09:30,904 - INFO - train -   epoch:27, iter: 128. loss: 0.3054. loss_u: 0.2700. loss_x: 0.0354. Mask:0.7162 . LR: 0.0287. Time: 58.35\n",
      "2022-04-14 06:09:30,904 - INFO - train -   epoch:27, iter: 128. loss: 0.3054. loss_u: 0.2700. loss_x: 0.0354. Mask:0.7162 . LR: 0.0287. Time: 58.35\n",
      "2022-04-14 06:10:29,660 - INFO - train -   epoch:27, iter: 192. loss: 0.3086. loss_u: 0.2703. loss_x: 0.0383. Mask:0.7135 . LR: 0.0287. Time: 58.75\n",
      "2022-04-14 06:10:29,660 - INFO - train -   epoch:27, iter: 192. loss: 0.3086. loss_u: 0.2703. loss_x: 0.0383. Mask:0.7135 . LR: 0.0287. Time: 58.75\n",
      "2022-04-14 06:11:27,109 - INFO - train -   epoch:27, iter: 256. loss: 0.3100. loss_u: 0.2722. loss_x: 0.0379. Mask:0.7133 . LR: 0.0287. Time: 57.45\n",
      "2022-04-14 06:11:27,109 - INFO - train -   epoch:27, iter: 256. loss: 0.3100. loss_u: 0.2722. loss_x: 0.0379. Mask:0.7133 . LR: 0.0287. Time: 57.45\n",
      "2022-04-14 06:11:31,302 - INFO - train -   Epoch 27. Top1: 82.5097. Top5: 98.7645. best_acc: 82.5097 in epoch 27\n",
      "2022-04-14 06:11:31,302 - INFO - train -   Epoch 27. Top1: 82.5097. Top5: 98.7645. best_acc: 82.5097 in epoch 27\n",
      "2022-04-14 06:12:35,617 - INFO - train -   epoch:28, iter: 64. loss: 0.2974. loss_u: 0.2623. loss_x: 0.0352. Mask:0.7163 . LR: 0.0286. Time: 64.31\n",
      "2022-04-14 06:12:35,617 - INFO - train -   epoch:28, iter: 64. loss: 0.2974. loss_u: 0.2623. loss_x: 0.0352. Mask:0.7163 . LR: 0.0286. Time: 64.31\n",
      "2022-04-14 06:13:35,163 - INFO - train -   epoch:28, iter: 128. loss: 0.3018. loss_u: 0.2667. loss_x: 0.0351. Mask:0.7218 . LR: 0.0286. Time: 59.54\n",
      "2022-04-14 06:13:35,163 - INFO - train -   epoch:28, iter: 128. loss: 0.3018. loss_u: 0.2667. loss_x: 0.0351. Mask:0.7218 . LR: 0.0286. Time: 59.54\n",
      "2022-04-14 06:14:35,104 - INFO - train -   epoch:28, iter: 192. loss: 0.3040. loss_u: 0.2671. loss_x: 0.0369. Mask:0.7202 . LR: 0.0286. Time: 59.94\n",
      "2022-04-14 06:14:35,104 - INFO - train -   epoch:28, iter: 192. loss: 0.3040. loss_u: 0.2671. loss_x: 0.0369. Mask:0.7202 . LR: 0.0286. Time: 59.94\n",
      "2022-04-14 06:15:34,767 - INFO - train -   epoch:28, iter: 256. loss: 0.3117. loss_u: 0.2677. loss_x: 0.0439. Mask:0.7149 . LR: 0.0286. Time: 59.66\n",
      "2022-04-14 06:15:34,767 - INFO - train -   epoch:28, iter: 256. loss: 0.3117. loss_u: 0.2677. loss_x: 0.0439. Mask:0.7149 . LR: 0.0286. Time: 59.66\n",
      "2022-04-14 06:15:38,785 - INFO - train -   Epoch 28. Top1: 72.1475. Top5: 97.2020. best_acc: 82.5097 in epoch 27\n",
      "2022-04-14 06:15:38,785 - INFO - train -   Epoch 28. Top1: 72.1475. Top5: 97.2020. best_acc: 82.5097 in epoch 27\n",
      "2022-04-14 06:16:40,701 - INFO - train -   epoch:29, iter: 64. loss: 0.3312. loss_u: 0.2807. loss_x: 0.0505. Mask:0.6984 . LR: 0.0285. Time: 61.91\n",
      "2022-04-14 06:16:40,701 - INFO - train -   epoch:29, iter: 64. loss: 0.3312. loss_u: 0.2807. loss_x: 0.0505. Mask:0.6984 . LR: 0.0285. Time: 61.91\n",
      "2022-04-14 06:17:41,779 - INFO - train -   epoch:29, iter: 128. loss: 0.3246. loss_u: 0.2791. loss_x: 0.0456. Mask:0.7038 . LR: 0.0285. Time: 61.07\n",
      "2022-04-14 06:17:41,779 - INFO - train -   epoch:29, iter: 128. loss: 0.3246. loss_u: 0.2791. loss_x: 0.0456. Mask:0.7038 . LR: 0.0285. Time: 61.07\n",
      "2022-04-14 06:18:40,125 - INFO - train -   epoch:29, iter: 192. loss: 0.3203. loss_u: 0.2770. loss_x: 0.0433. Mask:0.7079 . LR: 0.0285. Time: 58.34\n",
      "2022-04-14 06:18:40,125 - INFO - train -   epoch:29, iter: 192. loss: 0.3203. loss_u: 0.2770. loss_x: 0.0433. Mask:0.7079 . LR: 0.0285. Time: 58.34\n",
      "2022-04-14 06:19:39,057 - INFO - train -   epoch:29, iter: 256. loss: 0.3169. loss_u: 0.2765. loss_x: 0.0403. Mask:0.7093 . LR: 0.0285. Time: 58.93\n",
      "2022-04-14 06:19:39,057 - INFO - train -   epoch:29, iter: 256. loss: 0.3169. loss_u: 0.2765. loss_x: 0.0403. Mask:0.7093 . LR: 0.0285. Time: 58.93\n",
      "2022-04-14 06:19:43,368 - INFO - train -   Epoch 29. Top1: 82.8609. Top5: 98.8009. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:19:43,368 - INFO - train -   Epoch 29. Top1: 82.8609. Top5: 98.8009. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:20:43,673 - INFO - train -   epoch:30, iter: 64. loss: 0.3112. loss_u: 0.2781. loss_x: 0.0331. Mask:0.7204 . LR: 0.0284. Time: 60.30\n",
      "2022-04-14 06:20:43,673 - INFO - train -   epoch:30, iter: 64. loss: 0.3112. loss_u: 0.2781. loss_x: 0.0331. Mask:0.7204 . LR: 0.0284. Time: 60.30\n",
      "2022-04-14 06:21:46,561 - INFO - train -   epoch:30, iter: 128. loss: 0.3039. loss_u: 0.2719. loss_x: 0.0320. Mask:0.7254 . LR: 0.0284. Time: 62.88\n",
      "2022-04-14 06:21:46,561 - INFO - train -   epoch:30, iter: 128. loss: 0.3039. loss_u: 0.2719. loss_x: 0.0320. Mask:0.7254 . LR: 0.0284. Time: 62.88\n",
      "2022-04-14 06:22:46,361 - INFO - train -   epoch:30, iter: 192. loss: 0.3016. loss_u: 0.2697. loss_x: 0.0320. Mask:0.7247 . LR: 0.0284. Time: 59.80\n",
      "2022-04-14 06:22:46,361 - INFO - train -   epoch:30, iter: 192. loss: 0.3016. loss_u: 0.2697. loss_x: 0.0320. Mask:0.7247 . LR: 0.0284. Time: 59.80\n",
      "2022-04-14 06:23:44,331 - INFO - train -   epoch:30, iter: 256. loss: 0.3008. loss_u: 0.2676. loss_x: 0.0332. Mask:0.7230 . LR: 0.0284. Time: 57.97\n",
      "2022-04-14 06:23:44,331 - INFO - train -   epoch:30, iter: 256. loss: 0.3008. loss_u: 0.2676. loss_x: 0.0332. Mask:0.7230 . LR: 0.0284. Time: 57.97\n",
      "2022-04-14 06:23:48,525 - INFO - train -   Epoch 30. Top1: 79.8874. Top5: 98.0196. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:23:48,525 - INFO - train -   Epoch 30. Top1: 79.8874. Top5: 98.0196. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:24:51,520 - INFO - train -   epoch:31, iter: 64. loss: 0.2899. loss_u: 0.2596. loss_x: 0.0302. Mask:0.7179 . LR: 0.0283. Time: 62.99\n",
      "2022-04-14 06:24:51,520 - INFO - train -   epoch:31, iter: 64. loss: 0.2899. loss_u: 0.2596. loss_x: 0.0302. Mask:0.7179 . LR: 0.0283. Time: 62.99\n",
      "2022-04-14 06:25:55,499 - INFO - train -   epoch:31, iter: 128. loss: 0.2927. loss_u: 0.2634. loss_x: 0.0293. Mask:0.7269 . LR: 0.0283. Time: 63.97\n",
      "2022-04-14 06:25:55,499 - INFO - train -   epoch:31, iter: 128. loss: 0.2927. loss_u: 0.2634. loss_x: 0.0293. Mask:0.7269 . LR: 0.0283. Time: 63.97\n",
      "2022-04-14 06:26:58,743 - INFO - train -   epoch:31, iter: 192. loss: 0.2937. loss_u: 0.2609. loss_x: 0.0327. Mask:0.7258 . LR: 0.0283. Time: 63.24\n",
      "2022-04-14 06:26:58,743 - INFO - train -   epoch:31, iter: 192. loss: 0.2937. loss_u: 0.2609. loss_x: 0.0327. Mask:0.7258 . LR: 0.0283. Time: 63.24\n",
      "2022-04-14 06:28:02,021 - INFO - train -   epoch:31, iter: 256. loss: 0.2962. loss_u: 0.2616. loss_x: 0.0347. Mask:0.7243 . LR: 0.0282. Time: 63.27\n",
      "2022-04-14 06:28:02,021 - INFO - train -   epoch:31, iter: 256. loss: 0.2962. loss_u: 0.2616. loss_x: 0.0347. Mask:0.7243 . LR: 0.0282. Time: 63.27\n",
      "2022-04-14 06:28:06,094 - INFO - train -   Epoch 31. Top1: 81.0623. Top5: 98.2922. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:28:06,094 - INFO - train -   Epoch 31. Top1: 81.0623. Top5: 98.2922. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:29:07,361 - INFO - train -   epoch:32, iter: 64. loss: 0.3099. loss_u: 0.2686. loss_x: 0.0412. Mask:0.7031 . LR: 0.0282. Time: 61.26\n",
      "2022-04-14 06:29:07,361 - INFO - train -   epoch:32, iter: 64. loss: 0.3099. loss_u: 0.2686. loss_x: 0.0412. Mask:0.7031 . LR: 0.0282. Time: 61.26\n",
      "2022-04-14 06:30:07,993 - INFO - train -   epoch:32, iter: 128. loss: 0.3041. loss_u: 0.2663. loss_x: 0.0378. Mask:0.7087 . LR: 0.0282. Time: 60.63\n",
      "2022-04-14 06:30:07,993 - INFO - train -   epoch:32, iter: 128. loss: 0.3041. loss_u: 0.2663. loss_x: 0.0378. Mask:0.7087 . LR: 0.0282. Time: 60.63\n",
      "2022-04-14 06:31:07,296 - INFO - train -   epoch:32, iter: 192. loss: 0.3077. loss_u: 0.2678. loss_x: 0.0399. Mask:0.7161 . LR: 0.0282. Time: 59.30\n",
      "2022-04-14 06:31:07,296 - INFO - train -   epoch:32, iter: 192. loss: 0.3077. loss_u: 0.2678. loss_x: 0.0399. Mask:0.7161 . LR: 0.0282. Time: 59.30\n",
      "2022-04-14 06:32:05,470 - INFO - train -   epoch:32, iter: 256. loss: 0.3080. loss_u: 0.2688. loss_x: 0.0391. Mask:0.7188 . LR: 0.0281. Time: 58.17\n",
      "2022-04-14 06:32:05,470 - INFO - train -   epoch:32, iter: 256. loss: 0.3080. loss_u: 0.2688. loss_x: 0.0391. Mask:0.7188 . LR: 0.0281. Time: 58.17\n",
      "2022-04-14 06:32:09,559 - INFO - train -   Epoch 32. Top1: 82.1039. Top5: 98.9644. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:32:09,559 - INFO - train -   Epoch 32. Top1: 82.1039. Top5: 98.9644. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:33:13,865 - INFO - train -   epoch:33, iter: 64. loss: 0.3059. loss_u: 0.2683. loss_x: 0.0376. Mask:0.7270 . LR: 0.0281. Time: 64.30\n",
      "2022-04-14 06:33:13,865 - INFO - train -   epoch:33, iter: 64. loss: 0.3059. loss_u: 0.2683. loss_x: 0.0376. Mask:0.7270 . LR: 0.0281. Time: 64.30\n",
      "2022-04-14 06:34:14,711 - INFO - train -   epoch:33, iter: 128. loss: 0.3000. loss_u: 0.2676. loss_x: 0.0323. Mask:0.7301 . LR: 0.0281. Time: 60.84\n",
      "2022-04-14 06:34:14,711 - INFO - train -   epoch:33, iter: 128. loss: 0.3000. loss_u: 0.2676. loss_x: 0.0323. Mask:0.7301 . LR: 0.0281. Time: 60.84\n",
      "2022-04-14 06:35:15,580 - INFO - train -   epoch:33, iter: 192. loss: 0.3006. loss_u: 0.2664. loss_x: 0.0342. Mask:0.7321 . LR: 0.0281. Time: 60.87\n",
      "2022-04-14 06:35:15,580 - INFO - train -   epoch:33, iter: 192. loss: 0.3006. loss_u: 0.2664. loss_x: 0.0342. Mask:0.7321 . LR: 0.0281. Time: 60.87\n",
      "2022-04-14 06:36:13,242 - INFO - train -   epoch:33, iter: 256. loss: 0.2992. loss_u: 0.2651. loss_x: 0.0341. Mask:0.7294 . LR: 0.0280. Time: 57.66\n",
      "2022-04-14 06:36:13,242 - INFO - train -   epoch:33, iter: 256. loss: 0.2992. loss_u: 0.2651. loss_x: 0.0341. Mask:0.7294 . LR: 0.0280. Time: 57.66\n",
      "2022-04-14 06:36:17,339 - INFO - train -   Epoch 33. Top1: 81.7042. Top5: 98.8009. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:36:17,339 - INFO - train -   Epoch 33. Top1: 81.7042. Top5: 98.8009. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:37:21,086 - INFO - train -   epoch:34, iter: 64. loss: 0.2931. loss_u: 0.2615. loss_x: 0.0316. Mask:0.7206 . LR: 0.0280. Time: 63.74\n",
      "2022-04-14 06:37:21,086 - INFO - train -   epoch:34, iter: 64. loss: 0.2931. loss_u: 0.2615. loss_x: 0.0316. Mask:0.7206 . LR: 0.0280. Time: 63.74\n",
      "2022-04-14 06:38:19,948 - INFO - train -   epoch:34, iter: 128. loss: 0.2966. loss_u: 0.2622. loss_x: 0.0344. Mask:0.7306 . LR: 0.0280. Time: 58.86\n",
      "2022-04-14 06:38:19,948 - INFO - train -   epoch:34, iter: 128. loss: 0.2966. loss_u: 0.2622. loss_x: 0.0344. Mask:0.7306 . LR: 0.0280. Time: 58.86\n",
      "2022-04-14 06:39:21,598 - INFO - train -   epoch:34, iter: 192. loss: 0.2926. loss_u: 0.2616. loss_x: 0.0311. Mask:0.7318 . LR: 0.0279. Time: 61.65\n",
      "2022-04-14 06:39:21,598 - INFO - train -   epoch:34, iter: 192. loss: 0.2926. loss_u: 0.2616. loss_x: 0.0311. Mask:0.7318 . LR: 0.0279. Time: 61.65\n",
      "2022-04-14 06:40:19,644 - INFO - train -   epoch:34, iter: 256. loss: 0.2937. loss_u: 0.2628. loss_x: 0.0309. Mask:0.7345 . LR: 0.0279. Time: 58.04\n",
      "2022-04-14 06:40:19,644 - INFO - train -   epoch:34, iter: 256. loss: 0.2937. loss_u: 0.2628. loss_x: 0.0309. Mask:0.7345 . LR: 0.0279. Time: 58.04\n",
      "2022-04-14 06:40:23,867 - INFO - train -   Epoch 34. Top1: 80.5656. Top5: 98.7282. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:40:23,867 - INFO - train -   Epoch 34. Top1: 80.5656. Top5: 98.7282. best_acc: 82.8609 in epoch 29\n",
      "2022-04-14 06:41:26,919 - INFO - train -   epoch:35, iter: 64. loss: 0.3054. loss_u: 0.2733. loss_x: 0.0321. Mask:0.7297 . LR: 0.0279. Time: 63.05\n",
      "2022-04-14 06:41:26,919 - INFO - train -   epoch:35, iter: 64. loss: 0.3054. loss_u: 0.2733. loss_x: 0.0321. Mask:0.7297 . LR: 0.0279. Time: 63.05\n",
      "2022-04-14 06:42:25,965 - INFO - train -   epoch:35, iter: 128. loss: 0.3055. loss_u: 0.2726. loss_x: 0.0329. Mask:0.7319 . LR: 0.0278. Time: 59.04\n",
      "2022-04-14 06:42:25,965 - INFO - train -   epoch:35, iter: 128. loss: 0.3055. loss_u: 0.2726. loss_x: 0.0329. Mask:0.7319 . LR: 0.0278. Time: 59.04\n",
      "2022-04-14 06:43:24,473 - INFO - train -   epoch:35, iter: 192. loss: 0.3084. loss_u: 0.2734. loss_x: 0.0350. Mask:0.7330 . LR: 0.0278. Time: 58.51\n",
      "2022-04-14 06:43:24,473 - INFO - train -   epoch:35, iter: 192. loss: 0.3084. loss_u: 0.2734. loss_x: 0.0350. Mask:0.7330 . LR: 0.0278. Time: 58.51\n",
      "2022-04-14 06:44:25,249 - INFO - train -   epoch:35, iter: 256. loss: 0.3084. loss_u: 0.2750. loss_x: 0.0334. Mask:0.7352 . LR: 0.0278. Time: 60.77\n",
      "2022-04-14 06:44:25,249 - INFO - train -   epoch:35, iter: 256. loss: 0.3084. loss_u: 0.2750. loss_x: 0.0334. Mask:0.7352 . LR: 0.0278. Time: 60.77\n",
      "2022-04-14 06:44:29,499 - INFO - train -   Epoch 35. Top1: 83.1819. Top5: 98.7282. best_acc: 83.1819 in epoch 35\n",
      "2022-04-14 06:44:29,499 - INFO - train -   Epoch 35. Top1: 83.1819. Top5: 98.7282. best_acc: 83.1819 in epoch 35\n",
      "2022-04-14 06:45:32,502 - INFO - train -   epoch:36, iter: 64. loss: 0.2942. loss_u: 0.2724. loss_x: 0.0218. Mask:0.7504 . LR: 0.0278. Time: 63.00\n",
      "2022-04-14 06:45:32,502 - INFO - train -   epoch:36, iter: 64. loss: 0.2942. loss_u: 0.2724. loss_x: 0.0218. Mask:0.7504 . LR: 0.0278. Time: 63.00\n",
      "2022-04-14 06:46:31,155 - INFO - train -   epoch:36, iter: 128. loss: 0.2946. loss_u: 0.2684. loss_x: 0.0263. Mask:0.7451 . LR: 0.0277. Time: 58.65\n",
      "2022-04-14 06:46:31,155 - INFO - train -   epoch:36, iter: 128. loss: 0.2946. loss_u: 0.2684. loss_x: 0.0263. Mask:0.7451 . LR: 0.0277. Time: 58.65\n",
      "2022-04-14 06:47:28,689 - INFO - train -   epoch:36, iter: 192. loss: 0.2984. loss_u: 0.2700. loss_x: 0.0285. Mask:0.7456 . LR: 0.0277. Time: 57.53\n",
      "2022-04-14 06:47:28,689 - INFO - train -   epoch:36, iter: 192. loss: 0.2984. loss_u: 0.2700. loss_x: 0.0285. Mask:0.7456 . LR: 0.0277. Time: 57.53\n",
      "2022-04-14 06:48:28,194 - INFO - train -   epoch:36, iter: 256. loss: 0.2964. loss_u: 0.2662. loss_x: 0.0302. Mask:0.7422 . LR: 0.0277. Time: 59.50\n",
      "2022-04-14 06:48:28,194 - INFO - train -   epoch:36, iter: 256. loss: 0.2964. loss_u: 0.2662. loss_x: 0.0302. Mask:0.7422 . LR: 0.0277. Time: 59.50\n",
      "2022-04-14 06:48:32,265 - INFO - train -   Epoch 36. Top1: 85.1502. Top5: 99.1642. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 06:48:32,265 - INFO - train -   Epoch 36. Top1: 85.1502. Top5: 99.1642. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 06:49:34,790 - INFO - train -   epoch:37, iter: 64. loss: 0.2821. loss_u: 0.2567. loss_x: 0.0253. Mask:0.7492 . LR: 0.0276. Time: 62.52\n",
      "2022-04-14 06:49:34,790 - INFO - train -   epoch:37, iter: 64. loss: 0.2821. loss_u: 0.2567. loss_x: 0.0253. Mask:0.7492 . LR: 0.0276. Time: 62.52\n",
      "2022-04-14 06:50:36,347 - INFO - train -   epoch:37, iter: 128. loss: 0.2849. loss_u: 0.2609. loss_x: 0.0241. Mask:0.7512 . LR: 0.0276. Time: 61.55\n",
      "2022-04-14 06:50:36,347 - INFO - train -   epoch:37, iter: 128. loss: 0.2849. loss_u: 0.2609. loss_x: 0.0241. Mask:0.7512 . LR: 0.0276. Time: 61.55\n",
      "2022-04-14 06:51:38,273 - INFO - train -   epoch:37, iter: 192. loss: 0.2844. loss_u: 0.2604. loss_x: 0.0239. Mask:0.7529 . LR: 0.0276. Time: 61.92\n",
      "2022-04-14 06:51:38,273 - INFO - train -   epoch:37, iter: 192. loss: 0.2844. loss_u: 0.2604. loss_x: 0.0239. Mask:0.7529 . LR: 0.0276. Time: 61.92\n",
      "2022-04-14 06:52:38,393 - INFO - train -   epoch:37, iter: 256. loss: 0.2879. loss_u: 0.2630. loss_x: 0.0249. Mask:0.7507 . LR: 0.0275. Time: 60.12\n",
      "2022-04-14 06:52:38,393 - INFO - train -   epoch:37, iter: 256. loss: 0.2879. loss_u: 0.2630. loss_x: 0.0249. Mask:0.7507 . LR: 0.0275. Time: 60.12\n",
      "2022-04-14 06:52:42,500 - INFO - train -   Epoch 37. Top1: 83.0729. Top5: 99.3278. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 06:52:42,500 - INFO - train -   Epoch 37. Top1: 83.0729. Top5: 99.3278. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 06:53:45,330 - INFO - train -   epoch:38, iter: 64. loss: 0.2894. loss_u: 0.2597. loss_x: 0.0297. Mask:0.7486 . LR: 0.0275. Time: 62.83\n",
      "2022-04-14 06:53:45,330 - INFO - train -   epoch:38, iter: 64. loss: 0.2894. loss_u: 0.2597. loss_x: 0.0297. Mask:0.7486 . LR: 0.0275. Time: 62.83\n",
      "2022-04-14 06:54:46,130 - INFO - train -   epoch:38, iter: 128. loss: 0.2907. loss_u: 0.2603. loss_x: 0.0304. Mask:0.7463 . LR: 0.0275. Time: 60.80\n",
      "2022-04-14 06:54:46,130 - INFO - train -   epoch:38, iter: 128. loss: 0.2907. loss_u: 0.2603. loss_x: 0.0304. Mask:0.7463 . LR: 0.0275. Time: 60.80\n",
      "2022-04-14 06:55:45,296 - INFO - train -   epoch:38, iter: 192. loss: 0.2910. loss_u: 0.2614. loss_x: 0.0296. Mask:0.7447 . LR: 0.0274. Time: 59.16\n",
      "2022-04-14 06:55:45,296 - INFO - train -   epoch:38, iter: 192. loss: 0.2910. loss_u: 0.2614. loss_x: 0.0296. Mask:0.7447 . LR: 0.0274. Time: 59.16\n",
      "2022-04-14 06:56:42,773 - INFO - train -   epoch:38, iter: 256. loss: 0.2918. loss_u: 0.2602. loss_x: 0.0316. Mask:0.7453 . LR: 0.0274. Time: 57.48\n",
      "2022-04-14 06:56:42,773 - INFO - train -   epoch:38, iter: 256. loss: 0.2918. loss_u: 0.2602. loss_x: 0.0316. Mask:0.7453 . LR: 0.0274. Time: 57.48\n",
      "2022-04-14 06:56:46,824 - INFO - train -   Epoch 38. Top1: 84.7263. Top5: 99.1279. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 06:56:46,824 - INFO - train -   Epoch 38. Top1: 84.7263. Top5: 99.1279. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 06:57:49,750 - INFO - train -   epoch:39, iter: 64. loss: 0.3060. loss_u: 0.2655. loss_x: 0.0404. Mask:0.7363 . LR: 0.0274. Time: 62.92\n",
      "2022-04-14 06:57:49,750 - INFO - train -   epoch:39, iter: 64. loss: 0.3060. loss_u: 0.2655. loss_x: 0.0404. Mask:0.7363 . LR: 0.0274. Time: 62.92\n",
      "2022-04-14 06:58:48,960 - INFO - train -   epoch:39, iter: 128. loss: 0.2973. loss_u: 0.2644. loss_x: 0.0329. Mask:0.7429 . LR: 0.0273. Time: 59.21\n",
      "2022-04-14 06:58:48,960 - INFO - train -   epoch:39, iter: 128. loss: 0.2973. loss_u: 0.2644. loss_x: 0.0329. Mask:0.7429 . LR: 0.0273. Time: 59.21\n",
      "2022-04-14 06:59:47,706 - INFO - train -   epoch:39, iter: 192. loss: 0.2937. loss_u: 0.2626. loss_x: 0.0311. Mask:0.7443 . LR: 0.0273. Time: 58.74\n",
      "2022-04-14 06:59:47,706 - INFO - train -   epoch:39, iter: 192. loss: 0.2937. loss_u: 0.2626. loss_x: 0.0311. Mask:0.7443 . LR: 0.0273. Time: 58.74\n",
      "2022-04-14 07:00:46,242 - INFO - train -   epoch:39, iter: 256. loss: 0.2939. loss_u: 0.2633. loss_x: 0.0306. Mask:0.7473 . LR: 0.0273. Time: 58.53\n",
      "2022-04-14 07:00:46,242 - INFO - train -   epoch:39, iter: 256. loss: 0.2939. loss_u: 0.2633. loss_x: 0.0306. Mask:0.7473 . LR: 0.0273. Time: 58.53\n",
      "2022-04-14 07:00:50,464 - INFO - train -   Epoch 39. Top1: 84.8292. Top5: 98.8372. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 07:00:50,464 - INFO - train -   Epoch 39. Top1: 84.8292. Top5: 98.8372. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 07:01:53,852 - INFO - train -   epoch:40, iter: 64. loss: 0.2869. loss_u: 0.2608. loss_x: 0.0260. Mask:0.7464 . LR: 0.0272. Time: 63.38\n",
      "2022-04-14 07:01:53,852 - INFO - train -   epoch:40, iter: 64. loss: 0.2869. loss_u: 0.2608. loss_x: 0.0260. Mask:0.7464 . LR: 0.0272. Time: 63.38\n",
      "2022-04-14 07:02:53,985 - INFO - train -   epoch:40, iter: 128. loss: 0.2914. loss_u: 0.2644. loss_x: 0.0270. Mask:0.7521 . LR: 0.0272. Time: 60.13\n",
      "2022-04-14 07:02:53,985 - INFO - train -   epoch:40, iter: 128. loss: 0.2914. loss_u: 0.2644. loss_x: 0.0270. Mask:0.7521 . LR: 0.0272. Time: 60.13\n",
      "2022-04-14 07:03:53,141 - INFO - train -   epoch:40, iter: 192. loss: 0.2897. loss_u: 0.2626. loss_x: 0.0271. Mask:0.7515 . LR: 0.0272. Time: 59.15\n",
      "2022-04-14 07:03:53,141 - INFO - train -   epoch:40, iter: 192. loss: 0.2897. loss_u: 0.2626. loss_x: 0.0271. Mask:0.7515 . LR: 0.0272. Time: 59.15\n",
      "2022-04-14 07:04:53,189 - INFO - train -   epoch:40, iter: 256. loss: 0.2882. loss_u: 0.2613. loss_x: 0.0269. Mask:0.7517 . LR: 0.0271. Time: 60.05\n",
      "2022-04-14 07:04:53,189 - INFO - train -   epoch:40, iter: 256. loss: 0.2882. loss_u: 0.2613. loss_x: 0.0269. Mask:0.7517 . LR: 0.0271. Time: 60.05\n",
      "2022-04-14 07:04:57,407 - INFO - train -   Epoch 40. Top1: 82.9518. Top5: 99.2551. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 07:04:57,407 - INFO - train -   Epoch 40. Top1: 82.9518. Top5: 99.2551. best_acc: 85.1502 in epoch 36\n",
      "2022-04-14 07:05:58,318 - INFO - train -   epoch:41, iter: 64. loss: 0.2942. loss_u: 0.2658. loss_x: 0.0284. Mask:0.7489 . LR: 0.0271. Time: 60.91\n",
      "2022-04-14 07:05:58,318 - INFO - train -   epoch:41, iter: 64. loss: 0.2942. loss_u: 0.2658. loss_x: 0.0284. Mask:0.7489 . LR: 0.0271. Time: 60.91\n",
      "2022-04-14 07:06:56,784 - INFO - train -   epoch:41, iter: 128. loss: 0.2866. loss_u: 0.2612. loss_x: 0.0254. Mask:0.7579 . LR: 0.0271. Time: 58.46\n",
      "2022-04-14 07:06:56,784 - INFO - train -   epoch:41, iter: 128. loss: 0.2866. loss_u: 0.2612. loss_x: 0.0254. Mask:0.7579 . LR: 0.0271. Time: 58.46\n",
      "2022-04-14 07:08:00,605 - INFO - train -   epoch:41, iter: 192. loss: 0.2876. loss_u: 0.2592. loss_x: 0.0285. Mask:0.7550 . LR: 0.0270. Time: 63.82\n",
      "2022-04-14 07:08:00,605 - INFO - train -   epoch:41, iter: 192. loss: 0.2876. loss_u: 0.2592. loss_x: 0.0285. Mask:0.7550 . LR: 0.0270. Time: 63.82\n",
      "2022-04-14 07:08:59,633 - INFO - train -   epoch:41, iter: 256. loss: 0.2880. loss_u: 0.2580. loss_x: 0.0300. Mask:0.7525 . LR: 0.0270. Time: 59.03\n",
      "2022-04-14 07:08:59,633 - INFO - train -   epoch:41, iter: 256. loss: 0.2880. loss_u: 0.2580. loss_x: 0.0300. Mask:0.7525 . LR: 0.0270. Time: 59.03\n",
      "2022-04-14 07:09:03,687 - INFO - train -   Epoch 41. Top1: 86.9368. Top5: 99.3278. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:09:03,687 - INFO - train -   Epoch 41. Top1: 86.9368. Top5: 99.3278. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:10:05,176 - INFO - train -   epoch:42, iter: 64. loss: 0.2795. loss_u: 0.2622. loss_x: 0.0173. Mask:0.7758 . LR: 0.0270. Time: 61.48\n",
      "2022-04-14 07:10:05,176 - INFO - train -   epoch:42, iter: 64. loss: 0.2795. loss_u: 0.2622. loss_x: 0.0173. Mask:0.7758 . LR: 0.0270. Time: 61.48\n",
      "2022-04-14 07:11:02,546 - INFO - train -   epoch:42, iter: 128. loss: 0.2809. loss_u: 0.2631. loss_x: 0.0178. Mask:0.7693 . LR: 0.0269. Time: 57.37\n",
      "2022-04-14 07:11:02,546 - INFO - train -   epoch:42, iter: 128. loss: 0.2809. loss_u: 0.2631. loss_x: 0.0178. Mask:0.7693 . LR: 0.0269. Time: 57.37\n",
      "2022-04-14 07:12:02,327 - INFO - train -   epoch:42, iter: 192. loss: 0.2816. loss_u: 0.2624. loss_x: 0.0193. Mask:0.7684 . LR: 0.0269. Time: 59.78\n",
      "2022-04-14 07:12:02,327 - INFO - train -   epoch:42, iter: 192. loss: 0.2816. loss_u: 0.2624. loss_x: 0.0193. Mask:0.7684 . LR: 0.0269. Time: 59.78\n",
      "2022-04-14 07:13:04,032 - INFO - train -   epoch:42, iter: 256. loss: 0.2836. loss_u: 0.2619. loss_x: 0.0217. Mask:0.7657 . LR: 0.0269. Time: 61.70\n",
      "2022-04-14 07:13:04,032 - INFO - train -   epoch:42, iter: 256. loss: 0.2836. loss_u: 0.2619. loss_x: 0.0217. Mask:0.7657 . LR: 0.0269. Time: 61.70\n",
      "2022-04-14 07:13:08,217 - INFO - train -   Epoch 42. Top1: 82.9942. Top5: 99.0007. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:13:08,217 - INFO - train -   Epoch 42. Top1: 82.9942. Top5: 99.0007. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:14:10,402 - INFO - train -   epoch:43, iter: 64. loss: 0.3094. loss_u: 0.2682. loss_x: 0.0412. Mask:0.7514 . LR: 0.0268. Time: 62.18\n",
      "2022-04-14 07:14:10,402 - INFO - train -   epoch:43, iter: 64. loss: 0.3094. loss_u: 0.2682. loss_x: 0.0412. Mask:0.7514 . LR: 0.0268. Time: 62.18\n",
      "2022-04-14 07:15:08,956 - INFO - train -   epoch:43, iter: 128. loss: 0.3005. loss_u: 0.2631. loss_x: 0.0374. Mask:0.7543 . LR: 0.0268. Time: 58.55\n",
      "2022-04-14 07:15:08,956 - INFO - train -   epoch:43, iter: 128. loss: 0.3005. loss_u: 0.2631. loss_x: 0.0374. Mask:0.7543 . LR: 0.0268. Time: 58.55\n",
      "2022-04-14 07:16:08,838 - INFO - train -   epoch:43, iter: 192. loss: 0.2954. loss_u: 0.2598. loss_x: 0.0356. Mask:0.7534 . LR: 0.0268. Time: 59.88\n",
      "2022-04-14 07:16:08,838 - INFO - train -   epoch:43, iter: 192. loss: 0.2954. loss_u: 0.2598. loss_x: 0.0356. Mask:0.7534 . LR: 0.0268. Time: 59.88\n",
      "2022-04-14 07:17:08,731 - INFO - train -   epoch:43, iter: 256. loss: 0.2923. loss_u: 0.2595. loss_x: 0.0329. Mask:0.7570 . LR: 0.0267. Time: 59.89\n",
      "2022-04-14 07:17:08,731 - INFO - train -   epoch:43, iter: 256. loss: 0.2923. loss_u: 0.2595. loss_x: 0.0329. Mask:0.7570 . LR: 0.0267. Time: 59.89\n",
      "2022-04-14 07:17:12,946 - INFO - train -   Epoch 43. Top1: 85.0048. Top5: 99.3823. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:17:12,946 - INFO - train -   Epoch 43. Top1: 85.0048. Top5: 99.3823. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:18:15,460 - INFO - train -   epoch:44, iter: 64. loss: 0.2873. loss_u: 0.2575. loss_x: 0.0298. Mask:0.7592 . LR: 0.0267. Time: 62.51\n",
      "2022-04-14 07:18:15,460 - INFO - train -   epoch:44, iter: 64. loss: 0.2873. loss_u: 0.2575. loss_x: 0.0298. Mask:0.7592 . LR: 0.0267. Time: 62.51\n",
      "2022-04-14 07:19:15,733 - INFO - train -   epoch:44, iter: 128. loss: 0.2964. loss_u: 0.2646. loss_x: 0.0318. Mask:0.7589 . LR: 0.0266. Time: 60.27\n",
      "2022-04-14 07:19:15,733 - INFO - train -   epoch:44, iter: 128. loss: 0.2964. loss_u: 0.2646. loss_x: 0.0318. Mask:0.7589 . LR: 0.0266. Time: 60.27\n",
      "2022-04-14 07:20:18,178 - INFO - train -   epoch:44, iter: 192. loss: 0.2951. loss_u: 0.2649. loss_x: 0.0302. Mask:0.7589 . LR: 0.0266. Time: 62.44\n",
      "2022-04-14 07:20:18,178 - INFO - train -   epoch:44, iter: 192. loss: 0.2951. loss_u: 0.2649. loss_x: 0.0302. Mask:0.7589 . LR: 0.0266. Time: 62.44\n",
      "2022-04-14 07:21:23,259 - INFO - train -   epoch:44, iter: 256. loss: 0.2980. loss_u: 0.2657. loss_x: 0.0323. Mask:0.7577 . LR: 0.0266. Time: 65.08\n",
      "2022-04-14 07:21:23,259 - INFO - train -   epoch:44, iter: 256. loss: 0.2980. loss_u: 0.2657. loss_x: 0.0323. Mask:0.7577 . LR: 0.0266. Time: 65.08\n",
      "2022-04-14 07:21:27,287 - INFO - train -   Epoch 44. Top1: 84.7747. Top5: 99.3823. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:21:27,287 - INFO - train -   Epoch 44. Top1: 84.7747. Top5: 99.3823. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:22:31,535 - INFO - train -   epoch:45, iter: 64. loss: 0.2690. loss_u: 0.2564. loss_x: 0.0125. Mask:0.7615 . LR: 0.0265. Time: 64.24\n",
      "2022-04-14 07:22:31,535 - INFO - train -   epoch:45, iter: 64. loss: 0.2690. loss_u: 0.2564. loss_x: 0.0125. Mask:0.7615 . LR: 0.0265. Time: 64.24\n",
      "2022-04-14 07:23:31,336 - INFO - train -   epoch:45, iter: 128. loss: 0.2771. loss_u: 0.2597. loss_x: 0.0174. Mask:0.7675 . LR: 0.0265. Time: 59.80\n",
      "2022-04-14 07:23:31,336 - INFO - train -   epoch:45, iter: 128. loss: 0.2771. loss_u: 0.2597. loss_x: 0.0174. Mask:0.7675 . LR: 0.0265. Time: 59.80\n",
      "2022-04-14 07:24:31,584 - INFO - train -   epoch:45, iter: 192. loss: 0.2776. loss_u: 0.2589. loss_x: 0.0186. Mask:0.7661 . LR: 0.0265. Time: 60.25\n",
      "2022-04-14 07:24:31,584 - INFO - train -   epoch:45, iter: 192. loss: 0.2776. loss_u: 0.2589. loss_x: 0.0186. Mask:0.7661 . LR: 0.0265. Time: 60.25\n",
      "2022-04-14 07:25:30,369 - INFO - train -   epoch:45, iter: 256. loss: 0.2770. loss_u: 0.2589. loss_x: 0.0181. Mask:0.7680 . LR: 0.0264. Time: 58.78\n",
      "2022-04-14 07:25:30,369 - INFO - train -   epoch:45, iter: 256. loss: 0.2770. loss_u: 0.2589. loss_x: 0.0181. Mask:0.7680 . LR: 0.0264. Time: 58.78\n",
      "2022-04-14 07:25:34,479 - INFO - train -   Epoch 45. Top1: 84.0056. Top5: 99.0916. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:25:34,479 - INFO - train -   Epoch 45. Top1: 84.0056. Top5: 99.0916. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:26:37,099 - INFO - train -   epoch:46, iter: 64. loss: 0.2919. loss_u: 0.2542. loss_x: 0.0376. Mask:0.7612 . LR: 0.0264. Time: 62.62\n",
      "2022-04-14 07:26:37,099 - INFO - train -   epoch:46, iter: 64. loss: 0.2919. loss_u: 0.2542. loss_x: 0.0376. Mask:0.7612 . LR: 0.0264. Time: 62.62\n",
      "2022-04-14 07:27:36,129 - INFO - train -   epoch:46, iter: 128. loss: 0.2874. loss_u: 0.2554. loss_x: 0.0320. Mask:0.7596 . LR: 0.0263. Time: 59.03\n",
      "2022-04-14 07:27:36,129 - INFO - train -   epoch:46, iter: 128. loss: 0.2874. loss_u: 0.2554. loss_x: 0.0320. Mask:0.7596 . LR: 0.0263. Time: 59.03\n",
      "2022-04-14 07:28:35,699 - INFO - train -   epoch:46, iter: 192. loss: 0.2895. loss_u: 0.2580. loss_x: 0.0315. Mask:0.7614 . LR: 0.0263. Time: 59.57\n",
      "2022-04-14 07:28:35,699 - INFO - train -   epoch:46, iter: 192. loss: 0.2895. loss_u: 0.2580. loss_x: 0.0315. Mask:0.7614 . LR: 0.0263. Time: 59.57\n",
      "2022-04-14 07:29:33,728 - INFO - train -   epoch:46, iter: 256. loss: 0.2872. loss_u: 0.2583. loss_x: 0.0289. Mask:0.7626 . LR: 0.0263. Time: 58.03\n",
      "2022-04-14 07:29:33,728 - INFO - train -   epoch:46, iter: 256. loss: 0.2872. loss_u: 0.2583. loss_x: 0.0289. Mask:0.7626 . LR: 0.0263. Time: 58.03\n",
      "2022-04-14 07:29:37,867 - INFO - train -   Epoch 46. Top1: 84.0480. Top5: 98.9099. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:29:37,867 - INFO - train -   Epoch 46. Top1: 84.0480. Top5: 98.9099. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:30:40,026 - INFO - train -   epoch:47, iter: 64. loss: 0.2828. loss_u: 0.2600. loss_x: 0.0227. Mask:0.7756 . LR: 0.0262. Time: 62.15\n",
      "2022-04-14 07:30:40,026 - INFO - train -   epoch:47, iter: 64. loss: 0.2828. loss_u: 0.2600. loss_x: 0.0227. Mask:0.7756 . LR: 0.0262. Time: 62.15\n",
      "2022-04-14 07:31:41,791 - INFO - train -   epoch:47, iter: 128. loss: 0.2897. loss_u: 0.2644. loss_x: 0.0253. Mask:0.7703 . LR: 0.0262. Time: 61.76\n",
      "2022-04-14 07:31:41,791 - INFO - train -   epoch:47, iter: 128. loss: 0.2897. loss_u: 0.2644. loss_x: 0.0253. Mask:0.7703 . LR: 0.0262. Time: 61.76\n",
      "2022-04-14 07:32:42,054 - INFO - train -   epoch:47, iter: 192. loss: 0.2892. loss_u: 0.2624. loss_x: 0.0268. Mask:0.7695 . LR: 0.0261. Time: 60.26\n",
      "2022-04-14 07:32:42,054 - INFO - train -   epoch:47, iter: 192. loss: 0.2892. loss_u: 0.2624. loss_x: 0.0268. Mask:0.7695 . LR: 0.0261. Time: 60.26\n",
      "2022-04-14 07:33:41,509 - INFO - train -   epoch:47, iter: 256. loss: 0.2886. loss_u: 0.2609. loss_x: 0.0278. Mask:0.7659 . LR: 0.0261. Time: 59.45\n",
      "2022-04-14 07:33:41,509 - INFO - train -   epoch:47, iter: 256. loss: 0.2886. loss_u: 0.2609. loss_x: 0.0278. Mask:0.7659 . LR: 0.0261. Time: 59.45\n",
      "2022-04-14 07:33:45,571 - INFO - train -   Epoch 47. Top1: 85.0109. Top5: 99.0552. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:33:45,571 - INFO - train -   Epoch 47. Top1: 85.0109. Top5: 99.0552. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:34:48,986 - INFO - train -   epoch:48, iter: 64. loss: 0.2738. loss_u: 0.2588. loss_x: 0.0150. Mask:0.7791 . LR: 0.0261. Time: 63.41\n",
      "2022-04-14 07:34:48,986 - INFO - train -   epoch:48, iter: 64. loss: 0.2738. loss_u: 0.2588. loss_x: 0.0150. Mask:0.7791 . LR: 0.0261. Time: 63.41\n",
      "2022-04-14 07:35:48,014 - INFO - train -   epoch:48, iter: 128. loss: 0.2812. loss_u: 0.2586. loss_x: 0.0226. Mask:0.7699 . LR: 0.0260. Time: 59.02\n",
      "2022-04-14 07:35:48,014 - INFO - train -   epoch:48, iter: 128. loss: 0.2812. loss_u: 0.2586. loss_x: 0.0226. Mask:0.7699 . LR: 0.0260. Time: 59.02\n",
      "2022-04-14 07:36:47,217 - INFO - train -   epoch:48, iter: 192. loss: 0.2807. loss_u: 0.2583. loss_x: 0.0224. Mask:0.7723 . LR: 0.0260. Time: 59.20\n",
      "2022-04-14 07:36:47,217 - INFO - train -   epoch:48, iter: 192. loss: 0.2807. loss_u: 0.2583. loss_x: 0.0224. Mask:0.7723 . LR: 0.0260. Time: 59.20\n",
      "2022-04-14 07:37:47,261 - INFO - train -   epoch:48, iter: 256. loss: 0.2804. loss_u: 0.2579. loss_x: 0.0225. Mask:0.7722 . LR: 0.0259. Time: 60.04\n",
      "2022-04-14 07:37:47,261 - INFO - train -   epoch:48, iter: 256. loss: 0.2804. loss_u: 0.2579. loss_x: 0.0225. Mask:0.7722 . LR: 0.0259. Time: 60.04\n",
      "2022-04-14 07:37:51,511 - INFO - train -   Epoch 48. Top1: 86.5855. Top5: 99.3641. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:37:51,511 - INFO - train -   Epoch 48. Top1: 86.5855. Top5: 99.3641. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:38:54,670 - INFO - train -   epoch:49, iter: 64. loss: 0.2719. loss_u: 0.2551. loss_x: 0.0168. Mask:0.7924 . LR: 0.0259. Time: 63.15\n",
      "2022-04-14 07:38:54,670 - INFO - train -   epoch:49, iter: 64. loss: 0.2719. loss_u: 0.2551. loss_x: 0.0168. Mask:0.7924 . LR: 0.0259. Time: 63.15\n",
      "2022-04-14 07:39:53,132 - INFO - train -   epoch:49, iter: 128. loss: 0.2816. loss_u: 0.2602. loss_x: 0.0214. Mask:0.7846 . LR: 0.0259. Time: 58.46\n",
      "2022-04-14 07:39:53,132 - INFO - train -   epoch:49, iter: 128. loss: 0.2816. loss_u: 0.2602. loss_x: 0.0214. Mask:0.7846 . LR: 0.0259. Time: 58.46\n",
      "2022-04-14 07:40:52,228 - INFO - train -   epoch:49, iter: 192. loss: 0.2823. loss_u: 0.2603. loss_x: 0.0219. Mask:0.7818 . LR: 0.0258. Time: 59.09\n",
      "2022-04-14 07:40:52,228 - INFO - train -   epoch:49, iter: 192. loss: 0.2823. loss_u: 0.2603. loss_x: 0.0219. Mask:0.7818 . LR: 0.0258. Time: 59.09\n",
      "2022-04-14 07:41:51,128 - INFO - train -   epoch:49, iter: 256. loss: 0.2816. loss_u: 0.2611. loss_x: 0.0205. Mask:0.7806 . LR: 0.0258. Time: 58.90\n",
      "2022-04-14 07:41:51,128 - INFO - train -   epoch:49, iter: 256. loss: 0.2816. loss_u: 0.2611. loss_x: 0.0205. Mask:0.7806 . LR: 0.0258. Time: 58.90\n",
      "2022-04-14 07:41:55,155 - INFO - train -   Epoch 49. Top1: 86.1979. Top5: 99.2006. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:41:55,155 - INFO - train -   Epoch 49. Top1: 86.1979. Top5: 99.2006. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:42:57,923 - INFO - train -   epoch:50, iter: 64. loss: 0.2982. loss_u: 0.2670. loss_x: 0.0313. Mask:0.7683 . LR: 0.0257. Time: 62.76\n",
      "2022-04-14 07:42:57,923 - INFO - train -   epoch:50, iter: 64. loss: 0.2982. loss_u: 0.2670. loss_x: 0.0313. Mask:0.7683 . LR: 0.0257. Time: 62.76\n",
      "2022-04-14 07:43:56,157 - INFO - train -   epoch:50, iter: 128. loss: 0.2907. loss_u: 0.2632. loss_x: 0.0275. Mask:0.7756 . LR: 0.0257. Time: 58.23\n",
      "2022-04-14 07:43:56,157 - INFO - train -   epoch:50, iter: 128. loss: 0.2907. loss_u: 0.2632. loss_x: 0.0275. Mask:0.7756 . LR: 0.0257. Time: 58.23\n",
      "2022-04-14 07:44:56,428 - INFO - train -   epoch:50, iter: 192. loss: 0.2888. loss_u: 0.2614. loss_x: 0.0274. Mask:0.7715 . LR: 0.0257. Time: 60.27\n",
      "2022-04-14 07:44:56,428 - INFO - train -   epoch:50, iter: 192. loss: 0.2888. loss_u: 0.2614. loss_x: 0.0274. Mask:0.7715 . LR: 0.0257. Time: 60.27\n",
      "2022-04-14 07:45:59,301 - INFO - train -   epoch:50, iter: 256. loss: 0.2890. loss_u: 0.2620. loss_x: 0.0270. Mask:0.7689 . LR: 0.0256. Time: 62.87\n",
      "2022-04-14 07:45:59,301 - INFO - train -   epoch:50, iter: 256. loss: 0.2890. loss_u: 0.2620. loss_x: 0.0270. Mask:0.7689 . LR: 0.0256. Time: 62.87\n",
      "2022-04-14 07:46:03,266 - INFO - train -   Epoch 50. Top1: 82.9578. Top5: 98.6919. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:46:03,266 - INFO - train -   Epoch 50. Top1: 82.9578. Top5: 98.6919. best_acc: 86.9368 in epoch 41\n",
      "2022-04-14 07:47:06,936 - INFO - train -   epoch:51, iter: 64. loss: 0.2827. loss_u: 0.2563. loss_x: 0.0263. Mask:0.7717 . LR: 0.0256. Time: 63.66\n",
      "2022-04-14 07:47:06,936 - INFO - train -   epoch:51, iter: 64. loss: 0.2827. loss_u: 0.2563. loss_x: 0.0263. Mask:0.7717 . LR: 0.0256. Time: 63.66\n",
      "2022-04-14 07:48:06,160 - INFO - train -   epoch:51, iter: 128. loss: 0.2821. loss_u: 0.2586. loss_x: 0.0235. Mask:0.7733 . LR: 0.0255. Time: 59.22\n",
      "2022-04-14 07:48:06,160 - INFO - train -   epoch:51, iter: 128. loss: 0.2821. loss_u: 0.2586. loss_x: 0.0235. Mask:0.7733 . LR: 0.0255. Time: 59.22\n",
      "2022-04-14 07:49:07,360 - INFO - train -   epoch:51, iter: 192. loss: 0.2819. loss_u: 0.2580. loss_x: 0.0239. Mask:0.7749 . LR: 0.0255. Time: 61.20\n",
      "2022-04-14 07:49:07,360 - INFO - train -   epoch:51, iter: 192. loss: 0.2819. loss_u: 0.2580. loss_x: 0.0239. Mask:0.7749 . LR: 0.0255. Time: 61.20\n",
      "2022-04-14 07:50:09,120 - INFO - train -   epoch:51, iter: 256. loss: 0.2812. loss_u: 0.2558. loss_x: 0.0254. Mask:0.7749 . LR: 0.0254. Time: 61.76\n",
      "2022-04-14 07:50:09,120 - INFO - train -   epoch:51, iter: 256. loss: 0.2812. loss_u: 0.2558. loss_x: 0.0254. Mask:0.7749 . LR: 0.0254. Time: 61.76\n",
      "2022-04-14 07:50:13,138 - INFO - train -   Epoch 51. Top1: 87.5727. Top5: 99.4368. best_acc: 87.5727 in epoch 51\n",
      "2022-04-14 07:50:13,138 - INFO - train -   Epoch 51. Top1: 87.5727. Top5: 99.4368. best_acc: 87.5727 in epoch 51\n",
      "2022-04-14 07:51:17,144 - INFO - train -   epoch:52, iter: 64. loss: 0.2796. loss_u: 0.2597. loss_x: 0.0200. Mask:0.7814 . LR: 0.0254. Time: 64.00\n",
      "2022-04-14 07:51:17,144 - INFO - train -   epoch:52, iter: 64. loss: 0.2796. loss_u: 0.2597. loss_x: 0.0200. Mask:0.7814 . LR: 0.0254. Time: 64.00\n",
      "2022-04-14 07:52:20,006 - INFO - train -   epoch:52, iter: 128. loss: 0.2779. loss_u: 0.2560. loss_x: 0.0219. Mask:0.7819 . LR: 0.0254. Time: 62.86\n",
      "2022-04-14 07:52:20,006 - INFO - train -   epoch:52, iter: 128. loss: 0.2779. loss_u: 0.2560. loss_x: 0.0219. Mask:0.7819 . LR: 0.0254. Time: 62.86\n",
      "2022-04-14 07:53:22,083 - INFO - train -   epoch:52, iter: 192. loss: 0.2793. loss_u: 0.2562. loss_x: 0.0231. Mask:0.7791 . LR: 0.0253. Time: 62.07\n",
      "2022-04-14 07:53:22,083 - INFO - train -   epoch:52, iter: 192. loss: 0.2793. loss_u: 0.2562. loss_x: 0.0231. Mask:0.7791 . LR: 0.0253. Time: 62.07\n",
      "2022-04-14 07:54:22,799 - INFO - train -   epoch:52, iter: 256. loss: 0.2803. loss_u: 0.2566. loss_x: 0.0237. Mask:0.7805 . LR: 0.0253. Time: 60.71\n",
      "2022-04-14 07:54:22,799 - INFO - train -   epoch:52, iter: 256. loss: 0.2803. loss_u: 0.2566. loss_x: 0.0237. Mask:0.7805 . LR: 0.0253. Time: 60.71\n",
      "2022-04-14 07:54:26,829 - INFO - train -   Epoch 52. Top1: 84.6657. Top5: 99.1824. best_acc: 87.5727 in epoch 51\n",
      "2022-04-14 07:54:26,829 - INFO - train -   Epoch 52. Top1: 84.6657. Top5: 99.1824. best_acc: 87.5727 in epoch 51\n",
      "2022-04-14 07:55:32,366 - INFO - train -   epoch:53, iter: 64. loss: 0.2881. loss_u: 0.2631. loss_x: 0.0250. Mask:0.7781 . LR: 0.0252. Time: 65.53\n",
      "2022-04-14 07:55:32,366 - INFO - train -   epoch:53, iter: 64. loss: 0.2881. loss_u: 0.2631. loss_x: 0.0250. Mask:0.7781 . LR: 0.0252. Time: 65.53\n",
      "2022-04-14 07:56:35,761 - INFO - train -   epoch:53, iter: 128. loss: 0.2935. loss_u: 0.2623. loss_x: 0.0313. Mask:0.7701 . LR: 0.0252. Time: 63.39\n",
      "2022-04-14 07:56:35,761 - INFO - train -   epoch:53, iter: 128. loss: 0.2935. loss_u: 0.2623. loss_x: 0.0313. Mask:0.7701 . LR: 0.0252. Time: 63.39\n",
      "2022-04-14 07:57:36,827 - INFO - train -   epoch:53, iter: 192. loss: 0.2892. loss_u: 0.2616. loss_x: 0.0276. Mask:0.7712 . LR: 0.0251. Time: 61.06\n",
      "2022-04-14 07:57:36,827 - INFO - train -   epoch:53, iter: 192. loss: 0.2892. loss_u: 0.2616. loss_x: 0.0276. Mask:0.7712 . LR: 0.0251. Time: 61.06\n",
      "2022-04-14 07:58:35,934 - INFO - train -   epoch:53, iter: 256. loss: 0.2882. loss_u: 0.2602. loss_x: 0.0279. Mask:0.7706 . LR: 0.0251. Time: 59.10\n",
      "2022-04-14 07:58:35,934 - INFO - train -   epoch:53, iter: 256. loss: 0.2882. loss_u: 0.2602. loss_x: 0.0279. Mask:0.7706 . LR: 0.0251. Time: 59.10\n",
      "2022-04-14 07:58:39,844 - INFO - train -   Epoch 53. Top1: 83.7452. Top5: 99.1461. best_acc: 87.5727 in epoch 51\n",
      "2022-04-14 07:58:39,844 - INFO - train -   Epoch 53. Top1: 83.7452. Top5: 99.1461. best_acc: 87.5727 in epoch 51\n",
      "2022-04-14 07:59:41,221 - INFO - train -   epoch:54, iter: 64. loss: 0.2763. loss_u: 0.2550. loss_x: 0.0213. Mask:0.7663 . LR: 0.0251. Time: 61.37\n",
      "2022-04-14 07:59:41,221 - INFO - train -   epoch:54, iter: 64. loss: 0.2763. loss_u: 0.2550. loss_x: 0.0213. Mask:0.7663 . LR: 0.0251. Time: 61.37\n",
      "2022-04-14 08:00:42,924 - INFO - train -   epoch:54, iter: 128. loss: 0.2821. loss_u: 0.2561. loss_x: 0.0260. Mask:0.7706 . LR: 0.0250. Time: 61.70\n",
      "2022-04-14 08:00:42,924 - INFO - train -   epoch:54, iter: 128. loss: 0.2821. loss_u: 0.2561. loss_x: 0.0260. Mask:0.7706 . LR: 0.0250. Time: 61.70\n",
      "2022-04-14 08:01:43,884 - INFO - train -   epoch:54, iter: 192. loss: 0.2842. loss_u: 0.2575. loss_x: 0.0266. Mask:0.7716 . LR: 0.0250. Time: 60.96\n",
      "2022-04-14 08:01:43,884 - INFO - train -   epoch:54, iter: 192. loss: 0.2842. loss_u: 0.2575. loss_x: 0.0266. Mask:0.7716 . LR: 0.0250. Time: 60.96\n",
      "2022-04-14 08:02:42,667 - INFO - train -   epoch:54, iter: 256. loss: 0.2822. loss_u: 0.2580. loss_x: 0.0242. Mask:0.7753 . LR: 0.0249. Time: 58.78\n",
      "2022-04-14 08:02:42,667 - INFO - train -   epoch:54, iter: 256. loss: 0.2822. loss_u: 0.2580. loss_x: 0.0242. Mask:0.7753 . LR: 0.0249. Time: 58.78\n",
      "2022-04-14 08:02:46,680 - INFO - train -   Epoch 54. Top1: 87.8270. Top5: 99.3459. best_acc: 87.8270 in epoch 54\n",
      "2022-04-14 08:02:46,680 - INFO - train -   Epoch 54. Top1: 87.8270. Top5: 99.3459. best_acc: 87.8270 in epoch 54\n",
      "2022-04-14 08:03:47,412 - INFO - train -   epoch:55, iter: 64. loss: 0.2838. loss_u: 0.2624. loss_x: 0.0214. Mask:0.7810 . LR: 0.0249. Time: 60.73\n",
      "2022-04-14 08:03:47,412 - INFO - train -   epoch:55, iter: 64. loss: 0.2838. loss_u: 0.2624. loss_x: 0.0214. Mask:0.7810 . LR: 0.0249. Time: 60.73\n",
      "2022-04-14 08:04:47,283 - INFO - train -   epoch:55, iter: 128. loss: 0.2826. loss_u: 0.2599. loss_x: 0.0227. Mask:0.7843 . LR: 0.0248. Time: 59.87\n",
      "2022-04-14 08:04:47,283 - INFO - train -   epoch:55, iter: 128. loss: 0.2826. loss_u: 0.2599. loss_x: 0.0227. Mask:0.7843 . LR: 0.0248. Time: 59.87\n",
      "2022-04-14 08:05:47,345 - INFO - train -   epoch:55, iter: 192. loss: 0.2825. loss_u: 0.2596. loss_x: 0.0229. Mask:0.7800 . LR: 0.0248. Time: 60.06\n",
      "2022-04-14 08:05:47,345 - INFO - train -   epoch:55, iter: 192. loss: 0.2825. loss_u: 0.2596. loss_x: 0.0229. Mask:0.7800 . LR: 0.0248. Time: 60.06\n",
      "2022-04-14 08:06:46,621 - INFO - train -   epoch:55, iter: 256. loss: 0.2823. loss_u: 0.2589. loss_x: 0.0233. Mask:0.7793 . LR: 0.0247. Time: 59.27\n",
      "2022-04-14 08:06:46,621 - INFO - train -   epoch:55, iter: 256. loss: 0.2823. loss_u: 0.2589. loss_x: 0.0233. Mask:0.7793 . LR: 0.0247. Time: 59.27\n",
      "2022-04-14 08:06:50,764 - INFO - train -   Epoch 55. Top1: 85.8769. Top5: 99.2733. best_acc: 87.8270 in epoch 54\n",
      "2022-04-14 08:06:50,764 - INFO - train -   Epoch 55. Top1: 85.8769. Top5: 99.2733. best_acc: 87.8270 in epoch 54\n",
      "2022-04-14 08:07:53,389 - INFO - train -   epoch:56, iter: 64. loss: 0.2870. loss_u: 0.2610. loss_x: 0.0259. Mask:0.7736 . LR: 0.0247. Time: 62.62\n",
      "2022-04-14 08:07:53,389 - INFO - train -   epoch:56, iter: 64. loss: 0.2870. loss_u: 0.2610. loss_x: 0.0259. Mask:0.7736 . LR: 0.0247. Time: 62.62\n",
      "2022-04-14 08:08:55,991 - INFO - train -   epoch:56, iter: 128. loss: 0.2817. loss_u: 0.2567. loss_x: 0.0250. Mask:0.7725 . LR: 0.0246. Time: 62.60\n",
      "2022-04-14 08:08:55,991 - INFO - train -   epoch:56, iter: 128. loss: 0.2817. loss_u: 0.2567. loss_x: 0.0250. Mask:0.7725 . LR: 0.0246. Time: 62.60\n",
      "2022-04-14 08:09:55,142 - INFO - train -   epoch:56, iter: 192. loss: 0.2803. loss_u: 0.2554. loss_x: 0.0249. Mask:0.7737 . LR: 0.0246. Time: 59.15\n",
      "2022-04-14 08:09:55,142 - INFO - train -   epoch:56, iter: 192. loss: 0.2803. loss_u: 0.2554. loss_x: 0.0249. Mask:0.7737 . LR: 0.0246. Time: 59.15\n",
      "2022-04-14 08:10:53,533 - INFO - train -   epoch:56, iter: 256. loss: 0.2780. loss_u: 0.2544. loss_x: 0.0236. Mask:0.7766 . LR: 0.0246. Time: 58.39\n",
      "2022-04-14 08:10:53,533 - INFO - train -   epoch:56, iter: 256. loss: 0.2780. loss_u: 0.2544. loss_x: 0.0236. Mask:0.7766 . LR: 0.0246. Time: 58.39\n",
      "2022-04-14 08:10:57,713 - INFO - train -   Epoch 56. Top1: 87.9118. Top5: 99.1642. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:10:57,713 - INFO - train -   Epoch 56. Top1: 87.9118. Top5: 99.1642. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:11:59,857 - INFO - train -   epoch:57, iter: 64. loss: 0.2681. loss_u: 0.2511. loss_x: 0.0170. Mask:0.7967 . LR: 0.0245. Time: 62.14\n",
      "2022-04-14 08:11:59,857 - INFO - train -   epoch:57, iter: 64. loss: 0.2681. loss_u: 0.2511. loss_x: 0.0170. Mask:0.7967 . LR: 0.0245. Time: 62.14\n",
      "2022-04-14 08:13:01,576 - INFO - train -   epoch:57, iter: 128. loss: 0.2715. loss_u: 0.2541. loss_x: 0.0174. Mask:0.7941 . LR: 0.0245. Time: 61.72\n",
      "2022-04-14 08:13:01,576 - INFO - train -   epoch:57, iter: 128. loss: 0.2715. loss_u: 0.2541. loss_x: 0.0174. Mask:0.7941 . LR: 0.0245. Time: 61.72\n",
      "2022-04-14 08:14:02,026 - INFO - train -   epoch:57, iter: 192. loss: 0.2711. loss_u: 0.2540. loss_x: 0.0171. Mask:0.7945 . LR: 0.0244. Time: 60.45\n",
      "2022-04-14 08:14:02,026 - INFO - train -   epoch:57, iter: 192. loss: 0.2711. loss_u: 0.2540. loss_x: 0.0171. Mask:0.7945 . LR: 0.0244. Time: 60.45\n",
      "2022-04-14 08:15:05,139 - INFO - train -   epoch:57, iter: 256. loss: 0.2729. loss_u: 0.2544. loss_x: 0.0185. Mask:0.7945 . LR: 0.0244. Time: 63.11\n",
      "2022-04-14 08:15:05,139 - INFO - train -   epoch:57, iter: 256. loss: 0.2729. loss_u: 0.2544. loss_x: 0.0185. Mask:0.7945 . LR: 0.0244. Time: 63.11\n",
      "2022-04-14 08:15:09,162 - INFO - train -   Epoch 57. Top1: 86.0647. Top5: 98.9462. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:15:09,162 - INFO - train -   Epoch 57. Top1: 86.0647. Top5: 98.9462. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:16:13,818 - INFO - train -   epoch:58, iter: 64. loss: 0.2755. loss_u: 0.2500. loss_x: 0.0255. Mask:0.7831 . LR: 0.0243. Time: 64.65\n",
      "2022-04-14 08:16:13,818 - INFO - train -   epoch:58, iter: 64. loss: 0.2755. loss_u: 0.2500. loss_x: 0.0255. Mask:0.7831 . LR: 0.0243. Time: 64.65\n",
      "2022-04-14 08:17:12,234 - INFO - train -   epoch:58, iter: 128. loss: 0.2817. loss_u: 0.2593. loss_x: 0.0223. Mask:0.7837 . LR: 0.0243. Time: 58.41\n",
      "2022-04-14 08:17:12,234 - INFO - train -   epoch:58, iter: 128. loss: 0.2817. loss_u: 0.2593. loss_x: 0.0223. Mask:0.7837 . LR: 0.0243. Time: 58.41\n",
      "2022-04-14 08:18:10,533 - INFO - train -   epoch:58, iter: 192. loss: 0.2776. loss_u: 0.2578. loss_x: 0.0198. Mask:0.7923 . LR: 0.0242. Time: 58.30\n",
      "2022-04-14 08:18:10,533 - INFO - train -   epoch:58, iter: 192. loss: 0.2776. loss_u: 0.2578. loss_x: 0.0198. Mask:0.7923 . LR: 0.0242. Time: 58.30\n",
      "2022-04-14 08:19:08,440 - INFO - train -   epoch:58, iter: 256. loss: 0.2792. loss_u: 0.2579. loss_x: 0.0213. Mask:0.7919 . LR: 0.0242. Time: 57.91\n",
      "2022-04-14 08:19:08,440 - INFO - train -   epoch:58, iter: 256. loss: 0.2792. loss_u: 0.2579. loss_x: 0.0213. Mask:0.7919 . LR: 0.0242. Time: 57.91\n",
      "2022-04-14 08:19:12,511 - INFO - train -   Epoch 58. Top1: 84.9685. Top5: 99.1097. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:19:12,511 - INFO - train -   Epoch 58. Top1: 84.9685. Top5: 99.1097. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:20:17,978 - INFO - train -   epoch:59, iter: 64. loss: 0.2687. loss_u: 0.2503. loss_x: 0.0184. Mask:0.7974 . LR: 0.0241. Time: 65.46\n",
      "2022-04-14 08:20:17,978 - INFO - train -   epoch:59, iter: 64. loss: 0.2687. loss_u: 0.2503. loss_x: 0.0184. Mask:0.7974 . LR: 0.0241. Time: 65.46\n",
      "2022-04-14 08:21:19,182 - INFO - train -   epoch:59, iter: 128. loss: 0.2720. loss_u: 0.2529. loss_x: 0.0190. Mask:0.7924 . LR: 0.0241. Time: 61.20\n",
      "2022-04-14 08:21:19,182 - INFO - train -   epoch:59, iter: 128. loss: 0.2720. loss_u: 0.2529. loss_x: 0.0190. Mask:0.7924 . LR: 0.0241. Time: 61.20\n",
      "2022-04-14 08:22:21,843 - INFO - train -   epoch:59, iter: 192. loss: 0.2730. loss_u: 0.2539. loss_x: 0.0191. Mask:0.7907 . LR: 0.0240. Time: 62.66\n",
      "2022-04-14 08:22:21,843 - INFO - train -   epoch:59, iter: 192. loss: 0.2730. loss_u: 0.2539. loss_x: 0.0191. Mask:0.7907 . LR: 0.0240. Time: 62.66\n",
      "2022-04-14 08:23:23,466 - INFO - train -   epoch:59, iter: 256. loss: 0.2717. loss_u: 0.2526. loss_x: 0.0191. Mask:0.7895 . LR: 0.0240. Time: 61.62\n",
      "2022-04-14 08:23:23,466 - INFO - train -   epoch:59, iter: 256. loss: 0.2717. loss_u: 0.2526. loss_x: 0.0191. Mask:0.7895 . LR: 0.0240. Time: 61.62\n",
      "2022-04-14 08:23:27,646 - INFO - train -   Epoch 59. Top1: 84.7505. Top5: 99.1824. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:23:27,646 - INFO - train -   Epoch 59. Top1: 84.7505. Top5: 99.1824. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:24:30,942 - INFO - train -   epoch:60, iter: 64. loss: 0.2726. loss_u: 0.2558. loss_x: 0.0168. Mask:0.8005 . LR: 0.0239. Time: 63.29\n",
      "2022-04-14 08:24:30,942 - INFO - train -   epoch:60, iter: 64. loss: 0.2726. loss_u: 0.2558. loss_x: 0.0168. Mask:0.8005 . LR: 0.0239. Time: 63.29\n",
      "2022-04-14 08:25:31,456 - INFO - train -   epoch:60, iter: 128. loss: 0.2711. loss_u: 0.2544. loss_x: 0.0167. Mask:0.7980 . LR: 0.0239. Time: 60.51\n",
      "2022-04-14 08:25:31,456 - INFO - train -   epoch:60, iter: 128. loss: 0.2711. loss_u: 0.2544. loss_x: 0.0167. Mask:0.7980 . LR: 0.0239. Time: 60.51\n",
      "2022-04-14 08:26:31,323 - INFO - train -   epoch:60, iter: 192. loss: 0.2706. loss_u: 0.2554. loss_x: 0.0152. Mask:0.8023 . LR: 0.0238. Time: 59.86\n",
      "2022-04-14 08:26:31,323 - INFO - train -   epoch:60, iter: 192. loss: 0.2706. loss_u: 0.2554. loss_x: 0.0152. Mask:0.8023 . LR: 0.0238. Time: 59.86\n",
      "2022-04-14 08:27:30,463 - INFO - train -   epoch:60, iter: 256. loss: 0.2706. loss_u: 0.2541. loss_x: 0.0165. Mask:0.8002 . LR: 0.0238. Time: 59.14\n",
      "2022-04-14 08:27:30,463 - INFO - train -   epoch:60, iter: 256. loss: 0.2706. loss_u: 0.2541. loss_x: 0.0165. Mask:0.8002 . LR: 0.0238. Time: 59.14\n",
      "2022-04-14 08:27:34,636 - INFO - train -   Epoch 60. Top1: 85.6771. Top5: 99.1279. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:27:34,636 - INFO - train -   Epoch 60. Top1: 85.6771. Top5: 99.1279. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:28:39,701 - INFO - train -   epoch:61, iter: 64. loss: 0.2719. loss_u: 0.2534. loss_x: 0.0185. Mask:0.7994 . LR: 0.0237. Time: 65.06\n",
      "2022-04-14 08:28:39,701 - INFO - train -   epoch:61, iter: 64. loss: 0.2719. loss_u: 0.2534. loss_x: 0.0185. Mask:0.7994 . LR: 0.0237. Time: 65.06\n",
      "2022-04-14 08:29:38,676 - INFO - train -   epoch:61, iter: 128. loss: 0.2727. loss_u: 0.2535. loss_x: 0.0192. Mask:0.8001 . LR: 0.0237. Time: 58.97\n",
      "2022-04-14 08:29:38,676 - INFO - train -   epoch:61, iter: 128. loss: 0.2727. loss_u: 0.2535. loss_x: 0.0192. Mask:0.8001 . LR: 0.0237. Time: 58.97\n",
      "2022-04-14 08:30:40,196 - INFO - train -   epoch:61, iter: 192. loss: 0.2715. loss_u: 0.2530. loss_x: 0.0185. Mask:0.7996 . LR: 0.0236. Time: 61.52\n",
      "2022-04-14 08:30:40,196 - INFO - train -   epoch:61, iter: 192. loss: 0.2715. loss_u: 0.2530. loss_x: 0.0185. Mask:0.7996 . LR: 0.0236. Time: 61.52\n",
      "2022-04-14 08:31:38,675 - INFO - train -   epoch:61, iter: 256. loss: 0.2707. loss_u: 0.2525. loss_x: 0.0182. Mask:0.8001 . LR: 0.0236. Time: 58.48\n",
      "2022-04-14 08:31:38,675 - INFO - train -   epoch:61, iter: 256. loss: 0.2707. loss_u: 0.2525. loss_x: 0.0182. Mask:0.8001 . LR: 0.0236. Time: 58.48\n",
      "2022-04-14 08:31:42,690 - INFO - train -   Epoch 61. Top1: 84.3447. Top5: 99.2914. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:31:42,690 - INFO - train -   Epoch 61. Top1: 84.3447. Top5: 99.2914. best_acc: 87.9118 in epoch 56\n",
      "2022-04-14 08:32:45,041 - INFO - train -   epoch:62, iter: 64. loss: 0.2905. loss_u: 0.2633. loss_x: 0.0273. Mask:0.7856 . LR: 0.0235. Time: 62.34\n",
      "2022-04-14 08:32:45,041 - INFO - train -   epoch:62, iter: 64. loss: 0.2905. loss_u: 0.2633. loss_x: 0.0273. Mask:0.7856 . LR: 0.0235. Time: 62.34\n",
      "2022-04-14 08:33:43,959 - INFO - train -   epoch:62, iter: 128. loss: 0.2875. loss_u: 0.2604. loss_x: 0.0271. Mask:0.7829 . LR: 0.0235. Time: 58.92\n",
      "2022-04-14 08:33:43,959 - INFO - train -   epoch:62, iter: 128. loss: 0.2875. loss_u: 0.2604. loss_x: 0.0271. Mask:0.7829 . LR: 0.0235. Time: 58.92\n",
      "2022-04-14 08:34:44,143 - INFO - train -   epoch:62, iter: 192. loss: 0.2836. loss_u: 0.2587. loss_x: 0.0249. Mask:0.7865 . LR: 0.0234. Time: 60.18\n",
      "2022-04-14 08:34:44,143 - INFO - train -   epoch:62, iter: 192. loss: 0.2836. loss_u: 0.2587. loss_x: 0.0249. Mask:0.7865 . LR: 0.0234. Time: 60.18\n",
      "2022-04-14 08:35:44,883 - INFO - train -   epoch:62, iter: 256. loss: 0.2794. loss_u: 0.2570. loss_x: 0.0223. Mask:0.7914 . LR: 0.0234. Time: 60.74\n",
      "2022-04-14 08:35:44,883 - INFO - train -   epoch:62, iter: 256. loss: 0.2794. loss_u: 0.2570. loss_x: 0.0223. Mask:0.7914 . LR: 0.0234. Time: 60.74\n",
      "2022-04-14 08:35:49,037 - INFO - train -   Epoch 62. Top1: 88.2207. Top5: 99.3278. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:35:49,037 - INFO - train -   Epoch 62. Top1: 88.2207. Top5: 99.3278. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:36:51,045 - INFO - train -   epoch:63, iter: 64. loss: 0.2668. loss_u: 0.2498. loss_x: 0.0170. Mask:0.8010 . LR: 0.0233. Time: 62.00\n",
      "2022-04-14 08:36:51,045 - INFO - train -   epoch:63, iter: 64. loss: 0.2668. loss_u: 0.2498. loss_x: 0.0170. Mask:0.8010 . LR: 0.0233. Time: 62.00\n",
      "2022-04-14 08:37:51,728 - INFO - train -   epoch:63, iter: 128. loss: 0.2717. loss_u: 0.2530. loss_x: 0.0187. Mask:0.7979 . LR: 0.0233. Time: 60.68\n",
      "2022-04-14 08:37:51,728 - INFO - train -   epoch:63, iter: 128. loss: 0.2717. loss_u: 0.2530. loss_x: 0.0187. Mask:0.7979 . LR: 0.0233. Time: 60.68\n",
      "2022-04-14 08:38:51,291 - INFO - train -   epoch:63, iter: 192. loss: 0.2714. loss_u: 0.2534. loss_x: 0.0180. Mask:0.8019 . LR: 0.0232. Time: 59.56\n",
      "2022-04-14 08:38:51,291 - INFO - train -   epoch:63, iter: 192. loss: 0.2714. loss_u: 0.2534. loss_x: 0.0180. Mask:0.8019 . LR: 0.0232. Time: 59.56\n",
      "2022-04-14 08:39:53,024 - INFO - train -   epoch:63, iter: 256. loss: 0.2725. loss_u: 0.2525. loss_x: 0.0199. Mask:0.8019 . LR: 0.0232. Time: 61.73\n",
      "2022-04-14 08:39:53,024 - INFO - train -   epoch:63, iter: 256. loss: 0.2725. loss_u: 0.2525. loss_x: 0.0199. Mask:0.8019 . LR: 0.0232. Time: 61.73\n",
      "2022-04-14 08:39:57,198 - INFO - train -   Epoch 63. Top1: 87.5606. Top5: 99.3035. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:39:57,198 - INFO - train -   Epoch 63. Top1: 87.5606. Top5: 99.3035. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:41:00,946 - INFO - train -   epoch:64, iter: 64. loss: 0.2767. loss_u: 0.2558. loss_x: 0.0210. Mask:0.7983 . LR: 0.0231. Time: 63.74\n",
      "2022-04-14 08:41:00,946 - INFO - train -   epoch:64, iter: 64. loss: 0.2767. loss_u: 0.2558. loss_x: 0.0210. Mask:0.7983 . LR: 0.0231. Time: 63.74\n",
      "2022-04-14 08:42:01,750 - INFO - train -   epoch:64, iter: 128. loss: 0.2704. loss_u: 0.2514. loss_x: 0.0190. Mask:0.7978 . LR: 0.0231. Time: 60.80\n",
      "2022-04-14 08:42:01,750 - INFO - train -   epoch:64, iter: 128. loss: 0.2704. loss_u: 0.2514. loss_x: 0.0190. Mask:0.7978 . LR: 0.0231. Time: 60.80\n",
      "2022-04-14 08:43:01,539 - INFO - train -   epoch:64, iter: 192. loss: 0.2684. loss_u: 0.2497. loss_x: 0.0187. Mask:0.8002 . LR: 0.0230. Time: 59.79\n",
      "2022-04-14 08:43:01,539 - INFO - train -   epoch:64, iter: 192. loss: 0.2684. loss_u: 0.2497. loss_x: 0.0187. Mask:0.8002 . LR: 0.0230. Time: 59.79\n",
      "2022-04-14 08:43:59,788 - INFO - train -   epoch:64, iter: 256. loss: 0.2698. loss_u: 0.2511. loss_x: 0.0187. Mask:0.8007 . LR: 0.0230. Time: 58.25\n",
      "2022-04-14 08:43:59,788 - INFO - train -   epoch:64, iter: 256. loss: 0.2698. loss_u: 0.2511. loss_x: 0.0187. Mask:0.8007 . LR: 0.0230. Time: 58.25\n",
      "2022-04-14 08:44:04,120 - INFO - train -   Epoch 64. Top1: 87.7604. Top5: 99.4368. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:44:04,120 - INFO - train -   Epoch 64. Top1: 87.7604. Top5: 99.4368. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:45:05,092 - INFO - train -   epoch:65, iter: 64. loss: 0.2726. loss_u: 0.2520. loss_x: 0.0206. Mask:0.8009 . LR: 0.0229. Time: 60.97\n",
      "2022-04-14 08:45:05,092 - INFO - train -   epoch:65, iter: 64. loss: 0.2726. loss_u: 0.2520. loss_x: 0.0206. Mask:0.8009 . LR: 0.0229. Time: 60.97\n",
      "2022-04-14 08:46:02,435 - INFO - train -   epoch:65, iter: 128. loss: 0.2682. loss_u: 0.2494. loss_x: 0.0188. Mask:0.8037 . LR: 0.0229. Time: 57.34\n",
      "2022-04-14 08:46:02,435 - INFO - train -   epoch:65, iter: 128. loss: 0.2682. loss_u: 0.2494. loss_x: 0.0188. Mask:0.8037 . LR: 0.0229. Time: 57.34\n",
      "2022-04-14 08:47:01,192 - INFO - train -   epoch:65, iter: 192. loss: 0.2668. loss_u: 0.2486. loss_x: 0.0182. Mask:0.8053 . LR: 0.0228. Time: 58.76\n",
      "2022-04-14 08:47:01,192 - INFO - train -   epoch:65, iter: 192. loss: 0.2668. loss_u: 0.2486. loss_x: 0.0182. Mask:0.8053 . LR: 0.0228. Time: 58.76\n",
      "2022-04-14 08:48:01,523 - INFO - train -   epoch:65, iter: 256. loss: 0.2674. loss_u: 0.2506. loss_x: 0.0168. Mask:0.8080 . LR: 0.0228. Time: 60.33\n",
      "2022-04-14 08:48:01,523 - INFO - train -   epoch:65, iter: 256. loss: 0.2674. loss_u: 0.2506. loss_x: 0.0168. Mask:0.8080 . LR: 0.0228. Time: 60.33\n",
      "2022-04-14 08:48:05,599 - INFO - train -   Epoch 65. Top1: 87.1548. Top5: 99.2188. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:48:05,599 - INFO - train -   Epoch 65. Top1: 87.1548. Top5: 99.2188. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:49:09,786 - INFO - train -   epoch:66, iter: 64. loss: 0.2765. loss_u: 0.2535. loss_x: 0.0230. Mask:0.8019 . LR: 0.0227. Time: 64.18\n",
      "2022-04-14 08:49:09,786 - INFO - train -   epoch:66, iter: 64. loss: 0.2765. loss_u: 0.2535. loss_x: 0.0230. Mask:0.8019 . LR: 0.0227. Time: 64.18\n",
      "2022-04-14 08:50:09,019 - INFO - train -   epoch:66, iter: 128. loss: 0.2774. loss_u: 0.2543. loss_x: 0.0230. Mask:0.8050 . LR: 0.0227. Time: 59.23\n",
      "2022-04-14 08:50:09,019 - INFO - train -   epoch:66, iter: 128. loss: 0.2774. loss_u: 0.2543. loss_x: 0.0230. Mask:0.8050 . LR: 0.0227. Time: 59.23\n",
      "2022-04-14 08:51:10,975 - INFO - train -   epoch:66, iter: 192. loss: 0.2757. loss_u: 0.2531. loss_x: 0.0226. Mask:0.8025 . LR: 0.0226. Time: 61.95\n",
      "2022-04-14 08:51:10,975 - INFO - train -   epoch:66, iter: 192. loss: 0.2757. loss_u: 0.2531. loss_x: 0.0226. Mask:0.8025 . LR: 0.0226. Time: 61.95\n",
      "2022-04-14 08:52:13,764 - INFO - train -   epoch:66, iter: 256. loss: 0.2747. loss_u: 0.2513. loss_x: 0.0234. Mask:0.7993 . LR: 0.0226. Time: 62.79\n",
      "2022-04-14 08:52:13,764 - INFO - train -   epoch:66, iter: 256. loss: 0.2747. loss_u: 0.2513. loss_x: 0.0234. Mask:0.7993 . LR: 0.0226. Time: 62.79\n",
      "2022-04-14 08:52:17,920 - INFO - train -   Epoch 66. Top1: 86.7854. Top5: 99.3096. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:52:17,920 - INFO - train -   Epoch 66. Top1: 86.7854. Top5: 99.3096. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:53:22,143 - INFO - train -   epoch:67, iter: 64. loss: 0.2666. loss_u: 0.2505. loss_x: 0.0160. Mask:0.8017 . LR: 0.0225. Time: 64.22\n",
      "2022-04-14 08:53:22,143 - INFO - train -   epoch:67, iter: 64. loss: 0.2666. loss_u: 0.2505. loss_x: 0.0160. Mask:0.8017 . LR: 0.0225. Time: 64.22\n",
      "2022-04-14 08:54:20,439 - INFO - train -   epoch:67, iter: 128. loss: 0.2729. loss_u: 0.2523. loss_x: 0.0206. Mask:0.7981 . LR: 0.0225. Time: 58.29\n",
      "2022-04-14 08:54:20,439 - INFO - train -   epoch:67, iter: 128. loss: 0.2729. loss_u: 0.2523. loss_x: 0.0206. Mask:0.7981 . LR: 0.0225. Time: 58.29\n",
      "2022-04-14 08:55:21,508 - INFO - train -   epoch:67, iter: 192. loss: 0.2701. loss_u: 0.2504. loss_x: 0.0197. Mask:0.7957 . LR: 0.0224. Time: 61.07\n",
      "2022-04-14 08:55:21,508 - INFO - train -   epoch:67, iter: 192. loss: 0.2701. loss_u: 0.2504. loss_x: 0.0197. Mask:0.7957 . LR: 0.0224. Time: 61.07\n",
      "2022-04-14 08:56:21,555 - INFO - train -   epoch:67, iter: 256. loss: 0.2707. loss_u: 0.2517. loss_x: 0.0190. Mask:0.7989 . LR: 0.0224. Time: 60.04\n",
      "2022-04-14 08:56:21,555 - INFO - train -   epoch:67, iter: 256. loss: 0.2707. loss_u: 0.2517. loss_x: 0.0190. Mask:0.7989 . LR: 0.0224. Time: 60.04\n",
      "2022-04-14 08:56:25,517 - INFO - train -   Epoch 67. Top1: 88.0329. Top5: 99.3823. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:56:25,517 - INFO - train -   Epoch 67. Top1: 88.0329. Top5: 99.3823. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 08:57:27,594 - INFO - train -   epoch:68, iter: 64. loss: 0.2575. loss_u: 0.2434. loss_x: 0.0141. Mask:0.8135 . LR: 0.0223. Time: 62.07\n",
      "2022-04-14 08:57:27,594 - INFO - train -   epoch:68, iter: 64. loss: 0.2575. loss_u: 0.2434. loss_x: 0.0141. Mask:0.8135 . LR: 0.0223. Time: 62.07\n",
      "2022-04-14 08:58:27,228 - INFO - train -   epoch:68, iter: 128. loss: 0.2611. loss_u: 0.2435. loss_x: 0.0176. Mask:0.8088 . LR: 0.0222. Time: 59.63\n",
      "2022-04-14 08:58:27,228 - INFO - train -   epoch:68, iter: 128. loss: 0.2611. loss_u: 0.2435. loss_x: 0.0176. Mask:0.8088 . LR: 0.0222. Time: 59.63\n",
      "2022-04-14 08:59:26,167 - INFO - train -   epoch:68, iter: 192. loss: 0.2626. loss_u: 0.2444. loss_x: 0.0182. Mask:0.8080 . LR: 0.0222. Time: 58.94\n",
      "2022-04-14 08:59:26,167 - INFO - train -   epoch:68, iter: 192. loss: 0.2626. loss_u: 0.2444. loss_x: 0.0182. Mask:0.8080 . LR: 0.0222. Time: 58.94\n",
      "2022-04-14 09:00:27,225 - INFO - train -   epoch:68, iter: 256. loss: 0.2648. loss_u: 0.2464. loss_x: 0.0184. Mask:0.8075 . LR: 0.0221. Time: 61.06\n",
      "2022-04-14 09:00:27,225 - INFO - train -   epoch:68, iter: 256. loss: 0.2648. loss_u: 0.2464. loss_x: 0.0184. Mask:0.8075 . LR: 0.0221. Time: 61.06\n",
      "2022-04-14 09:00:31,391 - INFO - train -   Epoch 68. Top1: 88.0632. Top5: 99.1642. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 09:00:31,391 - INFO - train -   Epoch 68. Top1: 88.0632. Top5: 99.1642. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 09:01:31,832 - INFO - train -   epoch:69, iter: 64. loss: 0.2767. loss_u: 0.2541. loss_x: 0.0226. Mask:0.7938 . LR: 0.0221. Time: 60.43\n",
      "2022-04-14 09:01:31,832 - INFO - train -   epoch:69, iter: 64. loss: 0.2767. loss_u: 0.2541. loss_x: 0.0226. Mask:0.7938 . LR: 0.0221. Time: 60.43\n",
      "2022-04-14 09:02:29,624 - INFO - train -   epoch:69, iter: 128. loss: 0.2726. loss_u: 0.2543. loss_x: 0.0182. Mask:0.8002 . LR: 0.0220. Time: 57.79\n",
      "2022-04-14 09:02:29,624 - INFO - train -   epoch:69, iter: 128. loss: 0.2726. loss_u: 0.2543. loss_x: 0.0182. Mask:0.8002 . LR: 0.0220. Time: 57.79\n",
      "2022-04-14 09:03:28,669 - INFO - train -   epoch:69, iter: 192. loss: 0.2733. loss_u: 0.2536. loss_x: 0.0197. Mask:0.8029 . LR: 0.0220. Time: 59.04\n",
      "2022-04-14 09:03:28,669 - INFO - train -   epoch:69, iter: 192. loss: 0.2733. loss_u: 0.2536. loss_x: 0.0197. Mask:0.8029 . LR: 0.0220. Time: 59.04\n",
      "2022-04-14 09:04:26,230 - INFO - train -   epoch:69, iter: 256. loss: 0.2759. loss_u: 0.2542. loss_x: 0.0218. Mask:0.8005 . LR: 0.0219. Time: 57.56\n",
      "2022-04-14 09:04:26,230 - INFO - train -   epoch:69, iter: 256. loss: 0.2759. loss_u: 0.2542. loss_x: 0.0218. Mask:0.8005 . LR: 0.0219. Time: 57.56\n",
      "2022-04-14 09:04:30,465 - INFO - train -   Epoch 69. Top1: 87.8270. Top5: 99.4368. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 09:04:30,465 - INFO - train -   Epoch 69. Top1: 87.8270. Top5: 99.4368. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 09:05:32,336 - INFO - train -   epoch:70, iter: 64. loss: 0.2706. loss_u: 0.2491. loss_x: 0.0215. Mask:0.7971 . LR: 0.0219. Time: 61.87\n",
      "2022-04-14 09:05:32,336 - INFO - train -   epoch:70, iter: 64. loss: 0.2706. loss_u: 0.2491. loss_x: 0.0215. Mask:0.7971 . LR: 0.0219. Time: 61.87\n",
      "2022-04-14 09:06:33,249 - INFO - train -   epoch:70, iter: 128. loss: 0.2693. loss_u: 0.2487. loss_x: 0.0205. Mask:0.7977 . LR: 0.0218. Time: 60.91\n",
      "2022-04-14 09:06:33,249 - INFO - train -   epoch:70, iter: 128. loss: 0.2693. loss_u: 0.2487. loss_x: 0.0205. Mask:0.7977 . LR: 0.0218. Time: 60.91\n",
      "2022-04-14 09:07:34,592 - INFO - train -   epoch:70, iter: 192. loss: 0.2682. loss_u: 0.2487. loss_x: 0.0194. Mask:0.8022 . LR: 0.0218. Time: 61.34\n",
      "2022-04-14 09:07:34,592 - INFO - train -   epoch:70, iter: 192. loss: 0.2682. loss_u: 0.2487. loss_x: 0.0194. Mask:0.8022 . LR: 0.0218. Time: 61.34\n",
      "2022-04-14 09:08:36,375 - INFO - train -   epoch:70, iter: 256. loss: 0.2647. loss_u: 0.2479. loss_x: 0.0167. Mask:0.8060 . LR: 0.0217. Time: 61.78\n",
      "2022-04-14 09:08:36,375 - INFO - train -   epoch:70, iter: 256. loss: 0.2647. loss_u: 0.2479. loss_x: 0.0167. Mask:0.8060 . LR: 0.0217. Time: 61.78\n",
      "2022-04-14 09:08:40,544 - INFO - train -   Epoch 70. Top1: 87.4758. Top5: 99.4549. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 09:08:40,544 - INFO - train -   Epoch 70. Top1: 87.4758. Top5: 99.4549. best_acc: 88.2207 in epoch 62\n",
      "2022-04-14 09:09:47,276 - INFO - train -   epoch:71, iter: 64. loss: 0.2679. loss_u: 0.2559. loss_x: 0.0120. Mask:0.8104 . LR: 0.0216. Time: 66.73\n",
      "2022-04-14 09:09:47,276 - INFO - train -   epoch:71, iter: 64. loss: 0.2679. loss_u: 0.2559. loss_x: 0.0120. Mask:0.8104 . LR: 0.0216. Time: 66.73\n",
      "2022-04-14 09:10:51,161 - INFO - train -   epoch:71, iter: 128. loss: 0.2725. loss_u: 0.2539. loss_x: 0.0186. Mask:0.8120 . LR: 0.0216. Time: 63.88\n",
      "2022-04-14 09:10:51,161 - INFO - train -   epoch:71, iter: 128. loss: 0.2725. loss_u: 0.2539. loss_x: 0.0186. Mask:0.8120 . LR: 0.0216. Time: 63.88\n",
      "2022-04-14 09:11:54,540 - INFO - train -   epoch:71, iter: 192. loss: 0.2684. loss_u: 0.2474. loss_x: 0.0210. Mask:0.8091 . LR: 0.0215. Time: 63.38\n",
      "2022-04-14 09:11:54,540 - INFO - train -   epoch:71, iter: 192. loss: 0.2684. loss_u: 0.2474. loss_x: 0.0210. Mask:0.8091 . LR: 0.0215. Time: 63.38\n",
      "2022-04-14 09:12:56,531 - INFO - train -   epoch:71, iter: 256. loss: 0.2672. loss_u: 0.2473. loss_x: 0.0200. Mask:0.8091 . LR: 0.0215. Time: 61.99\n",
      "2022-04-14 09:12:56,531 - INFO - train -   epoch:71, iter: 256. loss: 0.2672. loss_u: 0.2473. loss_x: 0.0200. Mask:0.8091 . LR: 0.0215. Time: 61.99\n",
      "2022-04-14 09:13:00,584 - INFO - train -   Epoch 71. Top1: 88.7839. Top5: 99.4731. best_acc: 88.7839 in epoch 71\n",
      "2022-04-14 09:13:00,584 - INFO - train -   Epoch 71. Top1: 88.7839. Top5: 99.4731. best_acc: 88.7839 in epoch 71\n",
      "2022-04-14 09:14:04,473 - INFO - train -   epoch:72, iter: 64. loss: 0.2877. loss_u: 0.2518. loss_x: 0.0359. Mask:0.7880 . LR: 0.0214. Time: 63.88\n",
      "2022-04-14 09:14:04,473 - INFO - train -   epoch:72, iter: 64. loss: 0.2877. loss_u: 0.2518. loss_x: 0.0359. Mask:0.7880 . LR: 0.0214. Time: 63.88\n",
      "2022-04-14 09:15:05,467 - INFO - train -   epoch:72, iter: 128. loss: 0.2780. loss_u: 0.2493. loss_x: 0.0286. Mask:0.7971 . LR: 0.0214. Time: 60.99\n",
      "2022-04-14 09:15:05,467 - INFO - train -   epoch:72, iter: 128. loss: 0.2780. loss_u: 0.2493. loss_x: 0.0286. Mask:0.7971 . LR: 0.0214. Time: 60.99\n",
      "2022-04-14 09:16:06,433 - INFO - train -   epoch:72, iter: 192. loss: 0.2745. loss_u: 0.2498. loss_x: 0.0246. Mask:0.8042 . LR: 0.0213. Time: 60.96\n",
      "2022-04-14 09:16:06,433 - INFO - train -   epoch:72, iter: 192. loss: 0.2745. loss_u: 0.2498. loss_x: 0.0246. Mask:0.8042 . LR: 0.0213. Time: 60.96\n",
      "2022-04-14 09:17:09,603 - INFO - train -   epoch:72, iter: 256. loss: 0.2728. loss_u: 0.2499. loss_x: 0.0229. Mask:0.8057 . LR: 0.0212. Time: 63.17\n",
      "2022-04-14 09:17:09,603 - INFO - train -   epoch:72, iter: 256. loss: 0.2728. loss_u: 0.2499. loss_x: 0.0229. Mask:0.8057 . LR: 0.0212. Time: 63.17\n",
      "2022-04-14 09:17:13,570 - INFO - train -   Epoch 72. Top1: 88.9959. Top5: 99.6366. best_acc: 88.9959 in epoch 72\n",
      "2022-04-14 09:17:13,570 - INFO - train -   Epoch 72. Top1: 88.9959. Top5: 99.6366. best_acc: 88.9959 in epoch 72\n",
      "2022-04-14 09:18:19,070 - INFO - train -   epoch:73, iter: 64. loss: 0.2617. loss_u: 0.2450. loss_x: 0.0167. Mask:0.8141 . LR: 0.0212. Time: 65.49\n",
      "2022-04-14 09:18:19,070 - INFO - train -   epoch:73, iter: 64. loss: 0.2617. loss_u: 0.2450. loss_x: 0.0167. Mask:0.8141 . LR: 0.0212. Time: 65.49\n",
      "2022-04-14 09:19:23,058 - INFO - train -   epoch:73, iter: 128. loss: 0.2621. loss_u: 0.2446. loss_x: 0.0175. Mask:0.8154 . LR: 0.0211. Time: 63.98\n",
      "2022-04-14 09:19:23,058 - INFO - train -   epoch:73, iter: 128. loss: 0.2621. loss_u: 0.2446. loss_x: 0.0175. Mask:0.8154 . LR: 0.0211. Time: 63.98\n",
      "2022-04-14 09:20:26,603 - INFO - train -   epoch:73, iter: 192. loss: 0.2606. loss_u: 0.2433. loss_x: 0.0173. Mask:0.8172 . LR: 0.0211. Time: 63.54\n",
      "2022-04-14 09:20:26,603 - INFO - train -   epoch:73, iter: 192. loss: 0.2606. loss_u: 0.2433. loss_x: 0.0173. Mask:0.8172 . LR: 0.0211. Time: 63.54\n",
      "2022-04-14 09:21:30,252 - INFO - train -   epoch:73, iter: 256. loss: 0.2636. loss_u: 0.2450. loss_x: 0.0186. Mask:0.8152 . LR: 0.0210. Time: 63.64\n",
      "2022-04-14 09:21:30,252 - INFO - train -   epoch:73, iter: 256. loss: 0.2636. loss_u: 0.2450. loss_x: 0.0186. Mask:0.8152 . LR: 0.0210. Time: 63.64\n",
      "2022-04-14 09:21:34,305 - INFO - train -   Epoch 73. Top1: 86.9913. Top5: 99.1824. best_acc: 88.9959 in epoch 72\n",
      "2022-04-14 09:21:34,305 - INFO - train -   Epoch 73. Top1: 86.9913. Top5: 99.1824. best_acc: 88.9959 in epoch 72\n",
      "2022-04-14 09:22:40,394 - INFO - train -   epoch:74, iter: 64. loss: 0.2860. loss_u: 0.2528. loss_x: 0.0333. Mask:0.7878 . LR: 0.0210. Time: 66.08\n",
      "2022-04-14 09:22:40,394 - INFO - train -   epoch:74, iter: 64. loss: 0.2860. loss_u: 0.2528. loss_x: 0.0333. Mask:0.7878 . LR: 0.0210. Time: 66.08\n",
      "2022-04-14 09:23:45,732 - INFO - train -   epoch:74, iter: 128. loss: 0.2736. loss_u: 0.2503. loss_x: 0.0232. Mask:0.8012 . LR: 0.0209. Time: 65.34\n",
      "2022-04-14 09:23:45,732 - INFO - train -   epoch:74, iter: 128. loss: 0.2736. loss_u: 0.2503. loss_x: 0.0232. Mask:0.8012 . LR: 0.0209. Time: 65.34\n",
      "2022-04-14 09:24:48,482 - INFO - train -   epoch:74, iter: 192. loss: 0.2743. loss_u: 0.2523. loss_x: 0.0219. Mask:0.8069 . LR: 0.0208. Time: 62.75\n",
      "2022-04-14 09:24:48,482 - INFO - train -   epoch:74, iter: 192. loss: 0.2743. loss_u: 0.2523. loss_x: 0.0219. Mask:0.8069 . LR: 0.0208. Time: 62.75\n",
      "2022-04-14 09:25:53,766 - INFO - train -   epoch:74, iter: 256. loss: 0.2716. loss_u: 0.2510. loss_x: 0.0206. Mask:0.8084 . LR: 0.0208. Time: 65.28\n",
      "2022-04-14 09:25:53,766 - INFO - train -   epoch:74, iter: 256. loss: 0.2716. loss_u: 0.2510. loss_x: 0.0206. Mask:0.8084 . LR: 0.0208. Time: 65.28\n",
      "2022-04-14 09:25:57,919 - INFO - train -   Epoch 74. Top1: 87.9118. Top5: 99.5458. best_acc: 88.9959 in epoch 72\n",
      "2022-04-14 09:25:57,919 - INFO - train -   Epoch 74. Top1: 87.9118. Top5: 99.5458. best_acc: 88.9959 in epoch 72\n",
      "2022-04-14 09:27:02,109 - INFO - train -   epoch:75, iter: 64. loss: 0.2634. loss_u: 0.2499. loss_x: 0.0135. Mask:0.8090 . LR: 0.0207. Time: 64.19\n",
      "2022-04-14 09:27:02,109 - INFO - train -   epoch:75, iter: 64. loss: 0.2634. loss_u: 0.2499. loss_x: 0.0135. Mask:0.8090 . LR: 0.0207. Time: 64.19\n",
      "2022-04-14 09:28:03,709 - INFO - train -   epoch:75, iter: 128. loss: 0.2664. loss_u: 0.2514. loss_x: 0.0150. Mask:0.8120 . LR: 0.0207. Time: 61.60\n",
      "2022-04-14 09:28:03,709 - INFO - train -   epoch:75, iter: 128. loss: 0.2664. loss_u: 0.2514. loss_x: 0.0150. Mask:0.8120 . LR: 0.0207. Time: 61.60\n",
      "2022-04-14 09:29:06,399 - INFO - train -   epoch:75, iter: 192. loss: 0.2652. loss_u: 0.2514. loss_x: 0.0139. Mask:0.8180 . LR: 0.0206. Time: 62.69\n",
      "2022-04-14 09:29:06,399 - INFO - train -   epoch:75, iter: 192. loss: 0.2652. loss_u: 0.2514. loss_x: 0.0139. Mask:0.8180 . LR: 0.0206. Time: 62.69\n",
      "2022-04-14 09:30:06,695 - INFO - train -   epoch:75, iter: 256. loss: 0.2656. loss_u: 0.2518. loss_x: 0.0138. Mask:0.8190 . LR: 0.0206. Time: 60.29\n",
      "2022-04-14 09:30:06,695 - INFO - train -   epoch:75, iter: 256. loss: 0.2656. loss_u: 0.2518. loss_x: 0.0138. Mask:0.8190 . LR: 0.0206. Time: 60.29\n",
      "2022-04-14 09:30:10,830 - INFO - train -   Epoch 75. Top1: 89.0564. Top5: 99.3641. best_acc: 89.0564 in epoch 75\n",
      "2022-04-14 09:30:10,830 - INFO - train -   Epoch 75. Top1: 89.0564. Top5: 99.3641. best_acc: 89.0564 in epoch 75\n",
      "2022-04-14 09:31:18,988 - INFO - train -   epoch:76, iter: 64. loss: 0.2531. loss_u: 0.2434. loss_x: 0.0097. Mask:0.8310 . LR: 0.0205. Time: 68.15\n",
      "2022-04-14 09:31:18,988 - INFO - train -   epoch:76, iter: 64. loss: 0.2531. loss_u: 0.2434. loss_x: 0.0097. Mask:0.8310 . LR: 0.0205. Time: 68.15\n",
      "2022-04-14 09:32:22,491 - INFO - train -   epoch:76, iter: 128. loss: 0.2595. loss_u: 0.2444. loss_x: 0.0151. Mask:0.8229 . LR: 0.0204. Time: 63.50\n",
      "2022-04-14 09:32:22,491 - INFO - train -   epoch:76, iter: 128. loss: 0.2595. loss_u: 0.2444. loss_x: 0.0151. Mask:0.8229 . LR: 0.0204. Time: 63.50\n",
      "2022-04-14 09:33:24,397 - INFO - train -   epoch:76, iter: 192. loss: 0.2613. loss_u: 0.2451. loss_x: 0.0162. Mask:0.8201 . LR: 0.0204. Time: 61.90\n",
      "2022-04-14 09:33:24,397 - INFO - train -   epoch:76, iter: 192. loss: 0.2613. loss_u: 0.2451. loss_x: 0.0162. Mask:0.8201 . LR: 0.0204. Time: 61.90\n",
      "2022-04-14 09:34:26,567 - INFO - train -   epoch:76, iter: 256. loss: 0.2609. loss_u: 0.2445. loss_x: 0.0164. Mask:0.8177 . LR: 0.0203. Time: 62.17\n",
      "2022-04-14 09:34:26,567 - INFO - train -   epoch:76, iter: 256. loss: 0.2609. loss_u: 0.2445. loss_x: 0.0164. Mask:0.8177 . LR: 0.0203. Time: 62.17\n",
      "2022-04-14 09:34:30,614 - INFO - train -   Epoch 76. Top1: 87.3547. Top5: 99.0916. best_acc: 89.0564 in epoch 75\n",
      "2022-04-14 09:34:30,614 - INFO - train -   Epoch 76. Top1: 87.3547. Top5: 99.0916. best_acc: 89.0564 in epoch 75\n",
      "2022-04-14 09:35:37,950 - INFO - train -   epoch:77, iter: 64. loss: 0.2566. loss_u: 0.2408. loss_x: 0.0158. Mask:0.8195 . LR: 0.0203. Time: 67.33\n",
      "2022-04-14 09:35:37,950 - INFO - train -   epoch:77, iter: 64. loss: 0.2566. loss_u: 0.2408. loss_x: 0.0158. Mask:0.8195 . LR: 0.0203. Time: 67.33\n",
      "2022-04-14 09:36:42,535 - INFO - train -   epoch:77, iter: 128. loss: 0.2601. loss_u: 0.2414. loss_x: 0.0188. Mask:0.8168 . LR: 0.0202. Time: 64.58\n",
      "2022-04-14 09:36:42,535 - INFO - train -   epoch:77, iter: 128. loss: 0.2601. loss_u: 0.2414. loss_x: 0.0188. Mask:0.8168 . LR: 0.0202. Time: 64.58\n",
      "2022-04-14 09:37:45,152 - INFO - train -   epoch:77, iter: 192. loss: 0.2619. loss_u: 0.2454. loss_x: 0.0165. Mask:0.8182 . LR: 0.0201. Time: 62.61\n",
      "2022-04-14 09:37:45,152 - INFO - train -   epoch:77, iter: 192. loss: 0.2619. loss_u: 0.2454. loss_x: 0.0165. Mask:0.8182 . LR: 0.0201. Time: 62.61\n",
      "2022-04-14 09:38:47,419 - INFO - train -   epoch:77, iter: 256. loss: 0.2612. loss_u: 0.2442. loss_x: 0.0170. Mask:0.8181 . LR: 0.0201. Time: 62.27\n",
      "2022-04-14 09:38:47,419 - INFO - train -   epoch:77, iter: 256. loss: 0.2612. loss_u: 0.2442. loss_x: 0.0170. Mask:0.8181 . LR: 0.0201. Time: 62.27\n",
      "2022-04-14 09:38:51,793 - INFO - train -   Epoch 77. Top1: 88.9474. Top5: 99.3278. best_acc: 89.0564 in epoch 75\n",
      "2022-04-14 09:38:51,793 - INFO - train -   Epoch 77. Top1: 88.9474. Top5: 99.3278. best_acc: 89.0564 in epoch 75\n",
      "2022-04-14 09:39:56,238 - INFO - train -   epoch:78, iter: 64. loss: 0.2754. loss_u: 0.2521. loss_x: 0.0233. Mask:0.8214 . LR: 0.0200. Time: 64.44\n",
      "2022-04-14 09:39:56,238 - INFO - train -   epoch:78, iter: 64. loss: 0.2754. loss_u: 0.2521. loss_x: 0.0233. Mask:0.8214 . LR: 0.0200. Time: 64.44\n",
      "2022-04-14 09:40:58,806 - INFO - train -   epoch:78, iter: 128. loss: 0.2735. loss_u: 0.2519. loss_x: 0.0215. Mask:0.8174 . LR: 0.0200. Time: 62.56\n",
      "2022-04-14 09:40:58,806 - INFO - train -   epoch:78, iter: 128. loss: 0.2735. loss_u: 0.2519. loss_x: 0.0215. Mask:0.8174 . LR: 0.0200. Time: 62.56\n",
      "2022-04-14 09:42:00,287 - INFO - train -   epoch:78, iter: 192. loss: 0.2683. loss_u: 0.2491. loss_x: 0.0192. Mask:0.8177 . LR: 0.0199. Time: 61.48\n",
      "2022-04-14 09:42:00,287 - INFO - train -   epoch:78, iter: 192. loss: 0.2683. loss_u: 0.2491. loss_x: 0.0192. Mask:0.8177 . LR: 0.0199. Time: 61.48\n",
      "2022-04-14 09:43:02,526 - INFO - train -   epoch:78, iter: 256. loss: 0.2670. loss_u: 0.2498. loss_x: 0.0173. Mask:0.8182 . LR: 0.0198. Time: 62.23\n",
      "2022-04-14 09:43:02,526 - INFO - train -   epoch:78, iter: 256. loss: 0.2670. loss_u: 0.2498. loss_x: 0.0173. Mask:0.8182 . LR: 0.0198. Time: 62.23\n",
      "2022-04-14 09:43:06,568 - INFO - train -   Epoch 78. Top1: 89.8680. Top5: 99.3459. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 09:43:06,568 - INFO - train -   Epoch 78. Top1: 89.8680. Top5: 99.3459. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 09:44:12,283 - INFO - train -   epoch:79, iter: 64. loss: 0.2630. loss_u: 0.2510. loss_x: 0.0120. Mask:0.8190 . LR: 0.0198. Time: 65.71\n",
      "2022-04-14 09:44:12,283 - INFO - train -   epoch:79, iter: 64. loss: 0.2630. loss_u: 0.2510. loss_x: 0.0120. Mask:0.8190 . LR: 0.0198. Time: 65.71\n",
      "2022-04-14 09:45:16,418 - INFO - train -   epoch:79, iter: 128. loss: 0.2633. loss_u: 0.2493. loss_x: 0.0140. Mask:0.8207 . LR: 0.0197. Time: 64.13\n",
      "2022-04-14 09:45:16,418 - INFO - train -   epoch:79, iter: 128. loss: 0.2633. loss_u: 0.2493. loss_x: 0.0140. Mask:0.8207 . LR: 0.0197. Time: 64.13\n",
      "2022-04-14 09:46:20,096 - INFO - train -   epoch:79, iter: 192. loss: 0.2647. loss_u: 0.2484. loss_x: 0.0163. Mask:0.8195 . LR: 0.0197. Time: 63.68\n",
      "2022-04-14 09:46:20,096 - INFO - train -   epoch:79, iter: 192. loss: 0.2647. loss_u: 0.2484. loss_x: 0.0163. Mask:0.8195 . LR: 0.0197. Time: 63.68\n",
      "2022-04-14 09:47:24,700 - INFO - train -   epoch:79, iter: 256. loss: 0.2632. loss_u: 0.2473. loss_x: 0.0159. Mask:0.8196 . LR: 0.0196. Time: 64.60\n",
      "2022-04-14 09:47:24,700 - INFO - train -   epoch:79, iter: 256. loss: 0.2632. loss_u: 0.2473. loss_x: 0.0159. Mask:0.8196 . LR: 0.0196. Time: 64.60\n",
      "2022-04-14 09:47:28,795 - INFO - train -   Epoch 79. Top1: 89.1049. Top5: 99.3823. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 09:47:28,795 - INFO - train -   Epoch 79. Top1: 89.1049. Top5: 99.3823. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 09:48:33,946 - INFO - train -   epoch:80, iter: 64. loss: 0.2591. loss_u: 0.2429. loss_x: 0.0163. Mask:0.8197 . LR: 0.0195. Time: 65.15\n",
      "2022-04-14 09:48:33,946 - INFO - train -   epoch:80, iter: 64. loss: 0.2591. loss_u: 0.2429. loss_x: 0.0163. Mask:0.8197 . LR: 0.0195. Time: 65.15\n",
      "2022-04-14 09:49:36,948 - INFO - train -   epoch:80, iter: 128. loss: 0.2539. loss_u: 0.2397. loss_x: 0.0142. Mask:0.8221 . LR: 0.0195. Time: 63.00\n",
      "2022-04-14 09:49:36,948 - INFO - train -   epoch:80, iter: 128. loss: 0.2539. loss_u: 0.2397. loss_x: 0.0142. Mask:0.8221 . LR: 0.0195. Time: 63.00\n",
      "2022-04-14 09:50:42,721 - INFO - train -   epoch:80, iter: 192. loss: 0.2591. loss_u: 0.2437. loss_x: 0.0154. Mask:0.8241 . LR: 0.0194. Time: 65.77\n",
      "2022-04-14 09:50:42,721 - INFO - train -   epoch:80, iter: 192. loss: 0.2591. loss_u: 0.2437. loss_x: 0.0154. Mask:0.8241 . LR: 0.0194. Time: 65.77\n",
      "2022-04-14 09:51:44,379 - INFO - train -   epoch:80, iter: 256. loss: 0.2625. loss_u: 0.2456. loss_x: 0.0169. Mask:0.8216 . LR: 0.0194. Time: 61.66\n",
      "2022-04-14 09:51:44,379 - INFO - train -   epoch:80, iter: 256. loss: 0.2625. loss_u: 0.2456. loss_x: 0.0169. Mask:0.8216 . LR: 0.0194. Time: 61.66\n",
      "2022-04-14 09:51:48,509 - INFO - train -   Epoch 80. Top1: 87.7846. Top5: 99.1461. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 09:51:48,509 - INFO - train -   Epoch 80. Top1: 87.7846. Top5: 99.1461. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 09:52:53,906 - INFO - train -   epoch:81, iter: 64. loss: 0.2559. loss_u: 0.2430. loss_x: 0.0129. Mask:0.8288 . LR: 0.0193. Time: 65.39\n",
      "2022-04-14 09:52:53,906 - INFO - train -   epoch:81, iter: 64. loss: 0.2559. loss_u: 0.2430. loss_x: 0.0129. Mask:0.8288 . LR: 0.0193. Time: 65.39\n",
      "2022-04-14 09:53:56,331 - INFO - train -   epoch:81, iter: 128. loss: 0.2569. loss_u: 0.2426. loss_x: 0.0143. Mask:0.8269 . LR: 0.0192. Time: 62.42\n",
      "2022-04-14 09:53:56,331 - INFO - train -   epoch:81, iter: 128. loss: 0.2569. loss_u: 0.2426. loss_x: 0.0143. Mask:0.8269 . LR: 0.0192. Time: 62.42\n",
      "2022-04-14 09:54:57,926 - INFO - train -   epoch:81, iter: 192. loss: 0.2548. loss_u: 0.2413. loss_x: 0.0135. Mask:0.8268 . LR: 0.0192. Time: 61.59\n",
      "2022-04-14 09:54:57,926 - INFO - train -   epoch:81, iter: 192. loss: 0.2548. loss_u: 0.2413. loss_x: 0.0135. Mask:0.8268 . LR: 0.0192. Time: 61.59\n",
      "2022-04-14 09:55:59,667 - INFO - train -   epoch:81, iter: 256. loss: 0.2538. loss_u: 0.2412. loss_x: 0.0125. Mask:0.8292 . LR: 0.0191. Time: 61.74\n",
      "2022-04-14 09:55:59,667 - INFO - train -   epoch:81, iter: 256. loss: 0.2538. loss_u: 0.2412. loss_x: 0.0125. Mask:0.8292 . LR: 0.0191. Time: 61.74\n",
      "2022-04-14 09:56:03,863 - INFO - train -   Epoch 81. Top1: 88.6083. Top5: 99.2006. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 09:56:03,863 - INFO - train -   Epoch 81. Top1: 88.6083. Top5: 99.2006. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 09:57:10,592 - INFO - train -   epoch:82, iter: 64. loss: 0.2691. loss_u: 0.2486. loss_x: 0.0205. Mask:0.8223 . LR: 0.0190. Time: 66.72\n",
      "2022-04-14 09:57:10,592 - INFO - train -   epoch:82, iter: 64. loss: 0.2691. loss_u: 0.2486. loss_x: 0.0205. Mask:0.8223 . LR: 0.0190. Time: 66.72\n",
      "2022-04-14 09:58:11,051 - INFO - train -   epoch:82, iter: 128. loss: 0.2620. loss_u: 0.2450. loss_x: 0.0171. Mask:0.8248 . LR: 0.0190. Time: 60.46\n",
      "2022-04-14 09:58:11,051 - INFO - train -   epoch:82, iter: 128. loss: 0.2620. loss_u: 0.2450. loss_x: 0.0171. Mask:0.8248 . LR: 0.0190. Time: 60.46\n",
      "2022-04-14 09:59:11,222 - INFO - train -   epoch:82, iter: 192. loss: 0.2621. loss_u: 0.2455. loss_x: 0.0166. Mask:0.8267 . LR: 0.0189. Time: 60.16\n",
      "2022-04-14 09:59:11,222 - INFO - train -   epoch:82, iter: 192. loss: 0.2621. loss_u: 0.2455. loss_x: 0.0166. Mask:0.8267 . LR: 0.0189. Time: 60.16\n",
      "2022-04-14 10:00:12,563 - INFO - train -   epoch:82, iter: 256. loss: 0.2624. loss_u: 0.2453. loss_x: 0.0171. Mask:0.8229 . LR: 0.0189. Time: 61.34\n",
      "2022-04-14 10:00:12,563 - INFO - train -   epoch:82, iter: 256. loss: 0.2624. loss_u: 0.2453. loss_x: 0.0171. Mask:0.8229 . LR: 0.0189. Time: 61.34\n",
      "2022-04-14 10:00:16,781 - INFO - train -   Epoch 82. Top1: 88.4448. Top5: 99.1824. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 10:00:16,781 - INFO - train -   Epoch 82. Top1: 88.4448. Top5: 99.1824. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 10:01:21,367 - INFO - train -   epoch:83, iter: 64. loss: 0.2654. loss_u: 0.2485. loss_x: 0.0169. Mask:0.8221 . LR: 0.0188. Time: 64.58\n",
      "2022-04-14 10:01:21,367 - INFO - train -   epoch:83, iter: 64. loss: 0.2654. loss_u: 0.2485. loss_x: 0.0169. Mask:0.8221 . LR: 0.0188. Time: 64.58\n",
      "2022-04-14 10:02:21,976 - INFO - train -   epoch:83, iter: 128. loss: 0.2662. loss_u: 0.2474. loss_x: 0.0188. Mask:0.8213 . LR: 0.0187. Time: 60.61\n",
      "2022-04-14 10:02:21,976 - INFO - train -   epoch:83, iter: 128. loss: 0.2662. loss_u: 0.2474. loss_x: 0.0188. Mask:0.8213 . LR: 0.0187. Time: 60.61\n",
      "2022-04-14 10:03:21,381 - INFO - train -   epoch:83, iter: 192. loss: 0.2636. loss_u: 0.2469. loss_x: 0.0167. Mask:0.8235 . LR: 0.0187. Time: 59.40\n",
      "2022-04-14 10:03:21,381 - INFO - train -   epoch:83, iter: 192. loss: 0.2636. loss_u: 0.2469. loss_x: 0.0167. Mask:0.8235 . LR: 0.0187. Time: 59.40\n",
      "2022-04-14 10:04:19,467 - INFO - train -   epoch:83, iter: 256. loss: 0.2640. loss_u: 0.2463. loss_x: 0.0177. Mask:0.8235 . LR: 0.0186. Time: 58.08\n",
      "2022-04-14 10:04:19,467 - INFO - train -   epoch:83, iter: 256. loss: 0.2640. loss_u: 0.2463. loss_x: 0.0177. Mask:0.8235 . LR: 0.0186. Time: 58.08\n",
      "2022-04-14 10:04:23,641 - INFO - train -   Epoch 83. Top1: 88.3479. Top5: 99.3641. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 10:04:23,641 - INFO - train -   Epoch 83. Top1: 88.3479. Top5: 99.3641. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 10:05:27,095 - INFO - train -   epoch:84, iter: 64. loss: 0.2566. loss_u: 0.2463. loss_x: 0.0104. Mask:0.8260 . LR: 0.0185. Time: 63.45\n",
      "2022-04-14 10:05:27,095 - INFO - train -   epoch:84, iter: 64. loss: 0.2566. loss_u: 0.2463. loss_x: 0.0104. Mask:0.8260 . LR: 0.0185. Time: 63.45\n",
      "2022-04-14 10:06:27,787 - INFO - train -   epoch:84, iter: 128. loss: 0.2605. loss_u: 0.2446. loss_x: 0.0159. Mask:0.8264 . LR: 0.0185. Time: 60.69\n",
      "2022-04-14 10:06:27,787 - INFO - train -   epoch:84, iter: 128. loss: 0.2605. loss_u: 0.2446. loss_x: 0.0159. Mask:0.8264 . LR: 0.0185. Time: 60.69\n",
      "2022-04-14 10:07:29,538 - INFO - train -   epoch:84, iter: 192. loss: 0.2614. loss_u: 0.2456. loss_x: 0.0157. Mask:0.8274 . LR: 0.0184. Time: 61.75\n",
      "2022-04-14 10:07:29,538 - INFO - train -   epoch:84, iter: 192. loss: 0.2614. loss_u: 0.2456. loss_x: 0.0157. Mask:0.8274 . LR: 0.0184. Time: 61.75\n",
      "2022-04-14 10:08:31,250 - INFO - train -   epoch:84, iter: 256. loss: 0.2609. loss_u: 0.2456. loss_x: 0.0153. Mask:0.8287 . LR: 0.0183. Time: 61.71\n",
      "2022-04-14 10:08:31,250 - INFO - train -   epoch:84, iter: 256. loss: 0.2609. loss_u: 0.2456. loss_x: 0.0153. Mask:0.8287 . LR: 0.0183. Time: 61.71\n",
      "2022-04-14 10:08:35,363 - INFO - train -   Epoch 84. Top1: 89.2260. Top5: 99.1824. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 10:08:35,363 - INFO - train -   Epoch 84. Top1: 89.2260. Top5: 99.1824. best_acc: 89.8680 in epoch 78\n",
      "2022-04-14 10:09:37,735 - INFO - train -   epoch:85, iter: 64. loss: 0.2514. loss_u: 0.2430. loss_x: 0.0084. Mask:0.8376 . LR: 0.0183. Time: 62.37\n",
      "2022-04-14 10:09:37,735 - INFO - train -   epoch:85, iter: 64. loss: 0.2514. loss_u: 0.2430. loss_x: 0.0084. Mask:0.8376 . LR: 0.0183. Time: 62.37\n",
      "2022-04-14 10:10:39,275 - INFO - train -   epoch:85, iter: 128. loss: 0.2524. loss_u: 0.2418. loss_x: 0.0106. Mask:0.8358 . LR: 0.0182. Time: 61.54\n",
      "2022-04-14 10:10:39,275 - INFO - train -   epoch:85, iter: 128. loss: 0.2524. loss_u: 0.2418. loss_x: 0.0106. Mask:0.8358 . LR: 0.0182. Time: 61.54\n",
      "2022-04-14 10:11:39,380 - INFO - train -   epoch:85, iter: 192. loss: 0.2563. loss_u: 0.2433. loss_x: 0.0130. Mask:0.8325 . LR: 0.0182. Time: 60.10\n",
      "2022-04-14 10:11:39,380 - INFO - train -   epoch:85, iter: 192. loss: 0.2563. loss_u: 0.2433. loss_x: 0.0130. Mask:0.8325 . LR: 0.0182. Time: 60.10\n",
      "2022-04-14 10:12:38,861 - INFO - train -   epoch:85, iter: 256. loss: 0.2573. loss_u: 0.2450. loss_x: 0.0123. Mask:0.8329 . LR: 0.0181. Time: 59.48\n",
      "2022-04-14 10:12:38,861 - INFO - train -   epoch:85, iter: 256. loss: 0.2573. loss_u: 0.2450. loss_x: 0.0123. Mask:0.8329 . LR: 0.0181. Time: 59.48\n",
      "2022-04-14 10:12:43,047 - INFO - train -   Epoch 85. Top1: 90.1647. Top5: 99.4186. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:12:43,047 - INFO - train -   Epoch 85. Top1: 90.1647. Top5: 99.4186. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:13:47,177 - INFO - train -   epoch:86, iter: 64. loss: 0.2610. loss_u: 0.2457. loss_x: 0.0152. Mask:0.8382 . LR: 0.0180. Time: 64.12\n",
      "2022-04-14 10:13:47,177 - INFO - train -   epoch:86, iter: 64. loss: 0.2610. loss_u: 0.2457. loss_x: 0.0152. Mask:0.8382 . LR: 0.0180. Time: 64.12\n",
      "2022-04-14 10:14:48,261 - INFO - train -   epoch:86, iter: 128. loss: 0.2586. loss_u: 0.2447. loss_x: 0.0138. Mask:0.8335 . LR: 0.0180. Time: 61.08\n",
      "2022-04-14 10:14:48,261 - INFO - train -   epoch:86, iter: 128. loss: 0.2586. loss_u: 0.2447. loss_x: 0.0138. Mask:0.8335 . LR: 0.0180. Time: 61.08\n",
      "2022-04-14 10:15:52,771 - INFO - train -   epoch:86, iter: 192. loss: 0.2563. loss_u: 0.2439. loss_x: 0.0124. Mask:0.8367 . LR: 0.0179. Time: 64.51\n",
      "2022-04-14 10:15:52,771 - INFO - train -   epoch:86, iter: 192. loss: 0.2563. loss_u: 0.2439. loss_x: 0.0124. Mask:0.8367 . LR: 0.0179. Time: 64.51\n",
      "2022-04-14 10:16:54,431 - INFO - train -   epoch:86, iter: 256. loss: 0.2558. loss_u: 0.2432. loss_x: 0.0126. Mask:0.8357 . LR: 0.0178. Time: 61.66\n",
      "2022-04-14 10:16:54,431 - INFO - train -   epoch:86, iter: 256. loss: 0.2558. loss_u: 0.2432. loss_x: 0.0126. Mask:0.8357 . LR: 0.0178. Time: 61.66\n",
      "2022-04-14 10:16:58,615 - INFO - train -   Epoch 86. Top1: 89.7408. Top5: 99.4549. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:16:58,615 - INFO - train -   Epoch 86. Top1: 89.7408. Top5: 99.4549. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:18:02,060 - INFO - train -   epoch:87, iter: 64. loss: 0.2663. loss_u: 0.2523. loss_x: 0.0140. Mask:0.8322 . LR: 0.0178. Time: 63.44\n",
      "2022-04-14 10:18:02,060 - INFO - train -   epoch:87, iter: 64. loss: 0.2663. loss_u: 0.2523. loss_x: 0.0140. Mask:0.8322 . LR: 0.0178. Time: 63.44\n",
      "2022-04-14 10:19:01,957 - INFO - train -   epoch:87, iter: 128. loss: 0.2602. loss_u: 0.2487. loss_x: 0.0116. Mask:0.8390 . LR: 0.0177. Time: 59.89\n",
      "2022-04-14 10:19:01,957 - INFO - train -   epoch:87, iter: 128. loss: 0.2602. loss_u: 0.2487. loss_x: 0.0116. Mask:0.8390 . LR: 0.0177. Time: 59.89\n",
      "2022-04-14 10:20:05,533 - INFO - train -   epoch:87, iter: 192. loss: 0.2593. loss_u: 0.2482. loss_x: 0.0111. Mask:0.8356 . LR: 0.0176. Time: 63.57\n",
      "2022-04-14 10:20:05,533 - INFO - train -   epoch:87, iter: 192. loss: 0.2593. loss_u: 0.2482. loss_x: 0.0111. Mask:0.8356 . LR: 0.0176. Time: 63.57\n",
      "2022-04-14 10:21:06,302 - INFO - train -   epoch:87, iter: 256. loss: 0.2571. loss_u: 0.2462. loss_x: 0.0108. Mask:0.8349 . LR: 0.0176. Time: 60.76\n",
      "2022-04-14 10:21:06,302 - INFO - train -   epoch:87, iter: 256. loss: 0.2571. loss_u: 0.2462. loss_x: 0.0108. Mask:0.8349 . LR: 0.0176. Time: 60.76\n",
      "2022-04-14 10:21:10,291 - INFO - train -   Epoch 87. Top1: 90.1344. Top5: 99.5276. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:21:10,291 - INFO - train -   Epoch 87. Top1: 90.1344. Top5: 99.5276. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:22:14,211 - INFO - train -   epoch:88, iter: 64. loss: 0.2617. loss_u: 0.2490. loss_x: 0.0127. Mask:0.8341 . LR: 0.0175. Time: 63.91\n",
      "2022-04-14 10:22:14,211 - INFO - train -   epoch:88, iter: 64. loss: 0.2617. loss_u: 0.2490. loss_x: 0.0127. Mask:0.8341 . LR: 0.0175. Time: 63.91\n",
      "2022-04-14 10:23:19,060 - INFO - train -   epoch:88, iter: 128. loss: 0.2572. loss_u: 0.2464. loss_x: 0.0108. Mask:0.8331 . LR: 0.0174. Time: 64.85\n",
      "2022-04-14 10:23:19,060 - INFO - train -   epoch:88, iter: 128. loss: 0.2572. loss_u: 0.2464. loss_x: 0.0108. Mask:0.8331 . LR: 0.0174. Time: 64.85\n",
      "2022-04-14 10:24:21,771 - INFO - train -   epoch:88, iter: 192. loss: 0.2547. loss_u: 0.2442. loss_x: 0.0105. Mask:0.8341 . LR: 0.0174. Time: 62.71\n",
      "2022-04-14 10:24:21,771 - INFO - train -   epoch:88, iter: 192. loss: 0.2547. loss_u: 0.2442. loss_x: 0.0105. Mask:0.8341 . LR: 0.0174. Time: 62.71\n",
      "2022-04-14 10:25:23,972 - INFO - train -   epoch:88, iter: 256. loss: 0.2543. loss_u: 0.2430. loss_x: 0.0113. Mask:0.8343 . LR: 0.0173. Time: 62.20\n",
      "2022-04-14 10:25:23,972 - INFO - train -   epoch:88, iter: 256. loss: 0.2543. loss_u: 0.2430. loss_x: 0.0113. Mask:0.8343 . LR: 0.0173. Time: 62.20\n",
      "2022-04-14 10:25:28,020 - INFO - train -   Epoch 88. Top1: 89.2078. Top5: 99.6366. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:25:28,020 - INFO - train -   Epoch 88. Top1: 89.2078. Top5: 99.6366. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:26:33,816 - INFO - train -   epoch:89, iter: 64. loss: 0.2564. loss_u: 0.2449. loss_x: 0.0115. Mask:0.8373 . LR: 0.0172. Time: 65.79\n",
      "2022-04-14 10:26:33,816 - INFO - train -   epoch:89, iter: 64. loss: 0.2564. loss_u: 0.2449. loss_x: 0.0115. Mask:0.8373 . LR: 0.0172. Time: 65.79\n",
      "2022-04-14 10:27:37,171 - INFO - train -   epoch:89, iter: 128. loss: 0.2504. loss_u: 0.2405. loss_x: 0.0099. Mask:0.8385 . LR: 0.0172. Time: 63.35\n",
      "2022-04-14 10:27:37,171 - INFO - train -   epoch:89, iter: 128. loss: 0.2504. loss_u: 0.2405. loss_x: 0.0099. Mask:0.8385 . LR: 0.0172. Time: 63.35\n",
      "2022-04-14 10:28:39,512 - INFO - train -   epoch:89, iter: 192. loss: 0.2536. loss_u: 0.2431. loss_x: 0.0106. Mask:0.8378 . LR: 0.0171. Time: 62.34\n",
      "2022-04-14 10:28:39,512 - INFO - train -   epoch:89, iter: 192. loss: 0.2536. loss_u: 0.2431. loss_x: 0.0106. Mask:0.8378 . LR: 0.0171. Time: 62.34\n",
      "2022-04-14 10:29:40,493 - INFO - train -   epoch:89, iter: 256. loss: 0.2544. loss_u: 0.2423. loss_x: 0.0121. Mask:0.8365 . LR: 0.0170. Time: 60.98\n",
      "2022-04-14 10:29:40,493 - INFO - train -   epoch:89, iter: 256. loss: 0.2544. loss_u: 0.2423. loss_x: 0.0121. Mask:0.8365 . LR: 0.0170. Time: 60.98\n",
      "2022-04-14 10:29:44,661 - INFO - train -   Epoch 89. Top1: 89.9528. Top5: 99.5821. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:29:44,661 - INFO - train -   Epoch 89. Top1: 89.9528. Top5: 99.5821. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:30:50,410 - INFO - train -   epoch:90, iter: 64. loss: 0.2536. loss_u: 0.2384. loss_x: 0.0153. Mask:0.8293 . LR: 0.0170. Time: 65.74\n",
      "2022-04-14 10:30:50,410 - INFO - train -   epoch:90, iter: 64. loss: 0.2536. loss_u: 0.2384. loss_x: 0.0153. Mask:0.8293 . LR: 0.0170. Time: 65.74\n",
      "2022-04-14 10:31:52,500 - INFO - train -   epoch:90, iter: 128. loss: 0.2550. loss_u: 0.2423. loss_x: 0.0127. Mask:0.8321 . LR: 0.0169. Time: 62.09\n",
      "2022-04-14 10:31:52,500 - INFO - train -   epoch:90, iter: 128. loss: 0.2550. loss_u: 0.2423. loss_x: 0.0127. Mask:0.8321 . LR: 0.0169. Time: 62.09\n",
      "2022-04-14 10:32:57,497 - INFO - train -   epoch:90, iter: 192. loss: 0.2540. loss_u: 0.2391. loss_x: 0.0150. Mask:0.8293 . LR: 0.0168. Time: 64.99\n",
      "2022-04-14 10:32:57,497 - INFO - train -   epoch:90, iter: 192. loss: 0.2540. loss_u: 0.2391. loss_x: 0.0150. Mask:0.8293 . LR: 0.0168. Time: 64.99\n",
      "2022-04-14 10:34:01,616 - INFO - train -   epoch:90, iter: 256. loss: 0.2549. loss_u: 0.2401. loss_x: 0.0148. Mask:0.8298 . LR: 0.0168. Time: 64.12\n",
      "2022-04-14 10:34:01,616 - INFO - train -   epoch:90, iter: 256. loss: 0.2549. loss_u: 0.2401. loss_x: 0.0148. Mask:0.8298 . LR: 0.0168. Time: 64.12\n",
      "2022-04-14 10:34:05,702 - INFO - train -   Epoch 90. Top1: 88.4266. Top5: 99.3096. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:34:05,702 - INFO - train -   Epoch 90. Top1: 88.4266. Top5: 99.3096. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:35:12,591 - INFO - train -   epoch:91, iter: 64. loss: 0.2547. loss_u: 0.2417. loss_x: 0.0130. Mask:0.8304 . LR: 0.0167. Time: 66.88\n",
      "2022-04-14 10:35:12,591 - INFO - train -   epoch:91, iter: 64. loss: 0.2547. loss_u: 0.2417. loss_x: 0.0130. Mask:0.8304 . LR: 0.0167. Time: 66.88\n",
      "2022-04-14 10:36:15,714 - INFO - train -   epoch:91, iter: 128. loss: 0.2523. loss_u: 0.2396. loss_x: 0.0127. Mask:0.8352 . LR: 0.0166. Time: 63.12\n",
      "2022-04-14 10:36:15,714 - INFO - train -   epoch:91, iter: 128. loss: 0.2523. loss_u: 0.2396. loss_x: 0.0127. Mask:0.8352 . LR: 0.0166. Time: 63.12\n",
      "2022-04-14 10:37:19,200 - INFO - train -   epoch:91, iter: 192. loss: 0.2539. loss_u: 0.2400. loss_x: 0.0139. Mask:0.8344 . LR: 0.0166. Time: 63.48\n",
      "2022-04-14 10:37:19,200 - INFO - train -   epoch:91, iter: 192. loss: 0.2539. loss_u: 0.2400. loss_x: 0.0139. Mask:0.8344 . LR: 0.0166. Time: 63.48\n",
      "2022-04-14 10:38:22,021 - INFO - train -   epoch:91, iter: 256. loss: 0.2545. loss_u: 0.2402. loss_x: 0.0143. Mask:0.8329 . LR: 0.0165. Time: 62.82\n",
      "2022-04-14 10:38:22,021 - INFO - train -   epoch:91, iter: 256. loss: 0.2545. loss_u: 0.2402. loss_x: 0.0143. Mask:0.8329 . LR: 0.0165. Time: 62.82\n",
      "2022-04-14 10:38:26,084 - INFO - train -   Epoch 91. Top1: 89.2866. Top5: 99.3641. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:38:26,084 - INFO - train -   Epoch 91. Top1: 89.2866. Top5: 99.3641. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:39:33,438 - INFO - train -   epoch:92, iter: 64. loss: 0.2496. loss_u: 0.2385. loss_x: 0.0110. Mask:0.8407 . LR: 0.0164. Time: 67.35\n",
      "2022-04-14 10:39:33,438 - INFO - train -   epoch:92, iter: 64. loss: 0.2496. loss_u: 0.2385. loss_x: 0.0110. Mask:0.8407 . LR: 0.0164. Time: 67.35\n",
      "2022-04-14 10:40:37,502 - INFO - train -   epoch:92, iter: 128. loss: 0.2513. loss_u: 0.2411. loss_x: 0.0102. Mask:0.8399 . LR: 0.0164. Time: 64.06\n",
      "2022-04-14 10:40:37,502 - INFO - train -   epoch:92, iter: 128. loss: 0.2513. loss_u: 0.2411. loss_x: 0.0102. Mask:0.8399 . LR: 0.0164. Time: 64.06\n",
      "2022-04-14 10:41:38,615 - INFO - train -   epoch:92, iter: 192. loss: 0.2525. loss_u: 0.2422. loss_x: 0.0102. Mask:0.8408 . LR: 0.0163. Time: 61.11\n",
      "2022-04-14 10:41:38,615 - INFO - train -   epoch:92, iter: 192. loss: 0.2525. loss_u: 0.2422. loss_x: 0.0102. Mask:0.8408 . LR: 0.0163. Time: 61.11\n",
      "2022-04-14 10:42:41,436 - INFO - train -   epoch:92, iter: 256. loss: 0.2526. loss_u: 0.2416. loss_x: 0.0110. Mask:0.8391 . LR: 0.0162. Time: 62.82\n",
      "2022-04-14 10:42:41,436 - INFO - train -   epoch:92, iter: 256. loss: 0.2526. loss_u: 0.2416. loss_x: 0.0110. Mask:0.8391 . LR: 0.0162. Time: 62.82\n",
      "2022-04-14 10:42:45,595 - INFO - train -   Epoch 92. Top1: 89.2624. Top5: 99.4368. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:42:45,595 - INFO - train -   Epoch 92. Top1: 89.2624. Top5: 99.4368. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:43:48,588 - INFO - train -   epoch:93, iter: 64. loss: 0.2474. loss_u: 0.2365. loss_x: 0.0109. Mask:0.8337 . LR: 0.0162. Time: 62.99\n",
      "2022-04-14 10:43:48,588 - INFO - train -   epoch:93, iter: 64. loss: 0.2474. loss_u: 0.2365. loss_x: 0.0109. Mask:0.8337 . LR: 0.0162. Time: 62.99\n",
      "2022-04-14 10:44:48,944 - INFO - train -   epoch:93, iter: 128. loss: 0.2582. loss_u: 0.2433. loss_x: 0.0149. Mask:0.8363 . LR: 0.0161. Time: 60.35\n",
      "2022-04-14 10:44:48,944 - INFO - train -   epoch:93, iter: 128. loss: 0.2582. loss_u: 0.2433. loss_x: 0.0149. Mask:0.8363 . LR: 0.0161. Time: 60.35\n",
      "2022-04-14 10:45:49,830 - INFO - train -   epoch:93, iter: 192. loss: 0.2617. loss_u: 0.2450. loss_x: 0.0167. Mask:0.8339 . LR: 0.0160. Time: 60.88\n",
      "2022-04-14 10:45:49,830 - INFO - train -   epoch:93, iter: 192. loss: 0.2617. loss_u: 0.2450. loss_x: 0.0167. Mask:0.8339 . LR: 0.0160. Time: 60.88\n",
      "2022-04-14 10:46:48,303 - INFO - train -   epoch:93, iter: 256. loss: 0.2617. loss_u: 0.2441. loss_x: 0.0175. Mask:0.8312 . LR: 0.0160. Time: 58.47\n",
      "2022-04-14 10:46:48,303 - INFO - train -   epoch:93, iter: 256. loss: 0.2617. loss_u: 0.2441. loss_x: 0.0175. Mask:0.8312 . LR: 0.0160. Time: 58.47\n",
      "2022-04-14 10:46:52,440 - INFO - train -   Epoch 93. Top1: 89.7953. Top5: 99.4004. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:46:52,440 - INFO - train -   Epoch 93. Top1: 89.7953. Top5: 99.4004. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:47:54,192 - INFO - train -   epoch:94, iter: 64. loss: 0.2539. loss_u: 0.2419. loss_x: 0.0119. Mask:0.8351 . LR: 0.0159. Time: 61.75\n",
      "2022-04-14 10:47:54,192 - INFO - train -   epoch:94, iter: 64. loss: 0.2539. loss_u: 0.2419. loss_x: 0.0119. Mask:0.8351 . LR: 0.0159. Time: 61.75\n",
      "2022-04-14 10:48:55,331 - INFO - train -   epoch:94, iter: 128. loss: 0.2584. loss_u: 0.2447. loss_x: 0.0137. Mask:0.8371 . LR: 0.0158. Time: 61.14\n",
      "2022-04-14 10:48:55,331 - INFO - train -   epoch:94, iter: 128. loss: 0.2584. loss_u: 0.2447. loss_x: 0.0137. Mask:0.8371 . LR: 0.0158. Time: 61.14\n",
      "2022-04-14 10:49:55,296 - INFO - train -   epoch:94, iter: 192. loss: 0.2598. loss_u: 0.2466. loss_x: 0.0132. Mask:0.8381 . LR: 0.0158. Time: 59.96\n",
      "2022-04-14 10:49:55,296 - INFO - train -   epoch:94, iter: 192. loss: 0.2598. loss_u: 0.2466. loss_x: 0.0132. Mask:0.8381 . LR: 0.0158. Time: 59.96\n",
      "2022-04-14 10:50:53,745 - INFO - train -   epoch:94, iter: 256. loss: 0.2567. loss_u: 0.2441. loss_x: 0.0126. Mask:0.8385 . LR: 0.0157. Time: 58.45\n",
      "2022-04-14 10:50:53,745 - INFO - train -   epoch:94, iter: 256. loss: 0.2567. loss_u: 0.2441. loss_x: 0.0126. Mask:0.8385 . LR: 0.0157. Time: 58.45\n",
      "2022-04-14 10:50:57,967 - INFO - train -   Epoch 94. Top1: 89.6984. Top5: 99.4549. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:50:57,967 - INFO - train -   Epoch 94. Top1: 89.6984. Top5: 99.4549. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:52:02,508 - INFO - train -   epoch:95, iter: 64. loss: 0.2509. loss_u: 0.2397. loss_x: 0.0112. Mask:0.8308 . LR: 0.0156. Time: 64.53\n",
      "2022-04-14 10:52:02,508 - INFO - train -   epoch:95, iter: 64. loss: 0.2509. loss_u: 0.2397. loss_x: 0.0112. Mask:0.8308 . LR: 0.0156. Time: 64.53\n",
      "2022-04-14 10:53:01,722 - INFO - train -   epoch:95, iter: 128. loss: 0.2462. loss_u: 0.2364. loss_x: 0.0098. Mask:0.8356 . LR: 0.0156. Time: 59.21\n",
      "2022-04-14 10:53:01,722 - INFO - train -   epoch:95, iter: 128. loss: 0.2462. loss_u: 0.2364. loss_x: 0.0098. Mask:0.8356 . LR: 0.0156. Time: 59.21\n",
      "2022-04-14 10:54:03,519 - INFO - train -   epoch:95, iter: 192. loss: 0.2480. loss_u: 0.2374. loss_x: 0.0106. Mask:0.8363 . LR: 0.0155. Time: 61.80\n",
      "2022-04-14 10:54:03,519 - INFO - train -   epoch:95, iter: 192. loss: 0.2480. loss_u: 0.2374. loss_x: 0.0106. Mask:0.8363 . LR: 0.0155. Time: 61.80\n",
      "2022-04-14 10:55:03,354 - INFO - train -   epoch:95, iter: 256. loss: 0.2475. loss_u: 0.2370. loss_x: 0.0105. Mask:0.8373 . LR: 0.0154. Time: 59.83\n",
      "2022-04-14 10:55:03,354 - INFO - train -   epoch:95, iter: 256. loss: 0.2475. loss_u: 0.2370. loss_x: 0.0105. Mask:0.8373 . LR: 0.0154. Time: 59.83\n",
      "2022-04-14 10:55:07,461 - INFO - train -   Epoch 95. Top1: 89.6802. Top5: 99.3641. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:55:07,461 - INFO - train -   Epoch 95. Top1: 89.6802. Top5: 99.3641. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:56:11,383 - INFO - train -   epoch:96, iter: 64. loss: 0.2451. loss_u: 0.2347. loss_x: 0.0103. Mask:0.8421 . LR: 0.0154. Time: 63.92\n",
      "2022-04-14 10:56:11,383 - INFO - train -   epoch:96, iter: 64. loss: 0.2451. loss_u: 0.2347. loss_x: 0.0103. Mask:0.8421 . LR: 0.0154. Time: 63.92\n",
      "2022-04-14 10:57:10,663 - INFO - train -   epoch:96, iter: 128. loss: 0.2485. loss_u: 0.2388. loss_x: 0.0097. Mask:0.8455 . LR: 0.0153. Time: 59.28\n",
      "2022-04-14 10:57:10,663 - INFO - train -   epoch:96, iter: 128. loss: 0.2485. loss_u: 0.2388. loss_x: 0.0097. Mask:0.8455 . LR: 0.0153. Time: 59.28\n",
      "2022-04-14 10:58:10,515 - INFO - train -   epoch:96, iter: 192. loss: 0.2486. loss_u: 0.2380. loss_x: 0.0106. Mask:0.8459 . LR: 0.0152. Time: 59.85\n",
      "2022-04-14 10:58:10,515 - INFO - train -   epoch:96, iter: 192. loss: 0.2486. loss_u: 0.2380. loss_x: 0.0106. Mask:0.8459 . LR: 0.0152. Time: 59.85\n",
      "2022-04-14 10:59:10,115 - INFO - train -   epoch:96, iter: 256. loss: 0.2492. loss_u: 0.2386. loss_x: 0.0106. Mask:0.8474 . LR: 0.0151. Time: 59.60\n",
      "2022-04-14 10:59:10,115 - INFO - train -   epoch:96, iter: 256. loss: 0.2492. loss_u: 0.2386. loss_x: 0.0106. Mask:0.8474 . LR: 0.0151. Time: 59.60\n",
      "2022-04-14 10:59:14,178 - INFO - train -   Epoch 96. Top1: 88.4508. Top5: 99.2369. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 10:59:14,178 - INFO - train -   Epoch 96. Top1: 88.4508. Top5: 99.2369. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 11:00:14,788 - INFO - train -   epoch:97, iter: 64. loss: 0.2580. loss_u: 0.2452. loss_x: 0.0128. Mask:0.8471 . LR: 0.0151. Time: 60.61\n",
      "2022-04-14 11:00:14,788 - INFO - train -   epoch:97, iter: 64. loss: 0.2580. loss_u: 0.2452. loss_x: 0.0128. Mask:0.8471 . LR: 0.0151. Time: 60.61\n",
      "2022-04-14 11:01:12,312 - INFO - train -   epoch:97, iter: 128. loss: 0.2536. loss_u: 0.2438. loss_x: 0.0098. Mask:0.8443 . LR: 0.0150. Time: 57.52\n",
      "2022-04-14 11:01:12,312 - INFO - train -   epoch:97, iter: 128. loss: 0.2536. loss_u: 0.2438. loss_x: 0.0098. Mask:0.8443 . LR: 0.0150. Time: 57.52\n",
      "2022-04-14 11:02:13,750 - INFO - train -   epoch:97, iter: 192. loss: 0.2512. loss_u: 0.2413. loss_x: 0.0099. Mask:0.8428 . LR: 0.0149. Time: 61.44\n",
      "2022-04-14 11:02:13,750 - INFO - train -   epoch:97, iter: 192. loss: 0.2512. loss_u: 0.2413. loss_x: 0.0099. Mask:0.8428 . LR: 0.0149. Time: 61.44\n",
      "2022-04-14 11:03:12,670 - INFO - train -   epoch:97, iter: 256. loss: 0.2502. loss_u: 0.2396. loss_x: 0.0106. Mask:0.8429 . LR: 0.0149. Time: 58.92\n",
      "2022-04-14 11:03:12,670 - INFO - train -   epoch:97, iter: 256. loss: 0.2502. loss_u: 0.2396. loss_x: 0.0106. Mask:0.8429 . LR: 0.0149. Time: 58.92\n",
      "2022-04-14 11:03:16,801 - INFO - train -   Epoch 97. Top1: 88.6204. Top5: 99.1824. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 11:03:16,801 - INFO - train -   Epoch 97. Top1: 88.6204. Top5: 99.1824. best_acc: 90.1647 in epoch 85\n",
      "2022-04-14 11:04:18,274 - INFO - train -   epoch:98, iter: 64. loss: 0.2523. loss_u: 0.2421. loss_x: 0.0102. Mask:0.8476 . LR: 0.0148. Time: 61.47\n",
      "2022-04-14 11:04:18,274 - INFO - train -   epoch:98, iter: 64. loss: 0.2523. loss_u: 0.2421. loss_x: 0.0102. Mask:0.8476 . LR: 0.0148. Time: 61.47\n",
      "2022-04-14 11:05:19,295 - INFO - train -   epoch:98, iter: 128. loss: 0.2502. loss_u: 0.2391. loss_x: 0.0110. Mask:0.8473 . LR: 0.0147. Time: 61.02\n",
      "2022-04-14 11:05:19,295 - INFO - train -   epoch:98, iter: 128. loss: 0.2502. loss_u: 0.2391. loss_x: 0.0110. Mask:0.8473 . LR: 0.0147. Time: 61.02\n",
      "2022-04-14 11:06:20,973 - INFO - train -   epoch:98, iter: 192. loss: 0.2490. loss_u: 0.2383. loss_x: 0.0107. Mask:0.8475 . LR: 0.0147. Time: 61.68\n",
      "2022-04-14 11:06:20,973 - INFO - train -   epoch:98, iter: 192. loss: 0.2490. loss_u: 0.2383. loss_x: 0.0107. Mask:0.8475 . LR: 0.0147. Time: 61.68\n",
      "2022-04-14 11:07:21,606 - INFO - train -   epoch:98, iter: 256. loss: 0.2479. loss_u: 0.2380. loss_x: 0.0099. Mask:0.8486 . LR: 0.0146. Time: 60.63\n",
      "2022-04-14 11:07:21,606 - INFO - train -   epoch:98, iter: 256. loss: 0.2479. loss_u: 0.2380. loss_x: 0.0099. Mask:0.8486 . LR: 0.0146. Time: 60.63\n",
      "2022-04-14 11:07:25,774 - INFO - train -   Epoch 98. Top1: 90.4191. Top5: 99.5276. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:07:25,774 - INFO - train -   Epoch 98. Top1: 90.4191. Top5: 99.5276. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:08:30,194 - INFO - train -   epoch:99, iter: 64. loss: 0.2522. loss_u: 0.2404. loss_x: 0.0118. Mask:0.8491 . LR: 0.0145. Time: 64.42\n",
      "2022-04-14 11:08:30,194 - INFO - train -   epoch:99, iter: 64. loss: 0.2522. loss_u: 0.2404. loss_x: 0.0118. Mask:0.8491 . LR: 0.0145. Time: 64.42\n",
      "2022-04-14 11:09:32,870 - INFO - train -   epoch:99, iter: 128. loss: 0.2532. loss_u: 0.2430. loss_x: 0.0102. Mask:0.8493 . LR: 0.0144. Time: 62.67\n",
      "2022-04-14 11:09:32,870 - INFO - train -   epoch:99, iter: 128. loss: 0.2532. loss_u: 0.2430. loss_x: 0.0102. Mask:0.8493 . LR: 0.0144. Time: 62.67\n",
      "2022-04-14 11:10:36,043 - INFO - train -   epoch:99, iter: 192. loss: 0.2503. loss_u: 0.2413. loss_x: 0.0089. Mask:0.8506 . LR: 0.0144. Time: 63.17\n",
      "2022-04-14 11:10:36,043 - INFO - train -   epoch:99, iter: 192. loss: 0.2503. loss_u: 0.2413. loss_x: 0.0089. Mask:0.8506 . LR: 0.0144. Time: 63.17\n",
      "2022-04-14 11:11:36,914 - INFO - train -   epoch:99, iter: 256. loss: 0.2503. loss_u: 0.2413. loss_x: 0.0090. Mask:0.8502 . LR: 0.0143. Time: 60.87\n",
      "2022-04-14 11:11:36,914 - INFO - train -   epoch:99, iter: 256. loss: 0.2503. loss_u: 0.2413. loss_x: 0.0090. Mask:0.8502 . LR: 0.0143. Time: 60.87\n",
      "2022-04-14 11:11:41,197 - INFO - train -   Epoch 99. Top1: 88.4872. Top5: 99.0734. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:11:41,197 - INFO - train -   Epoch 99. Top1: 88.4872. Top5: 99.0734. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:12:47,440 - INFO - train -   epoch:100, iter: 64. loss: 0.2480. loss_u: 0.2352. loss_x: 0.0128. Mask:0.8418 . LR: 0.0142. Time: 66.24\n",
      "2022-04-14 11:12:47,440 - INFO - train -   epoch:100, iter: 64. loss: 0.2480. loss_u: 0.2352. loss_x: 0.0128. Mask:0.8418 . LR: 0.0142. Time: 66.24\n",
      "2022-04-14 11:13:49,442 - INFO - train -   epoch:100, iter: 128. loss: 0.2478. loss_u: 0.2377. loss_x: 0.0101. Mask:0.8480 . LR: 0.0142. Time: 62.00\n",
      "2022-04-14 11:13:49,442 - INFO - train -   epoch:100, iter: 128. loss: 0.2478. loss_u: 0.2377. loss_x: 0.0101. Mask:0.8480 . LR: 0.0142. Time: 62.00\n",
      "2022-04-14 11:14:52,535 - INFO - train -   epoch:100, iter: 192. loss: 0.2480. loss_u: 0.2373. loss_x: 0.0107. Mask:0.8447 . LR: 0.0141. Time: 63.09\n",
      "2022-04-14 11:14:52,535 - INFO - train -   epoch:100, iter: 192. loss: 0.2480. loss_u: 0.2373. loss_x: 0.0107. Mask:0.8447 . LR: 0.0141. Time: 63.09\n",
      "2022-04-14 11:15:53,321 - INFO - train -   epoch:100, iter: 256. loss: 0.2477. loss_u: 0.2372. loss_x: 0.0105. Mask:0.8444 . LR: 0.0140. Time: 60.78\n",
      "2022-04-14 11:15:53,321 - INFO - train -   epoch:100, iter: 256. loss: 0.2477. loss_u: 0.2372. loss_x: 0.0105. Mask:0.8444 . LR: 0.0140. Time: 60.78\n",
      "2022-04-14 11:15:57,523 - INFO - train -   Epoch 100. Top1: 89.2321. Top5: 98.9220. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:15:57,523 - INFO - train -   Epoch 100. Top1: 89.2321. Top5: 98.9220. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:17:04,125 - INFO - train -   epoch:101, iter: 64. loss: 0.2447. loss_u: 0.2337. loss_x: 0.0110. Mask:0.8345 . LR: 0.0139. Time: 66.60\n",
      "2022-04-14 11:17:04,125 - INFO - train -   epoch:101, iter: 64. loss: 0.2447. loss_u: 0.2337. loss_x: 0.0110. Mask:0.8345 . LR: 0.0139. Time: 66.60\n",
      "2022-04-14 11:18:05,856 - INFO - train -   epoch:101, iter: 128. loss: 0.2446. loss_u: 0.2348. loss_x: 0.0098. Mask:0.8426 . LR: 0.0139. Time: 61.73\n",
      "2022-04-14 11:18:05,856 - INFO - train -   epoch:101, iter: 128. loss: 0.2446. loss_u: 0.2348. loss_x: 0.0098. Mask:0.8426 . LR: 0.0139. Time: 61.73\n",
      "2022-04-14 11:19:06,073 - INFO - train -   epoch:101, iter: 192. loss: 0.2447. loss_u: 0.2350. loss_x: 0.0097. Mask:0.8460 . LR: 0.0138. Time: 60.21\n",
      "2022-04-14 11:19:06,073 - INFO - train -   epoch:101, iter: 192. loss: 0.2447. loss_u: 0.2350. loss_x: 0.0097. Mask:0.8460 . LR: 0.0138. Time: 60.21\n",
      "2022-04-14 11:20:04,942 - INFO - train -   epoch:101, iter: 256. loss: 0.2467. loss_u: 0.2360. loss_x: 0.0107. Mask:0.8447 . LR: 0.0137. Time: 58.87\n",
      "2022-04-14 11:20:04,942 - INFO - train -   epoch:101, iter: 256. loss: 0.2467. loss_u: 0.2360. loss_x: 0.0107. Mask:0.8447 . LR: 0.0137. Time: 58.87\n",
      "2022-04-14 11:20:08,971 - INFO - train -   Epoch 101. Top1: 90.1344. Top5: 99.5276. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:20:08,971 - INFO - train -   Epoch 101. Top1: 90.1344. Top5: 99.5276. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:21:12,687 - INFO - train -   epoch:102, iter: 64. loss: 0.2419. loss_u: 0.2312. loss_x: 0.0107. Mask:0.8530 . LR: 0.0137. Time: 63.71\n",
      "2022-04-14 11:21:12,687 - INFO - train -   epoch:102, iter: 64. loss: 0.2419. loss_u: 0.2312. loss_x: 0.0107. Mask:0.8530 . LR: 0.0137. Time: 63.71\n",
      "2022-04-14 11:22:15,165 - INFO - train -   epoch:102, iter: 128. loss: 0.2469. loss_u: 0.2353. loss_x: 0.0116. Mask:0.8508 . LR: 0.0136. Time: 62.47\n",
      "2022-04-14 11:22:15,165 - INFO - train -   epoch:102, iter: 128. loss: 0.2469. loss_u: 0.2353. loss_x: 0.0116. Mask:0.8508 . LR: 0.0136. Time: 62.47\n",
      "2022-04-14 11:23:17,251 - INFO - train -   epoch:102, iter: 192. loss: 0.2480. loss_u: 0.2375. loss_x: 0.0105. Mask:0.8522 . LR: 0.0135. Time: 62.08\n",
      "2022-04-14 11:23:17,251 - INFO - train -   epoch:102, iter: 192. loss: 0.2480. loss_u: 0.2375. loss_x: 0.0105. Mask:0.8522 . LR: 0.0135. Time: 62.08\n",
      "2022-04-14 11:24:18,690 - INFO - train -   epoch:102, iter: 256. loss: 0.2487. loss_u: 0.2382. loss_x: 0.0105. Mask:0.8530 . LR: 0.0134. Time: 61.44\n",
      "2022-04-14 11:24:18,690 - INFO - train -   epoch:102, iter: 256. loss: 0.2487. loss_u: 0.2382. loss_x: 0.0105. Mask:0.8530 . LR: 0.0134. Time: 61.44\n",
      "2022-04-14 11:24:22,906 - INFO - train -   Epoch 102. Top1: 89.8559. Top5: 99.4368. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:24:22,906 - INFO - train -   Epoch 102. Top1: 89.8559. Top5: 99.4368. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:25:26,936 - INFO - train -   epoch:103, iter: 64. loss: 0.2473. loss_u: 0.2364. loss_x: 0.0109. Mask:0.8523 . LR: 0.0134. Time: 64.02\n",
      "2022-04-14 11:25:26,936 - INFO - train -   epoch:103, iter: 64. loss: 0.2473. loss_u: 0.2364. loss_x: 0.0109. Mask:0.8523 . LR: 0.0134. Time: 64.02\n",
      "2022-04-14 11:26:28,791 - INFO - train -   epoch:103, iter: 128. loss: 0.2480. loss_u: 0.2374. loss_x: 0.0106. Mask:0.8531 . LR: 0.0133. Time: 61.85\n",
      "2022-04-14 11:26:28,791 - INFO - train -   epoch:103, iter: 128. loss: 0.2480. loss_u: 0.2374. loss_x: 0.0106. Mask:0.8531 . LR: 0.0133. Time: 61.85\n",
      "2022-04-14 11:27:31,877 - INFO - train -   epoch:103, iter: 192. loss: 0.2469. loss_u: 0.2369. loss_x: 0.0099. Mask:0.8528 . LR: 0.0132. Time: 63.08\n",
      "2022-04-14 11:27:31,877 - INFO - train -   epoch:103, iter: 192. loss: 0.2469. loss_u: 0.2369. loss_x: 0.0099. Mask:0.8528 . LR: 0.0132. Time: 63.08\n",
      "2022-04-14 11:28:34,338 - INFO - train -   epoch:103, iter: 256. loss: 0.2463. loss_u: 0.2369. loss_x: 0.0094. Mask:0.8520 . LR: 0.0132. Time: 62.46\n",
      "2022-04-14 11:28:34,338 - INFO - train -   epoch:103, iter: 256. loss: 0.2463. loss_u: 0.2369. loss_x: 0.0094. Mask:0.8520 . LR: 0.0132. Time: 62.46\n",
      "2022-04-14 11:28:38,634 - INFO - train -   Epoch 103. Top1: 90.0012. Top5: 99.5276. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:28:38,634 - INFO - train -   Epoch 103. Top1: 90.0012. Top5: 99.5276. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:29:44,625 - INFO - train -   epoch:104, iter: 64. loss: 0.2357. loss_u: 0.2278. loss_x: 0.0080. Mask:0.8521 . LR: 0.0131. Time: 65.98\n",
      "2022-04-14 11:29:44,625 - INFO - train -   epoch:104, iter: 64. loss: 0.2357. loss_u: 0.2278. loss_x: 0.0080. Mask:0.8521 . LR: 0.0131. Time: 65.98\n",
      "2022-04-14 11:30:46,709 - INFO - train -   epoch:104, iter: 128. loss: 0.2424. loss_u: 0.2326. loss_x: 0.0098. Mask:0.8504 . LR: 0.0130. Time: 62.08\n",
      "2022-04-14 11:30:46,709 - INFO - train -   epoch:104, iter: 128. loss: 0.2424. loss_u: 0.2326. loss_x: 0.0098. Mask:0.8504 . LR: 0.0130. Time: 62.08\n",
      "2022-04-14 11:31:49,054 - INFO - train -   epoch:104, iter: 192. loss: 0.2426. loss_u: 0.2334. loss_x: 0.0092. Mask:0.8526 . LR: 0.0129. Time: 62.34\n",
      "2022-04-14 11:31:49,054 - INFO - train -   epoch:104, iter: 192. loss: 0.2426. loss_u: 0.2334. loss_x: 0.0092. Mask:0.8526 . LR: 0.0129. Time: 62.34\n",
      "2022-04-14 11:32:51,204 - INFO - train -   epoch:104, iter: 256. loss: 0.2445. loss_u: 0.2353. loss_x: 0.0092. Mask:0.8533 . LR: 0.0129. Time: 62.15\n",
      "2022-04-14 11:32:51,204 - INFO - train -   epoch:104, iter: 256. loss: 0.2445. loss_u: 0.2353. loss_x: 0.0092. Mask:0.8533 . LR: 0.0129. Time: 62.15\n",
      "2022-04-14 11:32:55,397 - INFO - train -   Epoch 104. Top1: 89.3774. Top5: 99.3278. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:32:55,397 - INFO - train -   Epoch 104. Top1: 89.3774. Top5: 99.3278. best_acc: 90.4191 in epoch 98\n",
      "2022-04-14 11:34:01,848 - INFO - train -   epoch:105, iter: 64. loss: 0.2365. loss_u: 0.2297. loss_x: 0.0068. Mask:0.8629 . LR: 0.0128. Time: 66.45\n",
      "2022-04-14 11:34:01,848 - INFO - train -   epoch:105, iter: 64. loss: 0.2365. loss_u: 0.2297. loss_x: 0.0068. Mask:0.8629 . LR: 0.0128. Time: 66.45\n",
      "2022-04-14 11:35:04,625 - INFO - train -   epoch:105, iter: 128. loss: 0.2364. loss_u: 0.2287. loss_x: 0.0077. Mask:0.8599 . LR: 0.0127. Time: 62.77\n",
      "2022-04-14 11:35:04,625 - INFO - train -   epoch:105, iter: 128. loss: 0.2364. loss_u: 0.2287. loss_x: 0.0077. Mask:0.8599 . LR: 0.0127. Time: 62.77\n",
      "2022-04-14 11:36:08,063 - INFO - train -   epoch:105, iter: 192. loss: 0.2388. loss_u: 0.2316. loss_x: 0.0072. Mask:0.8609 . LR: 0.0126. Time: 63.44\n",
      "2022-04-14 11:36:08,063 - INFO - train -   epoch:105, iter: 192. loss: 0.2388. loss_u: 0.2316. loss_x: 0.0072. Mask:0.8609 . LR: 0.0126. Time: 63.44\n",
      "2022-04-14 11:37:15,576 - INFO - train -   epoch:105, iter: 256. loss: 0.2410. loss_u: 0.2331. loss_x: 0.0078. Mask:0.8576 . LR: 0.0126. Time: 67.51\n",
      "2022-04-14 11:37:15,576 - INFO - train -   epoch:105, iter: 256. loss: 0.2410. loss_u: 0.2331. loss_x: 0.0078. Mask:0.8576 . LR: 0.0126. Time: 67.51\n",
      "2022-04-14 11:37:19,876 - INFO - train -   Epoch 105. Top1: 90.7461. Top5: 99.6366. best_acc: 90.7461 in epoch 105\n",
      "2022-04-14 11:37:19,876 - INFO - train -   Epoch 105. Top1: 90.7461. Top5: 99.6366. best_acc: 90.7461 in epoch 105\n",
      "2022-04-14 11:38:26,477 - INFO - train -   epoch:106, iter: 64. loss: 0.2378. loss_u: 0.2315. loss_x: 0.0063. Mask:0.8597 . LR: 0.0125. Time: 66.60\n",
      "2022-04-14 11:38:26,477 - INFO - train -   epoch:106, iter: 64. loss: 0.2378. loss_u: 0.2315. loss_x: 0.0063. Mask:0.8597 . LR: 0.0125. Time: 66.60\n",
      "2022-04-14 11:39:28,500 - INFO - train -   epoch:106, iter: 128. loss: 0.2417. loss_u: 0.2336. loss_x: 0.0080. Mask:0.8593 . LR: 0.0124. Time: 62.02\n",
      "2022-04-14 11:39:28,500 - INFO - train -   epoch:106, iter: 128. loss: 0.2417. loss_u: 0.2336. loss_x: 0.0080. Mask:0.8593 . LR: 0.0124. Time: 62.02\n",
      "2022-04-14 11:40:33,977 - INFO - train -   epoch:106, iter: 192. loss: 0.2426. loss_u: 0.2342. loss_x: 0.0084. Mask:0.8573 . LR: 0.0124. Time: 65.47\n",
      "2022-04-14 11:40:33,977 - INFO - train -   epoch:106, iter: 192. loss: 0.2426. loss_u: 0.2342. loss_x: 0.0084. Mask:0.8573 . LR: 0.0124. Time: 65.47\n",
      "2022-04-14 11:41:37,626 - INFO - train -   epoch:106, iter: 256. loss: 0.2432. loss_u: 0.2349. loss_x: 0.0083. Mask:0.8552 . LR: 0.0123. Time: 63.64\n",
      "2022-04-14 11:41:37,626 - INFO - train -   epoch:106, iter: 256. loss: 0.2432. loss_u: 0.2349. loss_x: 0.0083. Mask:0.8552 . LR: 0.0123. Time: 63.64\n",
      "2022-04-14 11:41:41,673 - INFO - train -   Epoch 106. Top1: 90.4675. Top5: 99.3459. best_acc: 90.7461 in epoch 105\n",
      "2022-04-14 11:41:41,673 - INFO - train -   Epoch 106. Top1: 90.4675. Top5: 99.3459. best_acc: 90.7461 in epoch 105\n",
      "2022-04-14 11:42:49,571 - INFO - train -   epoch:107, iter: 64. loss: 0.2487. loss_u: 0.2400. loss_x: 0.0088. Mask:0.8503 . LR: 0.0122. Time: 67.89\n",
      "2022-04-14 11:42:49,571 - INFO - train -   epoch:107, iter: 64. loss: 0.2487. loss_u: 0.2400. loss_x: 0.0088. Mask:0.8503 . LR: 0.0122. Time: 67.89\n",
      "2022-04-14 11:43:51,070 - INFO - train -   epoch:107, iter: 128. loss: 0.2447. loss_u: 0.2344. loss_x: 0.0103. Mask:0.8540 . LR: 0.0121. Time: 61.50\n",
      "2022-04-14 11:43:51,070 - INFO - train -   epoch:107, iter: 128. loss: 0.2447. loss_u: 0.2344. loss_x: 0.0103. Mask:0.8540 . LR: 0.0121. Time: 61.50\n",
      "2022-04-14 11:44:51,642 - INFO - train -   epoch:107, iter: 192. loss: 0.2449. loss_u: 0.2355. loss_x: 0.0094. Mask:0.8537 . LR: 0.0121. Time: 60.57\n",
      "2022-04-14 11:44:51,642 - INFO - train -   epoch:107, iter: 192. loss: 0.2449. loss_u: 0.2355. loss_x: 0.0094. Mask:0.8537 . LR: 0.0121. Time: 60.57\n",
      "2022-04-14 11:45:51,769 - INFO - train -   epoch:107, iter: 256. loss: 0.2430. loss_u: 0.2346. loss_x: 0.0084. Mask:0.8546 . LR: 0.0120. Time: 60.12\n",
      "2022-04-14 11:45:51,769 - INFO - train -   epoch:107, iter: 256. loss: 0.2430. loss_u: 0.2346. loss_x: 0.0084. Mask:0.8546 . LR: 0.0120. Time: 60.12\n",
      "2022-04-14 11:45:55,950 - INFO - train -   Epoch 107. Top1: 89.6923. Top5: 99.2914. best_acc: 90.7461 in epoch 105\n",
      "2022-04-14 11:45:55,950 - INFO - train -   Epoch 107. Top1: 89.6923. Top5: 99.2914. best_acc: 90.7461 in epoch 105\n",
      "2022-04-14 11:47:02,231 - INFO - train -   epoch:108, iter: 64. loss: 0.2398. loss_u: 0.2343. loss_x: 0.0054. Mask:0.8593 . LR: 0.0119. Time: 66.28\n",
      "2022-04-14 11:47:02,231 - INFO - train -   epoch:108, iter: 64. loss: 0.2398. loss_u: 0.2343. loss_x: 0.0054. Mask:0.8593 . LR: 0.0119. Time: 66.28\n",
      "2022-04-14 11:48:04,526 - INFO - train -   epoch:108, iter: 128. loss: 0.2417. loss_u: 0.2354. loss_x: 0.0063. Mask:0.8568 . LR: 0.0118. Time: 62.29\n",
      "2022-04-14 11:48:04,526 - INFO - train -   epoch:108, iter: 128. loss: 0.2417. loss_u: 0.2354. loss_x: 0.0063. Mask:0.8568 . LR: 0.0118. Time: 62.29\n",
      "2022-04-14 11:49:07,111 - INFO - train -   epoch:108, iter: 192. loss: 0.2414. loss_u: 0.2337. loss_x: 0.0077. Mask:0.8546 . LR: 0.0118. Time: 62.58\n",
      "2022-04-14 11:49:07,111 - INFO - train -   epoch:108, iter: 192. loss: 0.2414. loss_u: 0.2337. loss_x: 0.0077. Mask:0.8546 . LR: 0.0118. Time: 62.58\n",
      "2022-04-14 11:50:08,653 - INFO - train -   epoch:108, iter: 256. loss: 0.2390. loss_u: 0.2310. loss_x: 0.0080. Mask:0.8534 . LR: 0.0117. Time: 61.54\n",
      "2022-04-14 11:50:08,653 - INFO - train -   epoch:108, iter: 256. loss: 0.2390. loss_u: 0.2310. loss_x: 0.0080. Mask:0.8534 . LR: 0.0117. Time: 61.54\n",
      "2022-04-14 11:50:12,670 - INFO - train -   Epoch 108. Top1: 91.8362. Top5: 99.3278. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 11:50:12,670 - INFO - train -   Epoch 108. Top1: 91.8362. Top5: 99.3278. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 11:51:18,176 - INFO - train -   epoch:109, iter: 64. loss: 0.2384. loss_u: 0.2318. loss_x: 0.0066. Mask:0.8621 . LR: 0.0116. Time: 65.50\n",
      "2022-04-14 11:51:18,176 - INFO - train -   epoch:109, iter: 64. loss: 0.2384. loss_u: 0.2318. loss_x: 0.0066. Mask:0.8621 . LR: 0.0116. Time: 65.50\n",
      "2022-04-14 11:52:19,237 - INFO - train -   epoch:109, iter: 128. loss: 0.2391. loss_u: 0.2331. loss_x: 0.0060. Mask:0.8640 . LR: 0.0115. Time: 61.06\n",
      "2022-04-14 11:52:19,237 - INFO - train -   epoch:109, iter: 128. loss: 0.2391. loss_u: 0.2331. loss_x: 0.0060. Mask:0.8640 . LR: 0.0115. Time: 61.06\n",
      "2022-04-14 11:53:21,601 - INFO - train -   epoch:109, iter: 192. loss: 0.2400. loss_u: 0.2330. loss_x: 0.0070. Mask:0.8632 . LR: 0.0115. Time: 62.36\n",
      "2022-04-14 11:53:21,601 - INFO - train -   epoch:109, iter: 192. loss: 0.2400. loss_u: 0.2330. loss_x: 0.0070. Mask:0.8632 . LR: 0.0115. Time: 62.36\n",
      "2022-04-14 11:54:23,823 - INFO - train -   epoch:109, iter: 256. loss: 0.2394. loss_u: 0.2318. loss_x: 0.0076. Mask:0.8620 . LR: 0.0114. Time: 62.22\n",
      "2022-04-14 11:54:23,823 - INFO - train -   epoch:109, iter: 256. loss: 0.2394. loss_u: 0.2318. loss_x: 0.0076. Mask:0.8620 . LR: 0.0114. Time: 62.22\n",
      "2022-04-14 11:54:27,907 - INFO - train -   Epoch 109. Top1: 91.5879. Top5: 99.6366. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 11:54:27,907 - INFO - train -   Epoch 109. Top1: 91.5879. Top5: 99.6366. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 11:55:33,058 - INFO - train -   epoch:110, iter: 64. loss: 0.2430. loss_u: 0.2349. loss_x: 0.0082. Mask:0.8593 . LR: 0.0113. Time: 65.15\n",
      "2022-04-14 11:55:33,058 - INFO - train -   epoch:110, iter: 64. loss: 0.2430. loss_u: 0.2349. loss_x: 0.0082. Mask:0.8593 . LR: 0.0113. Time: 65.15\n",
      "2022-04-14 11:56:32,995 - INFO - train -   epoch:110, iter: 128. loss: 0.2504. loss_u: 0.2401. loss_x: 0.0103. Mask:0.8570 . LR: 0.0112. Time: 59.93\n",
      "2022-04-14 11:56:32,995 - INFO - train -   epoch:110, iter: 128. loss: 0.2504. loss_u: 0.2401. loss_x: 0.0103. Mask:0.8570 . LR: 0.0112. Time: 59.93\n",
      "2022-04-14 11:57:34,696 - INFO - train -   epoch:110, iter: 192. loss: 0.2464. loss_u: 0.2370. loss_x: 0.0094. Mask:0.8563 . LR: 0.0112. Time: 61.70\n",
      "2022-04-14 11:57:34,696 - INFO - train -   epoch:110, iter: 192. loss: 0.2464. loss_u: 0.2370. loss_x: 0.0094. Mask:0.8563 . LR: 0.0112. Time: 61.70\n",
      "2022-04-14 11:58:34,749 - INFO - train -   epoch:110, iter: 256. loss: 0.2450. loss_u: 0.2357. loss_x: 0.0092. Mask:0.8577 . LR: 0.0111. Time: 60.05\n",
      "2022-04-14 11:58:34,749 - INFO - train -   epoch:110, iter: 256. loss: 0.2450. loss_u: 0.2357. loss_x: 0.0092. Mask:0.8577 . LR: 0.0111. Time: 60.05\n",
      "2022-04-14 11:58:38,824 - INFO - train -   Epoch 110. Top1: 91.2003. Top5: 99.4913. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 11:58:38,824 - INFO - train -   Epoch 110. Top1: 91.2003. Top5: 99.4913. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 11:59:45,327 - INFO - train -   epoch:111, iter: 64. loss: 0.2324. loss_u: 0.2268. loss_x: 0.0057. Mask:0.8634 . LR: 0.0110. Time: 66.50\n",
      "2022-04-14 11:59:45,327 - INFO - train -   epoch:111, iter: 64. loss: 0.2324. loss_u: 0.2268. loss_x: 0.0057. Mask:0.8634 . LR: 0.0110. Time: 66.50\n",
      "2022-04-14 12:00:45,374 - INFO - train -   epoch:111, iter: 128. loss: 0.2359. loss_u: 0.2291. loss_x: 0.0067. Mask:0.8640 . LR: 0.0109. Time: 60.04\n",
      "2022-04-14 12:00:45,374 - INFO - train -   epoch:111, iter: 128. loss: 0.2359. loss_u: 0.2291. loss_x: 0.0067. Mask:0.8640 . LR: 0.0109. Time: 60.04\n",
      "2022-04-14 12:01:47,384 - INFO - train -   epoch:111, iter: 192. loss: 0.2391. loss_u: 0.2317. loss_x: 0.0074. Mask:0.8623 . LR: 0.0109. Time: 62.01\n",
      "2022-04-14 12:01:47,384 - INFO - train -   epoch:111, iter: 192. loss: 0.2391. loss_u: 0.2317. loss_x: 0.0074. Mask:0.8623 . LR: 0.0109. Time: 62.01\n",
      "2022-04-14 12:02:48,035 - INFO - train -   epoch:111, iter: 256. loss: 0.2394. loss_u: 0.2320. loss_x: 0.0074. Mask:0.8609 . LR: 0.0108. Time: 60.65\n",
      "2022-04-14 12:02:48,035 - INFO - train -   epoch:111, iter: 256. loss: 0.2394. loss_u: 0.2320. loss_x: 0.0074. Mask:0.8609 . LR: 0.0108. Time: 60.65\n",
      "2022-04-14 12:02:52,304 - INFO - train -   Epoch 111. Top1: 90.3161. Top5: 99.3641. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:02:52,304 - INFO - train -   Epoch 111. Top1: 90.3161. Top5: 99.3641. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:03:57,299 - INFO - train -   epoch:112, iter: 64. loss: 0.2426. loss_u: 0.2359. loss_x: 0.0067. Mask:0.8579 . LR: 0.0107. Time: 64.99\n",
      "2022-04-14 12:03:57,299 - INFO - train -   epoch:112, iter: 64. loss: 0.2426. loss_u: 0.2359. loss_x: 0.0067. Mask:0.8579 . LR: 0.0107. Time: 64.99\n",
      "2022-04-14 12:04:58,012 - INFO - train -   epoch:112, iter: 128. loss: 0.2404. loss_u: 0.2328. loss_x: 0.0076. Mask:0.8597 . LR: 0.0106. Time: 60.71\n",
      "2022-04-14 12:04:58,012 - INFO - train -   epoch:112, iter: 128. loss: 0.2404. loss_u: 0.2328. loss_x: 0.0076. Mask:0.8597 . LR: 0.0106. Time: 60.71\n",
      "2022-04-14 12:05:56,449 - INFO - train -   epoch:112, iter: 192. loss: 0.2391. loss_u: 0.2329. loss_x: 0.0063. Mask:0.8609 . LR: 0.0106. Time: 58.43\n",
      "2022-04-14 12:05:56,449 - INFO - train -   epoch:112, iter: 192. loss: 0.2391. loss_u: 0.2329. loss_x: 0.0063. Mask:0.8609 . LR: 0.0106. Time: 58.43\n",
      "2022-04-14 12:06:55,078 - INFO - train -   epoch:112, iter: 256. loss: 0.2415. loss_u: 0.2337. loss_x: 0.0077. Mask:0.8602 . LR: 0.0105. Time: 58.63\n",
      "2022-04-14 12:06:55,078 - INFO - train -   epoch:112, iter: 256. loss: 0.2415. loss_u: 0.2337. loss_x: 0.0077. Mask:0.8602 . LR: 0.0105. Time: 58.63\n",
      "2022-04-14 12:06:59,130 - INFO - train -   Epoch 112. Top1: 90.0799. Top5: 99.5821. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:06:59,130 - INFO - train -   Epoch 112. Top1: 90.0799. Top5: 99.5821. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:08:01,911 - INFO - train -   epoch:113, iter: 64. loss: 0.2429. loss_u: 0.2374. loss_x: 0.0054. Mask:0.8711 . LR: 0.0104. Time: 62.78\n",
      "2022-04-14 12:08:01,911 - INFO - train -   epoch:113, iter: 64. loss: 0.2429. loss_u: 0.2374. loss_x: 0.0054. Mask:0.8711 . LR: 0.0104. Time: 62.78\n",
      "2022-04-14 12:09:03,422 - INFO - train -   epoch:113, iter: 128. loss: 0.2396. loss_u: 0.2320. loss_x: 0.0076. Mask:0.8651 . LR: 0.0103. Time: 61.51\n",
      "2022-04-14 12:09:03,422 - INFO - train -   epoch:113, iter: 128. loss: 0.2396. loss_u: 0.2320. loss_x: 0.0076. Mask:0.8651 . LR: 0.0103. Time: 61.51\n",
      "2022-04-14 12:10:05,453 - INFO - train -   epoch:113, iter: 192. loss: 0.2375. loss_u: 0.2300. loss_x: 0.0075. Mask:0.8643 . LR: 0.0103. Time: 62.03\n",
      "2022-04-14 12:10:05,453 - INFO - train -   epoch:113, iter: 192. loss: 0.2375. loss_u: 0.2300. loss_x: 0.0075. Mask:0.8643 . LR: 0.0103. Time: 62.03\n",
      "2022-04-14 12:11:05,561 - INFO - train -   epoch:113, iter: 256. loss: 0.2360. loss_u: 0.2287. loss_x: 0.0073. Mask:0.8638 . LR: 0.0102. Time: 60.11\n",
      "2022-04-14 12:11:05,561 - INFO - train -   epoch:113, iter: 256. loss: 0.2360. loss_u: 0.2287. loss_x: 0.0073. Mask:0.8638 . LR: 0.0102. Time: 60.11\n",
      "2022-04-14 12:11:09,778 - INFO - train -   Epoch 113. Top1: 90.9399. Top5: 99.5094. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:11:09,778 - INFO - train -   Epoch 113. Top1: 90.9399. Top5: 99.5094. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:12:12,079 - INFO - train -   epoch:114, iter: 64. loss: 0.2324. loss_u: 0.2252. loss_x: 0.0072. Mask:0.8594 . LR: 0.0101. Time: 62.30\n",
      "2022-04-14 12:12:12,079 - INFO - train -   epoch:114, iter: 64. loss: 0.2324. loss_u: 0.2252. loss_x: 0.0072. Mask:0.8594 . LR: 0.0101. Time: 62.30\n",
      "2022-04-14 12:13:10,921 - INFO - train -   epoch:114, iter: 128. loss: 0.2336. loss_u: 0.2278. loss_x: 0.0059. Mask:0.8621 . LR: 0.0100. Time: 58.84\n",
      "2022-04-14 12:13:10,921 - INFO - train -   epoch:114, iter: 128. loss: 0.2336. loss_u: 0.2278. loss_x: 0.0059. Mask:0.8621 . LR: 0.0100. Time: 58.84\n",
      "2022-04-14 12:14:13,868 - INFO - train -   epoch:114, iter: 192. loss: 0.2356. loss_u: 0.2295. loss_x: 0.0061. Mask:0.8631 . LR: 0.0100. Time: 62.94\n",
      "2022-04-14 12:14:13,868 - INFO - train -   epoch:114, iter: 192. loss: 0.2356. loss_u: 0.2295. loss_x: 0.0061. Mask:0.8631 . LR: 0.0100. Time: 62.94\n",
      "2022-04-14 12:15:16,596 - INFO - train -   epoch:114, iter: 256. loss: 0.2346. loss_u: 0.2288. loss_x: 0.0058. Mask:0.8643 . LR: 0.0099. Time: 62.73\n",
      "2022-04-14 12:15:16,596 - INFO - train -   epoch:114, iter: 256. loss: 0.2346. loss_u: 0.2288. loss_x: 0.0058. Mask:0.8643 . LR: 0.0099. Time: 62.73\n",
      "2022-04-14 12:15:20,578 - INFO - train -   Epoch 114. Top1: 90.8733. Top5: 99.5640. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:15:20,578 - INFO - train -   Epoch 114. Top1: 90.8733. Top5: 99.5640. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:16:27,034 - INFO - train -   epoch:115, iter: 64. loss: 0.2249. loss_u: 0.2211. loss_x: 0.0038. Mask:0.8725 . LR: 0.0098. Time: 66.45\n",
      "2022-04-14 12:16:27,034 - INFO - train -   epoch:115, iter: 64. loss: 0.2249. loss_u: 0.2211. loss_x: 0.0038. Mask:0.8725 . LR: 0.0098. Time: 66.45\n",
      "2022-04-14 12:17:30,231 - INFO - train -   epoch:115, iter: 128. loss: 0.2327. loss_u: 0.2268. loss_x: 0.0059. Mask:0.8701 . LR: 0.0097. Time: 63.19\n",
      "2022-04-14 12:17:30,231 - INFO - train -   epoch:115, iter: 128. loss: 0.2327. loss_u: 0.2268. loss_x: 0.0059. Mask:0.8701 . LR: 0.0097. Time: 63.19\n",
      "2022-04-14 12:18:34,352 - INFO - train -   epoch:115, iter: 192. loss: 0.2344. loss_u: 0.2283. loss_x: 0.0061. Mask:0.8689 . LR: 0.0097. Time: 64.12\n",
      "2022-04-14 12:18:34,352 - INFO - train -   epoch:115, iter: 192. loss: 0.2344. loss_u: 0.2283. loss_x: 0.0061. Mask:0.8689 . LR: 0.0097. Time: 64.12\n",
      "2022-04-14 12:19:36,209 - INFO - train -   epoch:115, iter: 256. loss: 0.2326. loss_u: 0.2263. loss_x: 0.0063. Mask:0.8687 . LR: 0.0096. Time: 61.85\n",
      "2022-04-14 12:19:36,209 - INFO - train -   epoch:115, iter: 256. loss: 0.2326. loss_u: 0.2263. loss_x: 0.0063. Mask:0.8687 . LR: 0.0096. Time: 61.85\n",
      "2022-04-14 12:19:40,214 - INFO - train -   Epoch 115. Top1: 90.7825. Top5: 99.3641. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:19:40,214 - INFO - train -   Epoch 115. Top1: 90.7825. Top5: 99.3641. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:20:44,828 - INFO - train -   epoch:116, iter: 64. loss: 0.2334. loss_u: 0.2275. loss_x: 0.0059. Mask:0.8716 . LR: 0.0095. Time: 64.61\n",
      "2022-04-14 12:20:44,828 - INFO - train -   epoch:116, iter: 64. loss: 0.2334. loss_u: 0.2275. loss_x: 0.0059. Mask:0.8716 . LR: 0.0095. Time: 64.61\n",
      "2022-04-14 12:21:43,772 - INFO - train -   epoch:116, iter: 128. loss: 0.2351. loss_u: 0.2293. loss_x: 0.0058. Mask:0.8737 . LR: 0.0094. Time: 58.94\n",
      "2022-04-14 12:21:43,772 - INFO - train -   epoch:116, iter: 128. loss: 0.2351. loss_u: 0.2293. loss_x: 0.0058. Mask:0.8737 . LR: 0.0094. Time: 58.94\n",
      "2022-04-14 12:22:41,925 - INFO - train -   epoch:116, iter: 192. loss: 0.2365. loss_u: 0.2307. loss_x: 0.0058. Mask:0.8726 . LR: 0.0094. Time: 58.15\n",
      "2022-04-14 12:22:41,925 - INFO - train -   epoch:116, iter: 192. loss: 0.2365. loss_u: 0.2307. loss_x: 0.0058. Mask:0.8726 . LR: 0.0094. Time: 58.15\n",
      "2022-04-14 12:23:42,299 - INFO - train -   epoch:116, iter: 256. loss: 0.2357. loss_u: 0.2299. loss_x: 0.0058. Mask:0.8712 . LR: 0.0093. Time: 60.37\n",
      "2022-04-14 12:23:42,299 - INFO - train -   epoch:116, iter: 256. loss: 0.2357. loss_u: 0.2299. loss_x: 0.0058. Mask:0.8712 . LR: 0.0093. Time: 60.37\n",
      "2022-04-14 12:23:46,376 - INFO - train -   Epoch 116. Top1: 91.2427. Top5: 99.5094. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:23:46,376 - INFO - train -   Epoch 116. Top1: 91.2427. Top5: 99.5094. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:24:46,490 - INFO - train -   epoch:117, iter: 64. loss: 0.2448. loss_u: 0.2365. loss_x: 0.0083. Mask:0.8699 . LR: 0.0092. Time: 60.11\n",
      "2022-04-14 12:24:46,490 - INFO - train -   epoch:117, iter: 64. loss: 0.2448. loss_u: 0.2365. loss_x: 0.0083. Mask:0.8699 . LR: 0.0092. Time: 60.11\n",
      "2022-04-14 12:25:45,599 - INFO - train -   epoch:117, iter: 128. loss: 0.2400. loss_u: 0.2335. loss_x: 0.0065. Mask:0.8702 . LR: 0.0091. Time: 59.11\n",
      "2022-04-14 12:25:45,599 - INFO - train -   epoch:117, iter: 128. loss: 0.2400. loss_u: 0.2335. loss_x: 0.0065. Mask:0.8702 . LR: 0.0091. Time: 59.11\n",
      "2022-04-14 12:26:44,631 - INFO - train -   epoch:117, iter: 192. loss: 0.2406. loss_u: 0.2317. loss_x: 0.0089. Mask:0.8677 . LR: 0.0090. Time: 59.03\n",
      "2022-04-14 12:26:44,631 - INFO - train -   epoch:117, iter: 192. loss: 0.2406. loss_u: 0.2317. loss_x: 0.0089. Mask:0.8677 . LR: 0.0090. Time: 59.03\n",
      "2022-04-14 12:27:42,157 - INFO - train -   epoch:117, iter: 256. loss: 0.2379. loss_u: 0.2287. loss_x: 0.0092. Mask:0.8662 . LR: 0.0090. Time: 57.52\n",
      "2022-04-14 12:27:42,157 - INFO - train -   epoch:117, iter: 256. loss: 0.2379. loss_u: 0.2287. loss_x: 0.0092. Mask:0.8662 . LR: 0.0090. Time: 57.52\n",
      "2022-04-14 12:27:46,238 - INFO - train -   Epoch 117. Top1: 91.3154. Top5: 99.6911. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:27:46,238 - INFO - train -   Epoch 117. Top1: 91.3154. Top5: 99.6911. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:28:52,378 - INFO - train -   epoch:118, iter: 64. loss: 0.2375. loss_u: 0.2291. loss_x: 0.0084. Mask:0.8635 . LR: 0.0089. Time: 66.13\n",
      "2022-04-14 12:28:52,378 - INFO - train -   epoch:118, iter: 64. loss: 0.2375. loss_u: 0.2291. loss_x: 0.0084. Mask:0.8635 . LR: 0.0089. Time: 66.13\n",
      "2022-04-14 12:29:57,961 - INFO - train -   epoch:118, iter: 128. loss: 0.2365. loss_u: 0.2283. loss_x: 0.0082. Mask:0.8653 . LR: 0.0088. Time: 65.58\n",
      "2022-04-14 12:29:57,961 - INFO - train -   epoch:118, iter: 128. loss: 0.2365. loss_u: 0.2283. loss_x: 0.0082. Mask:0.8653 . LR: 0.0088. Time: 65.58\n",
      "2022-04-14 12:30:59,859 - INFO - train -   epoch:118, iter: 192. loss: 0.2325. loss_u: 0.2253. loss_x: 0.0072. Mask:0.8678 . LR: 0.0087. Time: 61.90\n",
      "2022-04-14 12:30:59,859 - INFO - train -   epoch:118, iter: 192. loss: 0.2325. loss_u: 0.2253. loss_x: 0.0072. Mask:0.8678 . LR: 0.0087. Time: 61.90\n",
      "2022-04-14 12:32:01,504 - INFO - train -   epoch:118, iter: 256. loss: 0.2315. loss_u: 0.2244. loss_x: 0.0071. Mask:0.8699 . LR: 0.0087. Time: 61.64\n",
      "2022-04-14 12:32:01,504 - INFO - train -   epoch:118, iter: 256. loss: 0.2315. loss_u: 0.2244. loss_x: 0.0071. Mask:0.8699 . LR: 0.0087. Time: 61.64\n",
      "2022-04-14 12:32:05,565 - INFO - train -   Epoch 118. Top1: 91.4729. Top5: 99.4186. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:32:05,565 - INFO - train -   Epoch 118. Top1: 91.4729. Top5: 99.4186. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:33:07,944 - INFO - train -   epoch:119, iter: 64. loss: 0.2364. loss_u: 0.2292. loss_x: 0.0072. Mask:0.8693 . LR: 0.0086. Time: 62.37\n",
      "2022-04-14 12:33:07,944 - INFO - train -   epoch:119, iter: 64. loss: 0.2364. loss_u: 0.2292. loss_x: 0.0072. Mask:0.8693 . LR: 0.0086. Time: 62.37\n",
      "2022-04-14 12:34:09,629 - INFO - train -   epoch:119, iter: 128. loss: 0.2346. loss_u: 0.2286. loss_x: 0.0060. Mask:0.8715 . LR: 0.0085. Time: 61.68\n",
      "2022-04-14 12:34:09,629 - INFO - train -   epoch:119, iter: 128. loss: 0.2346. loss_u: 0.2286. loss_x: 0.0060. Mask:0.8715 . LR: 0.0085. Time: 61.68\n",
      "2022-04-14 12:35:09,509 - INFO - train -   epoch:119, iter: 192. loss: 0.2361. loss_u: 0.2301. loss_x: 0.0060. Mask:0.8719 . LR: 0.0084. Time: 59.88\n",
      "2022-04-14 12:35:09,509 - INFO - train -   epoch:119, iter: 192. loss: 0.2361. loss_u: 0.2301. loss_x: 0.0060. Mask:0.8719 . LR: 0.0084. Time: 59.88\n",
      "2022-04-14 12:36:09,714 - INFO - train -   epoch:119, iter: 256. loss: 0.2359. loss_u: 0.2301. loss_x: 0.0058. Mask:0.8728 . LR: 0.0084. Time: 60.20\n",
      "2022-04-14 12:36:09,714 - INFO - train -   epoch:119, iter: 256. loss: 0.2359. loss_u: 0.2301. loss_x: 0.0058. Mask:0.8728 . LR: 0.0084. Time: 60.20\n",
      "2022-04-14 12:36:13,615 - INFO - train -   Epoch 119. Top1: 91.2185. Top5: 99.5276. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:36:13,615 - INFO - train -   Epoch 119. Top1: 91.2185. Top5: 99.5276. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:37:16,824 - INFO - train -   epoch:120, iter: 64. loss: 0.2341. loss_u: 0.2281. loss_x: 0.0060. Mask:0.8748 . LR: 0.0083. Time: 63.20\n",
      "2022-04-14 12:37:16,824 - INFO - train -   epoch:120, iter: 64. loss: 0.2341. loss_u: 0.2281. loss_x: 0.0060. Mask:0.8748 . LR: 0.0083. Time: 63.20\n",
      "2022-04-14 12:38:17,882 - INFO - train -   epoch:120, iter: 128. loss: 0.2343. loss_u: 0.2282. loss_x: 0.0061. Mask:0.8728 . LR: 0.0082. Time: 61.05\n",
      "2022-04-14 12:38:17,882 - INFO - train -   epoch:120, iter: 128. loss: 0.2343. loss_u: 0.2282. loss_x: 0.0061. Mask:0.8728 . LR: 0.0082. Time: 61.05\n",
      "2022-04-14 12:39:17,191 - INFO - train -   epoch:120, iter: 192. loss: 0.2356. loss_u: 0.2299. loss_x: 0.0057. Mask:0.8730 . LR: 0.0081. Time: 59.31\n",
      "2022-04-14 12:39:17,191 - INFO - train -   epoch:120, iter: 192. loss: 0.2356. loss_u: 0.2299. loss_x: 0.0057. Mask:0.8730 . LR: 0.0081. Time: 59.31\n",
      "2022-04-14 12:40:18,019 - INFO - train -   epoch:120, iter: 256. loss: 0.2337. loss_u: 0.2284. loss_x: 0.0053. Mask:0.8746 . LR: 0.0080. Time: 60.83\n",
      "2022-04-14 12:40:18,019 - INFO - train -   epoch:120, iter: 256. loss: 0.2337. loss_u: 0.2284. loss_x: 0.0053. Mask:0.8746 . LR: 0.0080. Time: 60.83\n",
      "2022-04-14 12:40:22,081 - INFO - train -   Epoch 120. Top1: 89.9952. Top5: 99.4549. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:40:22,081 - INFO - train -   Epoch 120. Top1: 89.9952. Top5: 99.4549. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:41:22,542 - INFO - train -   epoch:121, iter: 64. loss: 0.2288. loss_u: 0.2243. loss_x: 0.0044. Mask:0.8751 . LR: 0.0080. Time: 60.46\n",
      "2022-04-14 12:41:22,542 - INFO - train -   epoch:121, iter: 64. loss: 0.2288. loss_u: 0.2243. loss_x: 0.0044. Mask:0.8751 . LR: 0.0080. Time: 60.46\n",
      "2022-04-14 12:42:22,039 - INFO - train -   epoch:121, iter: 128. loss: 0.2288. loss_u: 0.2244. loss_x: 0.0044. Mask:0.8754 . LR: 0.0079. Time: 59.49\n",
      "2022-04-14 12:42:22,039 - INFO - train -   epoch:121, iter: 128. loss: 0.2288. loss_u: 0.2244. loss_x: 0.0044. Mask:0.8754 . LR: 0.0079. Time: 59.49\n",
      "2022-04-14 12:43:21,387 - INFO - train -   epoch:121, iter: 192. loss: 0.2341. loss_u: 0.2284. loss_x: 0.0057. Mask:0.8738 . LR: 0.0078. Time: 59.34\n",
      "2022-04-14 12:43:21,387 - INFO - train -   epoch:121, iter: 192. loss: 0.2341. loss_u: 0.2284. loss_x: 0.0057. Mask:0.8738 . LR: 0.0078. Time: 59.34\n",
      "2022-04-14 12:44:20,128 - INFO - train -   epoch:121, iter: 256. loss: 0.2336. loss_u: 0.2283. loss_x: 0.0053. Mask:0.8732 . LR: 0.0077. Time: 58.74\n",
      "2022-04-14 12:44:20,128 - INFO - train -   epoch:121, iter: 256. loss: 0.2336. loss_u: 0.2283. loss_x: 0.0053. Mask:0.8732 . LR: 0.0077. Time: 58.74\n",
      "2022-04-14 12:44:24,195 - INFO - train -   Epoch 121. Top1: 90.3888. Top5: 99.6003. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:44:24,195 - INFO - train -   Epoch 121. Top1: 90.3888. Top5: 99.6003. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:45:28,283 - INFO - train -   epoch:122, iter: 64. loss: 0.2332. loss_u: 0.2299. loss_x: 0.0034. Mask:0.8701 . LR: 0.0077. Time: 64.08\n",
      "2022-04-14 12:45:28,283 - INFO - train -   epoch:122, iter: 64. loss: 0.2332. loss_u: 0.2299. loss_x: 0.0034. Mask:0.8701 . LR: 0.0077. Time: 64.08\n",
      "2022-04-14 12:46:29,915 - INFO - train -   epoch:122, iter: 128. loss: 0.2334. loss_u: 0.2288. loss_x: 0.0046. Mask:0.8729 . LR: 0.0076. Time: 61.63\n",
      "2022-04-14 12:46:29,915 - INFO - train -   epoch:122, iter: 128. loss: 0.2334. loss_u: 0.2288. loss_x: 0.0046. Mask:0.8729 . LR: 0.0076. Time: 61.63\n",
      "2022-04-14 12:47:29,830 - INFO - train -   epoch:122, iter: 192. loss: 0.2340. loss_u: 0.2283. loss_x: 0.0057. Mask:0.8728 . LR: 0.0075. Time: 59.91\n",
      "2022-04-14 12:47:29,830 - INFO - train -   epoch:122, iter: 192. loss: 0.2340. loss_u: 0.2283. loss_x: 0.0057. Mask:0.8728 . LR: 0.0075. Time: 59.91\n",
      "2022-04-14 12:48:29,520 - INFO - train -   epoch:122, iter: 256. loss: 0.2326. loss_u: 0.2269. loss_x: 0.0057. Mask:0.8722 . LR: 0.0074. Time: 59.69\n",
      "2022-04-14 12:48:29,520 - INFO - train -   epoch:122, iter: 256. loss: 0.2326. loss_u: 0.2269. loss_x: 0.0057. Mask:0.8722 . LR: 0.0074. Time: 59.69\n",
      "2022-04-14 12:48:33,580 - INFO - train -   Epoch 122. Top1: 91.2427. Top5: 99.5821. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:48:33,580 - INFO - train -   Epoch 122. Top1: 91.2427. Top5: 99.5821. best_acc: 91.8362 in epoch 108\n",
      "2022-04-14 12:49:35,071 - INFO - train -   epoch:123, iter: 64. loss: 0.2308. loss_u: 0.2233. loss_x: 0.0075. Mask:0.8787 . LR: 0.0073. Time: 61.49\n",
      "2022-04-14 12:49:35,071 - INFO - train -   epoch:123, iter: 64. loss: 0.2308. loss_u: 0.2233. loss_x: 0.0075. Mask:0.8787 . LR: 0.0073. Time: 61.49\n",
      "2022-04-14 12:50:34,323 - INFO - train -   epoch:123, iter: 128. loss: 0.2306. loss_u: 0.2235. loss_x: 0.0071. Mask:0.8763 . LR: 0.0073. Time: 59.25\n",
      "2022-04-14 12:50:34,323 - INFO - train -   epoch:123, iter: 128. loss: 0.2306. loss_u: 0.2235. loss_x: 0.0071. Mask:0.8763 . LR: 0.0073. Time: 59.25\n",
      "2022-04-14 12:51:34,011 - INFO - train -   epoch:123, iter: 192. loss: 0.2321. loss_u: 0.2250. loss_x: 0.0070. Mask:0.8747 . LR: 0.0072. Time: 59.69\n",
      "2022-04-14 12:51:34,011 - INFO - train -   epoch:123, iter: 192. loss: 0.2321. loss_u: 0.2250. loss_x: 0.0070. Mask:0.8747 . LR: 0.0072. Time: 59.69\n",
      "2022-04-14 12:52:33,425 - INFO - train -   epoch:123, iter: 256. loss: 0.2324. loss_u: 0.2255. loss_x: 0.0069. Mask:0.8747 . LR: 0.0071. Time: 59.41\n",
      "2022-04-14 12:52:33,425 - INFO - train -   epoch:123, iter: 256. loss: 0.2324. loss_u: 0.2255. loss_x: 0.0069. Mask:0.8747 . LR: 0.0071. Time: 59.41\n",
      "2022-04-14 12:52:37,607 - INFO - train -   Epoch 123. Top1: 92.1148. Top5: 99.5640. best_acc: 92.1148 in epoch 123\n",
      "2022-04-14 12:52:37,607 - INFO - train -   Epoch 123. Top1: 92.1148. Top5: 99.5640. best_acc: 92.1148 in epoch 123\n",
      "2022-04-14 12:53:39,632 - INFO - train -   epoch:124, iter: 64. loss: 0.2378. loss_u: 0.2349. loss_x: 0.0029. Mask:0.8808 . LR: 0.0070. Time: 62.02\n",
      "2022-04-14 12:53:39,632 - INFO - train -   epoch:124, iter: 64. loss: 0.2378. loss_u: 0.2349. loss_x: 0.0029. Mask:0.8808 . LR: 0.0070. Time: 62.02\n",
      "2022-04-14 12:54:38,846 - INFO - train -   epoch:124, iter: 128. loss: 0.2393. loss_u: 0.2327. loss_x: 0.0066. Mask:0.8762 . LR: 0.0070. Time: 59.21\n",
      "2022-04-14 12:54:38,846 - INFO - train -   epoch:124, iter: 128. loss: 0.2393. loss_u: 0.2327. loss_x: 0.0066. Mask:0.8762 . LR: 0.0070. Time: 59.21\n",
      "2022-04-14 12:55:41,490 - INFO - train -   epoch:124, iter: 192. loss: 0.2345. loss_u: 0.2283. loss_x: 0.0062. Mask:0.8763 . LR: 0.0069. Time: 62.64\n",
      "2022-04-14 12:55:41,490 - INFO - train -   epoch:124, iter: 192. loss: 0.2345. loss_u: 0.2283. loss_x: 0.0062. Mask:0.8763 . LR: 0.0069. Time: 62.64\n",
      "2022-04-14 12:56:40,586 - INFO - train -   epoch:124, iter: 256. loss: 0.2313. loss_u: 0.2260. loss_x: 0.0053. Mask:0.8778 . LR: 0.0068. Time: 59.09\n",
      "2022-04-14 12:56:40,586 - INFO - train -   epoch:124, iter: 256. loss: 0.2313. loss_u: 0.2260. loss_x: 0.0053. Mask:0.8778 . LR: 0.0068. Time: 59.09\n",
      "2022-04-14 12:56:44,621 - INFO - train -   Epoch 124. Top1: 92.0422. Top5: 99.4731. best_acc: 92.1148 in epoch 123\n",
      "2022-04-14 12:56:44,621 - INFO - train -   Epoch 124. Top1: 92.0422. Top5: 99.4731. best_acc: 92.1148 in epoch 123\n",
      "2022-04-14 12:57:48,273 - INFO - train -   epoch:125, iter: 64. loss: 0.2291. loss_u: 0.2255. loss_x: 0.0036. Mask:0.8808 . LR: 0.0067. Time: 63.65\n",
      "2022-04-14 12:57:48,273 - INFO - train -   epoch:125, iter: 64. loss: 0.2291. loss_u: 0.2255. loss_x: 0.0036. Mask:0.8808 . LR: 0.0067. Time: 63.65\n",
      "2022-04-14 12:58:46,561 - INFO - train -   epoch:125, iter: 128. loss: 0.2286. loss_u: 0.2240. loss_x: 0.0046. Mask:0.8798 . LR: 0.0066. Time: 58.28\n",
      "2022-04-14 12:58:46,561 - INFO - train -   epoch:125, iter: 128. loss: 0.2286. loss_u: 0.2240. loss_x: 0.0046. Mask:0.8798 . LR: 0.0066. Time: 58.28\n",
      "2022-04-14 12:59:46,770 - INFO - train -   epoch:125, iter: 192. loss: 0.2283. loss_u: 0.2243. loss_x: 0.0041. Mask:0.8812 . LR: 0.0066. Time: 60.21\n",
      "2022-04-14 12:59:46,770 - INFO - train -   epoch:125, iter: 192. loss: 0.2283. loss_u: 0.2243. loss_x: 0.0041. Mask:0.8812 . LR: 0.0066. Time: 60.21\n",
      "2022-04-14 13:00:45,171 - INFO - train -   epoch:125, iter: 256. loss: 0.2290. loss_u: 0.2249. loss_x: 0.0041. Mask:0.8817 . LR: 0.0065. Time: 58.40\n",
      "2022-04-14 13:00:45,171 - INFO - train -   epoch:125, iter: 256. loss: 0.2290. loss_u: 0.2249. loss_x: 0.0041. Mask:0.8817 . LR: 0.0065. Time: 58.40\n",
      "2022-04-14 13:00:49,206 - INFO - train -   Epoch 125. Top1: 91.0974. Top5: 99.5094. best_acc: 92.1148 in epoch 123\n",
      "2022-04-14 13:00:49,206 - INFO - train -   Epoch 125. Top1: 91.0974. Top5: 99.5094. best_acc: 92.1148 in epoch 123\n",
      "2022-04-14 13:01:52,748 - INFO - train -   epoch:126, iter: 64. loss: 0.2293. loss_u: 0.2248. loss_x: 0.0045. Mask:0.8747 . LR: 0.0064. Time: 63.54\n",
      "2022-04-14 13:01:52,748 - INFO - train -   epoch:126, iter: 64. loss: 0.2293. loss_u: 0.2248. loss_x: 0.0045. Mask:0.8747 . LR: 0.0064. Time: 63.54\n",
      "2022-04-14 13:02:53,622 - INFO - train -   epoch:126, iter: 128. loss: 0.2307. loss_u: 0.2264. loss_x: 0.0043. Mask:0.8784 . LR: 0.0063. Time: 60.87\n",
      "2022-04-14 13:02:53,622 - INFO - train -   epoch:126, iter: 128. loss: 0.2307. loss_u: 0.2264. loss_x: 0.0043. Mask:0.8784 . LR: 0.0063. Time: 60.87\n",
      "2022-04-14 13:03:54,080 - INFO - train -   epoch:126, iter: 192. loss: 0.2286. loss_u: 0.2237. loss_x: 0.0049. Mask:0.8773 . LR: 0.0062. Time: 60.46\n",
      "2022-04-14 13:03:54,080 - INFO - train -   epoch:126, iter: 192. loss: 0.2286. loss_u: 0.2237. loss_x: 0.0049. Mask:0.8773 . LR: 0.0062. Time: 60.46\n",
      "2022-04-14 13:04:55,813 - INFO - train -   epoch:126, iter: 256. loss: 0.2273. loss_u: 0.2223. loss_x: 0.0050. Mask:0.8778 . LR: 0.0062. Time: 61.73\n",
      "2022-04-14 13:04:55,813 - INFO - train -   epoch:126, iter: 256. loss: 0.2273. loss_u: 0.2223. loss_x: 0.0050. Mask:0.8778 . LR: 0.0062. Time: 61.73\n",
      "2022-04-14 13:05:00,000 - INFO - train -   Epoch 126. Top1: 90.9339. Top5: 99.6730. best_acc: 92.1148 in epoch 123\n",
      "2022-04-14 13:05:00,000 - INFO - train -   Epoch 126. Top1: 90.9339. Top5: 99.6730. best_acc: 92.1148 in epoch 123\n",
      "2022-04-14 13:06:04,510 - INFO - train -   epoch:127, iter: 64. loss: 0.2262. loss_u: 0.2227. loss_x: 0.0035. Mask:0.8800 . LR: 0.0061. Time: 64.51\n",
      "2022-04-14 13:06:04,510 - INFO - train -   epoch:127, iter: 64. loss: 0.2262. loss_u: 0.2227. loss_x: 0.0035. Mask:0.8800 . LR: 0.0061. Time: 64.51\n",
      "2022-04-14 13:07:04,555 - INFO - train -   epoch:127, iter: 128. loss: 0.2267. loss_u: 0.2230. loss_x: 0.0037. Mask:0.8806 . LR: 0.0060. Time: 60.04\n",
      "2022-04-14 13:07:04,555 - INFO - train -   epoch:127, iter: 128. loss: 0.2267. loss_u: 0.2230. loss_x: 0.0037. Mask:0.8806 . LR: 0.0060. Time: 60.04\n",
      "2022-04-14 13:08:04,980 - INFO - train -   epoch:127, iter: 192. loss: 0.2282. loss_u: 0.2245. loss_x: 0.0037. Mask:0.8816 . LR: 0.0059. Time: 60.42\n",
      "2022-04-14 13:08:04,980 - INFO - train -   epoch:127, iter: 192. loss: 0.2282. loss_u: 0.2245. loss_x: 0.0037. Mask:0.8816 . LR: 0.0059. Time: 60.42\n",
      "2022-04-14 13:09:06,196 - INFO - train -   epoch:127, iter: 256. loss: 0.2274. loss_u: 0.2234. loss_x: 0.0039. Mask:0.8815 . LR: 0.0059. Time: 61.21\n",
      "2022-04-14 13:09:06,196 - INFO - train -   epoch:127, iter: 256. loss: 0.2274. loss_u: 0.2234. loss_x: 0.0039. Mask:0.8815 . LR: 0.0059. Time: 61.21\n",
      "2022-04-14 13:09:10,269 - INFO - train -   Epoch 127. Top1: 92.3692. Top5: 99.6366. best_acc: 92.3692 in epoch 127\n",
      "2022-04-14 13:09:10,269 - INFO - train -   Epoch 127. Top1: 92.3692. Top5: 99.6366. best_acc: 92.3692 in epoch 127\n"
     ]
    }
   ],
   "source": [
    "model,criteria_x,criteria_u = create_model(args)\n",
    "num_iters_per_epoch = args.num_images_per_epoch // args.batch_size\n",
    "num_iters_all = num_iters_per_epoch * args.num_epoches\n",
    "ema = EMA(model,args.ema_decay)\n",
    "wd_params,non_wd_params = [],[]\n",
    "for name,param in model.named_parameters():\n",
    "    if 'bn' in name:\n",
    "        non_wd_params.append(param)\n",
    "    else:\n",
    "        wd_params.append(param)\n",
    "# print(len(wd_params),len(non_wd_params))\n",
    "param_list = [\n",
    "    {\n",
    "        'params':wd_params\n",
    "    },\n",
    "    {\n",
    "        'params':non_wd_params,\n",
    "        'weight_decay': 0\n",
    "    }\n",
    "]\n",
    "optimizer = torch.optim.SGD(param_list,lr=args.lr,weight_decay=args.wdecay,momentum=args.momentum,nesterov=args.nesterov)\n",
    "lr_schdlr = WarmupCosineLrScheduler(\n",
    "    optimizer,\n",
    "    max_iter=num_iters_all,\n",
    "    warmup_iter=0\n",
    ")\n",
    "\n",
    "\n",
    "best_acc = -1\n",
    "best_epoch = 0\n",
    "logger,writer = setup_default_logging(args)\n",
    "labeledDatasetDataloader,unlabeledDatasetDataloader=get_train_loader(args)\n",
    "validDatasetDataloader = get_valid_loader(args)\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Task = {args.dataset}@{args.num_labeled}\")\n",
    "logger.info(f\"  Num Iters Per Epoch = {num_iters_per_epoch}\")\n",
    "logger.info(f\"  Batch size per GPU = {args.batch_size}\")\n",
    "# logger.info(f\"  Total train batch size = {args.batch_size * args.world_size}\")\n",
    "logger.info(f\"  Total optimization steps = {num_iters_all}\")\n",
    "logger.info(\"Total params: {:.2f}M\".format(\n",
    "    sum(p.numel() for p in model.parameters()) / 1e6))\n",
    "logger.info('-----------start training--------------')\n",
    "for epoch in range(args.num_epoches):\n",
    "    train_loss,loss_x,loss_u,mask_mean=train_one_epoch(\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        criteria_x=criteria_x,\n",
    "        criteria_u=criteria_u,\n",
    "        optimizer=optimizer,\n",
    "        lr_schdlr=lr_schdlr,\n",
    "        ema=ema,\n",
    "        labeledDatasetLoader=labeledDatasetDataloader,\n",
    "        unlabeledDatasetLoader=unlabeledDatasetDataloader,\n",
    "        lambda_u=args.lambda_u,\n",
    "        n_iters=num_iters_per_epoch,\n",
    "        args=args,\n",
    "        logger=logger \n",
    "    )\n",
    "    top1, top5, valid_loss = evaluate(ema, validDatasetDataloader, criteria_x, args=args)\n",
    "\n",
    "    writer.add_scalars('train/1.loss', {'train': train_loss,\n",
    "                                        'test': valid_loss}, epoch)\n",
    "    writer.add_scalar('train/2.train_loss_x', loss_x, epoch)\n",
    "    writer.add_scalar('train/3.train_loss_u', loss_u, epoch)\n",
    "    writer.add_scalar('train/4.mask_mean', mask_mean, epoch)\n",
    "    writer.add_scalars('test/1.test_acc', {'top1': top1, 'top5': top5}, epoch)\n",
    "    # writer.add_scalar('test/2.test_loss', loss, epoch)\n",
    "\n",
    "    # best_acc = top1 if best_acc < top1 else best_acc\n",
    "    if best_acc < top1:\n",
    "        best_acc = top1\n",
    "        best_epoch = epoch\n",
    "\n",
    "    logger.info(\"Epoch {}. Top1: {:.4f}. Top5: {:.4f}. best_acc: {:.4f} in epoch {}\".\n",
    "                format(epoch, top1, top5, best_acc, best_epoch))\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6b347f591e985303f98a5578330a51eea0838d27215b123c4c1d58108c23409"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

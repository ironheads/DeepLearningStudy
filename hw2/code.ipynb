{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "## Note that: here we provide a basic solution for loading data and transforming data.\n",
    "## You can directly change it if you find something wrong or not good enough.\n",
    "\n",
    "## the mean and standard variance of imagenet dataset\n",
    "## mean_vals = [0.485, 0.456, 0.406]\n",
    "## std_vals = [0.229, 0.224, 0.225]\n",
    "\n",
    "def load_data(data_dir = \"dataset/\",input_size = 224,batch_size = 36):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    ## The default dir is for the first task of large-scale deep learning\n",
    "    ## For other tasks, you may need to modify the data dir or even rewrite some part of 'data.py'\n",
    "    image_dataset_train = datasets.ImageFolder(os.path.join(data_dir, '1-Large-Scale', 'train'), data_transforms['train'])\n",
    "    image_dataset_valid = datasets.ImageFolder(os.path.join(data_dir,'test'), data_transforms['test'])\n",
    "\n",
    "    train_loader = DataLoader(image_dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    valid_loader = DataLoader(image_dataset_valid, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def model_A(num_classes):\n",
    "    model_resnet = models.resnet18(pretrained=False)\n",
    "    num_features = model_resnet.fc.in_features\n",
    "    model_resnet.fc = nn.Linear(num_features, num_classes)\n",
    "    return model_resnet\n",
    "\n",
    "def model_B(num_classes):\n",
    "    ## your code here\n",
    "    pass\n",
    "\n",
    "\n",
    "def model_C(num_classes):\n",
    "    ## your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "epoch:0/100\n",
      "****************************************************************************************************\n",
      "training: 1.1631, 0.5981\n",
      "validation: 0.9626, 0.6639\n",
      "epoch:1/100\n",
      "****************************************************************************************************\n",
      "training: 0.8579, 0.7019\n",
      "validation: 0.7091, 0.7443\n",
      "epoch:2/100\n",
      "****************************************************************************************************\n",
      "training: 0.7329, 0.7435\n",
      "validation: 0.5771, 0.7976\n",
      "epoch:3/100\n",
      "****************************************************************************************************\n",
      "training: 0.6489, 0.7737\n",
      "validation: 0.5659, 0.8022\n",
      "epoch:4/100\n",
      "****************************************************************************************************\n",
      "training: 0.5955, 0.7922\n",
      "validation: 0.5810, 0.7909\n",
      "epoch:5/100\n",
      "****************************************************************************************************\n",
      "training: 0.5434, 0.8163\n",
      "validation: 0.4519, 0.8391\n",
      "epoch:6/100\n",
      "****************************************************************************************************\n",
      "training: 0.4911, 0.8319\n",
      "validation: 0.3867, 0.8665\n",
      "epoch:7/100\n",
      "****************************************************************************************************\n",
      "training: 0.4776, 0.8407\n",
      "validation: 0.4608, 0.8400\n",
      "epoch:8/100\n",
      "****************************************************************************************************\n",
      "training: 0.4484, 0.8463\n",
      "validation: 0.4861, 0.8391\n",
      "epoch:9/100\n",
      "****************************************************************************************************\n",
      "training: 0.4210, 0.8563\n",
      "validation: 0.3137, 0.8915\n",
      "epoch:10/100\n",
      "****************************************************************************************************\n",
      "training: 0.4051, 0.8645\n",
      "validation: 0.4029, 0.8702\n",
      "epoch:11/100\n",
      "****************************************************************************************************\n",
      "training: 0.3920, 0.8704\n",
      "validation: 0.3011, 0.8981\n",
      "epoch:12/100\n",
      "****************************************************************************************************\n",
      "training: 0.3691, 0.8753\n",
      "validation: 0.2904, 0.8985\n",
      "epoch:13/100\n",
      "****************************************************************************************************\n",
      "training: 0.3614, 0.8792\n",
      "validation: 0.2383, 0.9181\n",
      "epoch:14/100\n",
      "****************************************************************************************************\n",
      "training: 0.3493, 0.8831\n",
      "validation: 0.2076, 0.9302\n",
      "epoch:15/100\n",
      "****************************************************************************************************\n",
      "training: 0.3320, 0.8861\n",
      "validation: 0.2296, 0.9207\n",
      "epoch:16/100\n",
      "****************************************************************************************************\n",
      "training: 0.3226, 0.8922\n",
      "validation: 0.2113, 0.9256\n",
      "epoch:17/100\n",
      "****************************************************************************************************\n",
      "training: 0.3197, 0.8948\n",
      "validation: 0.2225, 0.9254\n",
      "epoch:18/100\n",
      "****************************************************************************************************\n",
      "training: 0.3128, 0.8956\n",
      "validation: 0.2003, 0.9313\n",
      "epoch:19/100\n",
      "****************************************************************************************************\n",
      "training: 0.3008, 0.8995\n",
      "validation: 0.2163, 0.9276\n",
      "epoch:20/100\n",
      "****************************************************************************************************\n",
      "training: 0.2924, 0.9022\n",
      "validation: 0.1863, 0.9343\n",
      "epoch:21/100\n",
      "****************************************************************************************************\n",
      "training: 0.2862, 0.9038\n",
      "validation: 0.1936, 0.9330\n",
      "epoch:22/100\n",
      "****************************************************************************************************\n",
      "training: 0.2834, 0.9047\n",
      "validation: 0.2004, 0.9313\n",
      "epoch:23/100\n",
      "****************************************************************************************************\n",
      "training: 0.2689, 0.9091\n",
      "validation: 0.1980, 0.9315\n",
      "epoch:24/100\n",
      "****************************************************************************************************\n",
      "training: 0.2734, 0.9095\n",
      "validation: 0.2179, 0.9244\n",
      "epoch:25/100\n",
      "****************************************************************************************************\n",
      "training: 0.2583, 0.9143\n",
      "validation: 0.2899, 0.8985\n",
      "epoch:26/100\n",
      "****************************************************************************************************\n",
      "training: 0.2579, 0.9144\n",
      "validation: 0.1694, 0.9422\n",
      "epoch:27/100\n",
      "****************************************************************************************************\n",
      "training: 0.2570, 0.9153\n",
      "validation: 0.2593, 0.9104\n",
      "epoch:28/100\n",
      "****************************************************************************************************\n",
      "training: 0.2454, 0.9210\n",
      "validation: 0.1659, 0.9420\n",
      "epoch:29/100\n",
      "****************************************************************************************************\n",
      "training: 0.2342, 0.9218\n",
      "validation: 0.1854, 0.9394\n",
      "epoch:30/100\n",
      "****************************************************************************************************\n",
      "training: 0.2446, 0.9188\n",
      "validation: 0.1704, 0.9394\n",
      "epoch:31/100\n",
      "****************************************************************************************************\n",
      "training: 0.2356, 0.9215\n",
      "validation: 0.1545, 0.9465\n",
      "epoch:32/100\n",
      "****************************************************************************************************\n",
      "training: 0.2398, 0.9204\n",
      "validation: 0.1608, 0.9454\n",
      "epoch:33/100\n",
      "****************************************************************************************************\n",
      "training: 0.2347, 0.9216\n",
      "validation: 0.1705, 0.9415\n",
      "epoch:34/100\n",
      "****************************************************************************************************\n",
      "training: 0.2240, 0.9234\n",
      "validation: 0.1910, 0.9313\n",
      "epoch:35/100\n",
      "****************************************************************************************************\n",
      "training: 0.2274, 0.9233\n",
      "validation: 0.1562, 0.9493\n",
      "epoch:36/100\n",
      "****************************************************************************************************\n",
      "training: 0.2177, 0.9269\n",
      "validation: 0.1971, 0.9344\n",
      "epoch:37/100\n",
      "****************************************************************************************************\n",
      "training: 0.2208, 0.9264\n",
      "validation: 0.1544, 0.9494\n",
      "epoch:38/100\n",
      "****************************************************************************************************\n",
      "training: 0.2214, 0.9282\n",
      "validation: 0.1255, 0.9546\n",
      "epoch:39/100\n",
      "****************************************************************************************************\n",
      "training: 0.2081, 0.9311\n",
      "validation: 0.1409, 0.9504\n",
      "epoch:40/100\n",
      "****************************************************************************************************\n",
      "training: 0.2071, 0.9316\n",
      "validation: 0.1493, 0.9498\n",
      "epoch:41/100\n",
      "****************************************************************************************************\n",
      "training: 0.2103, 0.9310\n",
      "validation: 0.1460, 0.9520\n",
      "epoch:42/100\n",
      "****************************************************************************************************\n",
      "training: 0.2093, 0.9316\n",
      "validation: 0.1846, 0.9346\n",
      "epoch:43/100\n",
      "****************************************************************************************************\n",
      "training: 0.1998, 0.9326\n",
      "validation: 0.1462, 0.9520\n",
      "epoch:44/100\n",
      "****************************************************************************************************\n",
      "training: 0.2037, 0.9316\n",
      "validation: 0.2874, 0.9030\n",
      "epoch:45/100\n",
      "****************************************************************************************************\n",
      "training: 0.1996, 0.9349\n",
      "validation: 0.1592, 0.9457\n",
      "epoch:46/100\n",
      "****************************************************************************************************\n",
      "training: 0.1963, 0.9343\n",
      "validation: 0.1188, 0.9589\n",
      "epoch:47/100\n",
      "****************************************************************************************************\n",
      "training: 0.1940, 0.9373\n",
      "validation: 0.1463, 0.9524\n",
      "epoch:48/100\n",
      "****************************************************************************************************\n",
      "training: 0.1921, 0.9369\n",
      "validation: 0.1159, 0.9615\n",
      "epoch:49/100\n",
      "****************************************************************************************************\n",
      "training: 0.1986, 0.9348\n",
      "validation: 0.1272, 0.9589\n",
      "epoch:50/100\n",
      "****************************************************************************************************\n",
      "training: 0.1951, 0.9342\n",
      "validation: 0.1220, 0.9598\n",
      "epoch:51/100\n",
      "****************************************************************************************************\n",
      "training: 0.1930, 0.9369\n",
      "validation: 0.2506, 0.9196\n",
      "epoch:52/100\n",
      "****************************************************************************************************\n",
      "training: 0.1832, 0.9395\n",
      "validation: 0.1272, 0.9569\n",
      "epoch:53/100\n",
      "****************************************************************************************************\n",
      "training: 0.1907, 0.9371\n",
      "validation: 0.1337, 0.9526\n",
      "epoch:54/100\n",
      "****************************************************************************************************\n",
      "training: 0.1776, 0.9414\n",
      "validation: 0.1174, 0.9589\n",
      "epoch:55/100\n",
      "****************************************************************************************************\n",
      "training: 0.1803, 0.9399\n",
      "validation: 0.1247, 0.9576\n",
      "epoch:56/100\n",
      "****************************************************************************************************\n",
      "training: 0.1821, 0.9400\n",
      "validation: 0.1225, 0.9563\n",
      "epoch:57/100\n",
      "****************************************************************************************************\n",
      "training: 0.1802, 0.9417\n",
      "validation: 0.1343, 0.9552\n",
      "epoch:58/100\n",
      "****************************************************************************************************\n",
      "training: 0.1714, 0.9429\n",
      "validation: 0.1181, 0.9598\n",
      "epoch:59/100\n",
      "****************************************************************************************************\n",
      "training: 0.1720, 0.9432\n",
      "validation: 0.1338, 0.9559\n",
      "epoch:60/100\n",
      "****************************************************************************************************\n",
      "training: 0.1765, 0.9419\n",
      "validation: 0.1564, 0.9456\n",
      "epoch:61/100\n",
      "****************************************************************************************************\n",
      "training: 0.1727, 0.9439\n",
      "validation: 0.1058, 0.9644\n",
      "epoch:62/100\n",
      "****************************************************************************************************\n",
      "training: 0.1665, 0.9438\n",
      "validation: 0.1160, 0.9587\n",
      "epoch:63/100\n",
      "****************************************************************************************************\n",
      "training: 0.1670, 0.9440\n",
      "validation: 0.1031, 0.9644\n",
      "epoch:64/100\n",
      "****************************************************************************************************\n",
      "training: 0.1707, 0.9450\n",
      "validation: 0.1278, 0.9559\n",
      "epoch:65/100\n",
      "****************************************************************************************************\n",
      "training: 0.1649, 0.9444\n",
      "validation: 0.1289, 0.9561\n",
      "epoch:66/100\n",
      "****************************************************************************************************\n",
      "training: 0.1631, 0.9475\n",
      "validation: 0.1171, 0.9591\n",
      "epoch:67/100\n",
      "****************************************************************************************************\n",
      "training: 0.1666, 0.9437\n",
      "validation: 0.1376, 0.9550\n",
      "epoch:68/100\n",
      "****************************************************************************************************\n",
      "training: 0.1630, 0.9465\n",
      "validation: 0.1798, 0.9359\n",
      "epoch:69/100\n",
      "****************************************************************************************************\n",
      "training: 0.1607, 0.9478\n",
      "validation: 0.1204, 0.9587\n",
      "epoch:70/100\n",
      "****************************************************************************************************\n",
      "training: 0.1591, 0.9470\n",
      "validation: 0.1182, 0.9607\n",
      "epoch:71/100\n",
      "****************************************************************************************************\n",
      "training: 0.1534, 0.9485\n",
      "validation: 0.1257, 0.9561\n",
      "epoch:72/100\n",
      "****************************************************************************************************\n",
      "training: 0.1629, 0.9470\n",
      "validation: 0.1510, 0.9494\n",
      "epoch:73/100\n",
      "****************************************************************************************************\n",
      "training: 0.1550, 0.9484\n",
      "validation: 0.1260, 0.9589\n",
      "epoch:74/100\n",
      "****************************************************************************************************\n",
      "training: 0.1517, 0.9510\n",
      "validation: 0.1451, 0.9543\n",
      "epoch:75/100\n",
      "****************************************************************************************************\n",
      "training: 0.1583, 0.9469\n",
      "validation: 0.1108, 0.9613\n",
      "epoch:76/100\n",
      "****************************************************************************************************\n",
      "training: 0.1521, 0.9499\n",
      "validation: 0.1352, 0.9569\n",
      "epoch:77/100\n",
      "****************************************************************************************************\n",
      "training: 0.1496, 0.9504\n",
      "validation: 0.1217, 0.9576\n",
      "epoch:78/100\n",
      "****************************************************************************************************\n",
      "training: 0.1547, 0.9473\n",
      "validation: 0.1160, 0.9613\n",
      "epoch:79/100\n",
      "****************************************************************************************************\n",
      "training: 0.1479, 0.9519\n",
      "validation: 0.1014, 0.9654\n",
      "epoch:80/100\n",
      "****************************************************************************************************\n",
      "training: 0.1471, 0.9511\n",
      "validation: 0.0961, 0.9663\n",
      "epoch:81/100\n",
      "****************************************************************************************************\n",
      "training: 0.1465, 0.9514\n",
      "validation: 0.1313, 0.9607\n",
      "epoch:82/100\n",
      "****************************************************************************************************\n",
      "training: 0.1489, 0.9494\n",
      "validation: 0.1137, 0.9622\n",
      "epoch:83/100\n",
      "****************************************************************************************************\n",
      "training: 0.1468, 0.9513\n",
      "validation: 0.1012, 0.9669\n",
      "epoch:84/100\n",
      "****************************************************************************************************\n",
      "training: 0.1416, 0.9519\n",
      "validation: 0.1068, 0.9626\n",
      "epoch:85/100\n",
      "****************************************************************************************************\n",
      "training: 0.1427, 0.9524\n",
      "validation: 0.1004, 0.9674\n",
      "epoch:86/100\n",
      "****************************************************************************************************\n",
      "training: 0.1477, 0.9506\n",
      "validation: 0.1471, 0.9519\n",
      "epoch:87/100\n",
      "****************************************************************************************************\n",
      "training: 0.1510, 0.9506\n",
      "validation: 0.1163, 0.9594\n",
      "epoch:88/100\n",
      "****************************************************************************************************\n",
      "training: 0.1451, 0.9513\n",
      "validation: 0.1058, 0.9633\n",
      "epoch:89/100\n",
      "****************************************************************************************************\n",
      "training: 0.1386, 0.9543\n",
      "validation: 0.1055, 0.9643\n",
      "epoch:90/100\n",
      "****************************************************************************************************\n",
      "training: 0.1380, 0.9553\n",
      "validation: 0.1101, 0.9641\n",
      "epoch:91/100\n",
      "****************************************************************************************************\n",
      "training: 0.1452, 0.9525\n",
      "validation: 0.1221, 0.9619\n",
      "epoch:92/100\n",
      "****************************************************************************************************\n",
      "training: 0.1391, 0.9548\n",
      "validation: 0.1212, 0.9587\n",
      "epoch:93/100\n",
      "****************************************************************************************************\n",
      "training: 0.1406, 0.9542\n",
      "validation: 0.1016, 0.9631\n",
      "epoch:94/100\n",
      "****************************************************************************************************\n",
      "training: 0.1356, 0.9562\n",
      "validation: 0.0975, 0.9659\n",
      "epoch:95/100\n",
      "****************************************************************************************************\n",
      "training: 0.1360, 0.9551\n",
      "validation: 0.1088, 0.9637\n",
      "epoch:96/100\n",
      "****************************************************************************************************\n",
      "training: 0.1383, 0.9532\n",
      "validation: 0.1263, 0.9593\n",
      "epoch:97/100\n",
      "****************************************************************************************************\n",
      "training: 0.1386, 0.9530\n",
      "validation: 0.1023, 0.9652\n",
      "epoch:98/100\n",
      "****************************************************************************************************\n",
      "training: 0.1388, 0.9540\n",
      "validation: 0.1100, 0.9644\n",
      "epoch:99/100\n",
      "****************************************************************************************************\n",
      "training: 0.1356, 0.9557\n",
      "validation: 0.1032, 0.9656\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "## Note that: here we provide a basic solution for training and validation.\n",
    "## You can directly change it if you find something wrong or not good enough.\n",
    "\n",
    "def train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=20):\n",
    "\n",
    "    def train(model, train_loader,optimizer,criterion):\n",
    "        model.train(True)\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct += torch.sum(predictions == labels.data)\n",
    "\n",
    "        epoch_loss = total_loss / len(train_loader.dataset)\n",
    "        epoch_acc = total_correct.double() / len(train_loader.dataset)\n",
    "        return epoch_loss, epoch_acc.item()\n",
    "\n",
    "    def valid(model, valid_loader,criterion):\n",
    "        model.train(False)\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_correct += torch.sum(predictions == labels.data)\n",
    "        epoch_loss = total_loss / len(valid_loader.dataset)\n",
    "        epoch_acc = total_correct.double() / len(valid_loader.dataset)\n",
    "        return epoch_loss, epoch_acc.item()\n",
    "\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('epoch:{:d}/{:d}'.format(epoch, num_epochs))\n",
    "        print('*' * 100)\n",
    "        train_loss, train_acc = train(model, train_loader,optimizer,criterion)\n",
    "        print(\"training: {:.4f}, {:.4f}\".format(train_loss, train_acc))\n",
    "        valid_loss, valid_acc = valid(model, valid_loader,criterion)\n",
    "        print(\"validation: {:.4f}, {:.4f}\".format(valid_loss, valid_acc))\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_model = model\n",
    "            torch.save(best_model, 'best_model.pt')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "    ## about model\n",
    "    num_classes = 10\n",
    "\n",
    "    ## about data\n",
    "    data_dir = \"dataset/\" ## You need to specify the data_dir first\n",
    "    input_size = 224\n",
    "    batch_size = 36\n",
    "\n",
    "    ## about training\n",
    "    num_epochs = 100\n",
    "    lr = 0.001\n",
    "\n",
    "    ## model initialization\n",
    "    model = model_A(num_classes=num_classes)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    ## data preparation\n",
    "    train_loader, valid_loader = load_data(data_dir=data_dir,input_size=input_size, batch_size=batch_size)\n",
    "\n",
    "    ## optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    ## loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_model(model,train_loader, valid_loader, criterion, optimizer, num_epochs=num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6b347f591e985303f98a5578330a51eea0838d27215b123c4c1d58108c23409"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
